{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"causal-inference-studies","text":"<p>Explaining the main concepts around causal learning via bitesize theory and code! </p> <p>The notebooks can be found on this page \ud83d\udcbb, whereas the lessons are listed below \ud83d\udc47.</p> <p>Introduction</p> Number Lesson Complexity 01Why causality matters\ud83d\udfe2 02When regression goes wrong\ud83d\udfe2 03When regression goes wrong 2\ud83d\udfe2 04Defining causation\ud83d\udfe2 05Non-causal problems\ud83d\udfe2 <p>Core concepts</p> Number Lesson Complexity -Potential Outcomes\ud83d\udfe1 -DAGs - Expressing causal knowledge\ud83d\udfe1 -DAGs - Basic math\ud83d\udfe1 -Insights from DAGs\ud83d\udfe1 -Causal effect Identification\ud83d\udfe1 -Types of causal effects\ud83d\udfe1 <p>Advanced topics</p> Number Lesson Complexity -Simpson's paradox\ud83d\udfe1 -DAGs with math\ud83d\udd34 -Attribution\ud83d\udd34 -Causal assumptions\ud83d\udfe1 -A/B testing\ud83d\udfe1 -Causality and time\ud83d\udd34 -Shapley values\ud83d\udfe1 -Shapley cont'd\ud83d\udfe1 <p>Complexity score: </p> <ul> <li>\ud83d\udfe2: a piece of cake</li> <li>\ud83d\udfe1: requires thinking about it, involves some math</li> <li>\ud83d\udd34: requires connecting dots, it's more rigorous</li> </ul> <p>If you need a quick refresher on probability, check out this page.</p> <p>External material such as books, video lectures, repos and Python packages are listed here.</p>"},{"location":"ab_testing/","title":"Ab testing","text":"<p>Resources:</p> <p>https://alexdeng.github.io/causal/abintro.html</p> <p>The Relationship between Experimentation and Causal Inference. Sean Taylor. [video]</p>"},{"location":"association_vs_causation/","title":"Association vs causation","text":"<p>TL;DR</p> <p>Statistical association (including correlation) does not imply causation.</p> <p>Statistical correlation between variables is very common and easy to find<sup>1</sup>. Real and solid causation patterns are way harder. That's because correlation can be induced by other phenomena apart from causation, and we tend to get confused by it.</p> <p>Consider this. Chocolate consumption of countries is highly correlated with the number of Nobel Prize Laureates they have. Which of the following conclusions should one draw from such association?</p> <ul> <li>Chocolate makes you smarter, leading to a higher count of Nobel prizes.</li> <li>People like to celebrate the winning of a Nobel prize by eating loads of chocolate.</li> <li>Maybe the two above are true.</li> <li>In wealthy countries people tend to eat more chocolate. Also, they tend to have better education, leading to more Nobel prizes.</li> </ul> <p>All those, and many more, could be the source of the observed association. </p> <p>TL;DR</p> <p>Causation involves intervening on a variable \\(T\\) to affect the distribution of another variable \\(Y\\).</p> <p>We know flipping a light switch on will make the room get brighter. That's causation in action.</p> <p>If we formalize this using the language of statistics, flipping the switch becomes a random variable, and it getting brighter too. That allows for non-deterministic mechanisms to be modeled, which is very useful: flipping the switch will probably turn the lights on, but maybe because of poor electrical contact they won't.</p> <p>Say \\(T=0\\) represent the switch being OFF, and \\(T=1\\) the switch being ON, then if</p> \\[E[Y(T=0)] \\neq E[Y(T=1)]\\] <p>we could say the switch has a causal effect on the lights, all other things being equal<sup>2</sup>.</p> <p>There are two main schools when it comes to causal analysis: the Potential Outcomes or Rubin's model, and Graphical Causal Models (GCM) or Pearl's model. The former is centered around the idea of counterfactual distributions and statistical independence of key quantities, whereas the latter is more visual and borrows from graph theory.</p> <p>What's important is to understand that the two approaches aren't opposed, but express similar ideas via different formalisms. Knowing about both is more useful than picking sides!</p> <p>TL;DR</p> <p>Establishing causation involves handling related variables and blocking spurious correlations from biasing our estimates.</p> <p>Imagine you \"block\" the influence of every possible variable on \\(Y\\), except for \\(T\\). Then, if you measure any remaining association between the two, you've established there is a causal effect at play. In a nutshell, that's our main goal.</p> <p>In the following pages, we'll define what \"related variables\" are, what \"blocking\" means, and see the harm that bias can cause.</p> <ol> <li> <p>Butter consumption is highly correlated with wind power generation! Check it out. This whole website is dedicated to spurious correlations.\u00a0\u21a9</p> </li> <li> <p>This excludes the interference of other variables such as gnomes sabotaging your experiment.\u00a0\u21a9</p> </li> </ol>"},{"location":"attribution/","title":"Attribution","text":"<p>TL;DR</p> <p>Causal attribution explains \\(Y\\) in terms of \\(X\\), while taking your DAG into account.</p> <p>TBW</p>"},{"location":"cates/","title":"CATEs","text":"Conditional average treatment effects (CATEs) measure the treatment for particular subgroups of the population."},{"location":"causal_assumptions/","title":"Causal assumptions","text":"Establishing causal relationships requires making assumptions.  <p>Causal inference does not rely purely on data and statistics. It requires more assumptions for causal relationships to be established.</p> <p>DAGs are a visual way of expressing our beliefs about how different quantities influence each other.</p> <p>As it turns out, DAGs are not enough. Even with infinite data, some causal relationships cannot be estimated.</p> Exchangeability: assuming if the control and treatment groups were swapped, the results would have been the same.  <p>Formally, exchangeability reads</p> \\[Y(0) \\perp T, \\quad Y(1) \\perp T\\] <p>where \\(T\\) is the treatment assignment, \\(Y(0)\\) is the outcome for when not receiving the treatment, and \\(Y(1)\\) is the outcome when receiving the treatment.</p> <p>A less strict version of this assumption would be</p> \\[E[ Y(1) \\, | \\, T = 0 ] = E[ Y(1) \\, | \\, T = 1 ]\\] <p>which asks for the expected value of having received the treatment (a counterfactual in the left-hand side case) to be the same under being assigned to the control group (\\(T=0\\)) or the treatment group (\\(T=1\\)).</p>"},{"location":"causal_discovery/","title":"Causal discovery","text":"In causal discovery, we start from data and try to find a (good) graph for it."},{"location":"causal_effects/","title":"Causal effects","text":"<p>TL;DR</p> <p>The fundamental problem of Causal Inference is that we can't change the past.</p> <p>You feel unwell, so you take some meds and go to bed...</p> <p>Next day you wake up just fine. Was it thanks to the meds or did you body just recover by itself? </p> <p>Well, we will never know!</p> <p>The so-called fundamental problem of causal inference is that never will we be able to measure causal effects on an individual basis. And that's because we can't go back in time, intervene (not taking the meds) and verify what happened to be 100% the observed outcome was due to the intervention.</p> <p>TL;DR</p> <p>TBW.</p> <p>To be covered: - Individual Treatment Effect (ITE) - Total Effect (TE) - Natural Direct Effect (NDE) - Natural Indirect Effect (NIE) - Controlled Direct Effect (CDE)</p> Acronym Effect Name Definition Interpretation ATE Average Treatment Effect \\(E[Y(1)\u2212Y(0)]E[Y(1)\u2212Y(0)]\\) Effect on a random individual in the population ITE Individual Treatment Effect \\(Y_i\u200b(1)\u2212Yi_\u200b(0)\\) Effect on a random individual in the population CATE Conditional Average Treatment Effect \\(Y_i\u200b(1)\u2212Yi_\u200b(0)\\) Effect on a random individual in the population"},{"location":"causal_questions/","title":"Causal questions","text":"<p>TL;DR</p> <p>Not every causal-looking question is a valid causal question.</p> <p>Consider these:</p> <ol> <li>Do vaccines kill?</li> <li>What is the effect of Vaccine X (versus placebo) on infection rates in a randomized trial?</li> <li>In smokers over 60, what is the effect of quitting smoking (versus continuing) on 5-year lung cancer risk, adjusting for age and baseline health?</li> <li>What is the effect of race on income?</li> <li>What is the effect of parental income on child's future income?</li> </ol> <p>Question 1. and question 4. are not valid causal questions. In 1. </p> <p></p> <p>TL;DR</p> <p>For a causal question to be valid, we need: consistency, </p>"},{"location":"confounders/","title":"Confounders","text":"<p>TL;DR</p> <p>A confounder is a variable that is not the treatment, nor the effect, but that can affect the association between the two.</p> <p>You have some data on the monthly ice cream sales in Brazil and the number of shark attacks on a costal region. Both variables are highly correlated as shown below.</p> <p>One could propose the following DAG to try to explain the phenomenon.</p> <p>But perhaps the one below, with season influencing both blue variables, would be a more sensible structure.</p> <p>The season node is a confounder as it affects both main variables of interest. In this example, it being summer drives up both ice cream sales and shark incident, giving the impression there is a causal link between the two.</p> <p></p> <p>TL;DR</p> <p>Confounders are bad: they can lead you to spurious conclusions if you ignore them. </p> <p>If you fit a linear model to predict shark attacks from ice cream sales, you get a very nice graph (see notebook)</p> <p>Not only that, the linear coefficient of the predictor (ice cream sales) even has a very low p-value</p> <p>So it's all statistically sound, right? So if we stop selling ice cream, surely we'll also save some swimmers lives...</p> <p>Well, if you had included temperature, you'd see a very different picture</p> <p>And the p-values of ice cream are now very high</p> <p>From our knowledge of how the world works, this second model seems more reasonable than the first one. </p> <p>Causal inference is all about making use of that expert knowledge as the first steps of the process, before estimating any linear/non-linear relationships. In that way, we can better trust the outcomes of our models.</p> <p></p> <p>TL;DR</p> <p> Treatment randomization is magical: it makes all confounding go away!  </p> <p>If you were to randomly give out ice cream to people, regardless of the season, you would see the association between ice cream and shark attacks disappear.</p> <p>With the DAG in mind, randomization would cut the arrow that connects season and ice cream, disqualifying season as a confounder.</p> <p>This is the beauty of randomized controlled trials (RCTs), widely employed in medical studies. By randomly assigning patients to the treatment or control group, you break all confounding. No wonder why RCTs are regarded as a gold standard in that field.</p> <p></p> <p>TL;DR</p> <p>Under no confounding, causal inference becomes trivial.</p> <p>Say you want to estimate the average extra hours of sleep you get if you take some miraculous new medicine</p> \\[\\text{ATE} = E[Y(1) - Y(0)]\\] <p>You run an experiment and, if \\(T\\) was randomized, the causal effect is as simple as</p> \\[\\text{ATE} = E[Y \\, | \\, T=1] - E[Y \\, | \\, T=0]\\] <p>that is, averaging the sleep hours \\(Y\\) among all people who got the med, and subtracting the average sleep hours \\(Y\\) for all who didn't take the med.</p> <p>N.B. Of course you'd still have to check if the final number is reliable or not (was your sample too small?). The estimator isn't biased, but variance can still hit you hard. </p> <p></p> <p>TL;DR</p> <p>When you can't run experiments, you need causal inference tools. </p> <p>Experiments are great! but sometimes you can't run them for a variety of reasons: costs, regulatory restrictions<sup>1</sup>, ethical implications<sup>2</sup>, and practical infeasibility<sup>3</sup>.</p> <p>Say you're given observational data: some treatment/policy/intervention data points where the units have some features, and you also see some additional covariates, and all those variables interact in certain ways. Then your best bet is to carefully draw a DAG and apply causal inference techniques if you want to draw causal conclusions from the dataset.</p> <p>This will ensure your model generalizes way better! </p> <ol> <li> <p>You're legally not allowed to manipulate markets in certain ways.\u00a0\u21a9</p> </li> <li> <p>You can't expose people to health hazards, e.g. asking some group to smoke.\u00a0\u21a9</p> </li> <li> <p>The treatment is having grey-colored eyes, and the control is having any other eye color...\u00a0\u21a9</p> </li> </ol>"},{"location":"confounders_contd/","title":"Confounders cont'd","text":"<p>TL;DR</p> <p>d-separation.</p> <p>You have some data on the monthly ice cream sales in Brazil and the number of shark attacks on a costal region. Both variables are highly correlated as shown below.</p> <p></p> <p>One could propose the following DAG to try to explain the phenomenon.</p> <p></p> <p>But perhaps the one below, with season influencing both blue variables, would be a more sensible structure.</p> <p></p> <p>The season node is a confounder as it affects both main variables of interest. In this example, it being summer drives up both ice cream sales and shark incident, giving the impression there is a causal link between the two.</p> <p>TL;DR</p> <p>The three elemental confounds are: the fork, the pipe, and the collider.</p> <p>There are three main types of confounding structures, which are defined by 3-node diagrams. Any more complex DAG can be analyzed based on these.</p> <p> </p> <p>At first sight, the collider seems inoffensive as there are no arrows going from \\(Z\\) to \\(X\\) or \\(Y\\), so how could it bias our analysis?</p> <p>Well, causal effects respect the arrow directions, but statistical association doesn't. It can flow against them.</p>"},{"location":"dags/","title":"DAGs","text":"<p>TL;DR</p> <p>DAGs are visual ways of expressing connections between variables.</p> <p>Directed acyclic graphs (DAGs) are an intuitive way of expressing your beliefs about a set of variables. </p> <p>A DAG has one node per variable and a set of edges connecting the nodes. Also, edges must be directed and, by going around the graph following them, you should not be able to find any loops. </p> <p>Take a look at this one DAG and see if you agree with it</p> <p>According to it, exercise influences blood pressure directly, maybe because it increases your bpm right away. But it also influences blood pressure indirectly, by reducing your weight, thus reducing your blood pressure.</p> <p>Here's some terminology</p> <ul> <li>Given a node (say weight), a parent is a node that directly maps to it (diet and exercise).</li> <li>Given a node (say weight), a child is a node that is directly mapped by it (blood pressure).</li> <li>A root node is a node with no parents (diet and exercise).</li> <li>A leaf node is a node with no children (blood pressure).</li> <li>A directed path is a path across nodes that doesn't go against any arrows (e.g. exercise -&gt; weight -&gt; blood pressure)</li> <li>A node (say blood pressure) is a descendant of another node (diet) if there's a directed path linking the latter to the former.</li> <li>Check this wikipedia page for a comprehensive glossary!</li> </ul> <p>TL;DR</p> <p>DAGs do not encode plain statistical independence, but conditional independence.</p> <p>Take the following DAG</p> <p>It does not imply/encode that \\(X1\\) and \\(X4\\) are independent. It instead encodes the fact that, given all its parents (\\(X3\\) and \\(X2\\)), the node \\(X4\\) becomes independent of every one else (\\(X1\\)).</p> <p>Mathematically, \\(X1 \\perp X4 \\; | \\; (X3, X2)\\). Or, more generally,</p> \\[X_i \\perp \\text{NonDesc}(X_i) \\; | \\; \\text{Pa}(X_i)\\] <p>where \\(\\text{NonDesc}(X_i)\\) are all non-descendants of \\(X_i\\). This is called the local Markov property.</p> <p>This leads to the following factorization formula for DAGs</p> \\[P(X_1, X_2, \\dots, X_n) = \\prod_{i=1}^{n} P(X_i \\; | \\; \\text{Pa}(X_i))\\] <p>which is known as the Markov factorization of DAGs.</p> <p>TL;DR</p> <p>Data alone (without any expert knowledge) is insufficient to arrive at a single DAG.</p> <p>Say you're given the data below, which clearly show \\(X1\\) and \\(X2\\) are strongly associated. Which DAG would represent it best?</p> <p>\\(X \\rightarrow Y\\) would be a reasonable first try... but if I told you \\(X\\) is body weight and \\(Y\\) is monthly chocolate consumption, then perhaps \\(Y \\rightarrow X\\)?</p> <p>Only because the plot shows \\(X\\) on the horizontal axis, it doesn't mean it is the cause of \\(Y\\) like we're used to thinking...</p> <p>What if a nutritionist comes and says a third variable is missing, \\(Z\\), which represent one's metabolism. And that a better DAG would be \\(Y \\rightarrow Z \\rightarrow X\\)?</p> <p>If even in the 2-variable case we require more assumptions to draw a sensible DAG, imagine how difficult the task would be with 20 interconnected variables. The process of finding DAGs from data and additional assumptions is called causal discovery.</p> <p>TL;DR</p> <p>DAGs define dependencies, but won't tell you exactly how those variables are linked... SCMs give you that last part of the puzzle.</p> <p>Say you have a set of variables \\(X_1,...,X_4\\). A structural causal model (SCM) is a collection of equations linking them:</p> \\[\\begin{align} X_1 &amp;= f_1(N_1) \\nonumber \\\\ X_2 &amp;= f_2(N_2) \\nonumber \\\\ X_3 &amp;= f_3(X_1, X_2, N_3) \\nonumber \\\\ X_4 &amp;= f_4(X_2, X_3, N_4) \\nonumber \\end{align}\\] <p>where \\(N_1,...,N_4\\) are exogenous (aka noise) variables, which are assumed to be jointly independent. For a given variable \\(X_i\\) its function \\(f_i\\) will have as arguments all parents \\(\\text{Par}(X_i)\\) as encoded by the DAG.</p> <p>At first sight, you could think the \\(N_i\\) components are there just to account for random fluctuations of the \\(X_i\\) such as noise in your measurement instrument. In practice, though, they're there also to capture the influence of all variables that you didn't include in your DAG.</p> <p>Think of all the possible factors that influence someone's blood pressure. Could you list them all? Can you measure them all? Probably not. So long as the un-measures variables don't interact with each other (that is, the \\(N_i\\)s are jointly independent) CI tools will work just fine!</p> <p>TL;DR</p> <p>Association can flow against arrows, causality cannot.</p>"},{"location":"dags_2/","title":"DAGs 2","text":"<p>TL;DR</p> <p>The fork, the pipe, and the collider are three elemental building blocks of any DAG.</p> <p>These are important basic structures that can be used to analyze more complex DAGs.</p> <p>Because those variables are all linked, statistical association can in principle be found between any pair of variables. That's what causes you to see links between quantities you'd otherwise think are completely (causally) unrelated. </p> <p>But worry not! It turns out we can stop spurious associations from contaminating our estimates. We do that simply by conditioning on (aka controlling for) the right variables, which causes variables that are not causally linked to not display associations anymore. In the CI jargon, that's referred to as blocking paths.</p> <p>TL;DR</p> <p>In a fork, conditioning on \\(Z\\) blocks the path between \\(X\\) and \\(Y\\).</p> <p>From the Markov factorization of the fork, we have</p> \\[p(X,Y,Z) = p(X|Z) \\; p(Z) \\; p(Y|Z)\\] <p>Now the conditional \\(p(X,Y | Z)\\) can be written as<sup>1</sup></p> \\[ \\begin{align} p(X,Y | Z) &amp;= \\frac{p(X,Y,Z)}{p(Z)} \\\\[5pt] &amp;= p(X|Z) \\; p(Y|Z) \\end{align} \\] <p>which is the definition of the conditional independence \\(X \\perp Y  \\, | \\, Z\\).</p> <p>TL;DR</p> <p>In a pipe, conditioning on \\(Z\\) blocks the path between \\(X\\) and \\(Y\\).</p> <p>This will be similar to the fork case. We have</p> \\[p(X,Y,Z) = p(X) \\; p(Z|X) \\; p(Y|Z)\\] <p>Then<sup>2</sup></p> \\[ \\begin{align} p(X,Y | Z) &amp;= \\frac{p(X,Y,Z)}{p(Z)} \\\\[5pt] &amp;= \\frac{p(X) \\; p(Z|X) \\; p(Y|Z)}{p(Z)} \\\\[5pt] &amp;= \\frac{p(X,Z) \\; p(Y|Z)}{p(Z)} \\\\[5pt] &amp;= p(X|Z) \\; p(Y|Z) \\end{align} \\] <p>which is the definition of the conditional independence \\(X \\perp Y  \\, | \\, Z\\).</p> <p>TL;DR</p> <p>In a collider, the path between \\(X\\) and \\(Y\\) is naturally closed.</p> <p>From the Markov factorization of the fork, we have</p> \\[p(X,Y,Z) = p(X) \\; p(Y) \\; p(Z|X,Y)\\] <p>then</p> \\[ \\begin{align} p(Y|X) &amp;= \\frac{p(X,Y)}{p(X)} \\\\[5pt] &amp;= \\frac{\\sum_z p(X,Y,Z)}{p(X)} \\\\[5pt] &amp;= \\frac{\\sum_z p(X) \\; p(Y) \\; p(Z|X,Y)}{p(X)} \\\\[5pt] &amp;= \\frac{p(X) \\, p(Y)}{p(X)} \\\\[5pt] &amp;= p(Y) \\end{align} \\] <p>So \\(p(X,Y) = p(X) \\, p(Y|X) = p(X) p (Y)\\), which is the definition of the independence \\(X \\perp Y\\).</p> <p>Final remarks</p> <p>At this point we know that paths can be opened and closed, so...</p> <ul> <li>Which paths should we open and which should we close?</li> <li>How can this be generalized to more complex graphs?</li> <li>What if I need to condition on a variable I actually didn't measure?</li> </ul> <p>Basically, we first need to define what exactly it is we want to measure. Maybe the \"direct\" influence of \\(X\\) on \\(Y\\), or the \"total\" influence perhaps? Different causal effect are discussed here.</p> <p>Next we need to understand what roles the other variables in the DAG play in this analysis, and block any potentially unwanted association. Confounders, i.e. variables that could corrupt our analysis, are tackled here. A general criterion for deciding what to block and what not to block is given here.</p> <ol> <li> <p>The first equality follows from the def. of the conditional probability. The second, from the Markov factorization above.\u00a0\u21a9</p> </li> <li> <p>The first equality follows from the def. of the conditional probability. The second, from the Markov factorization above. The third, from the product rule. The fourth, from the definition of the conditional probability.\u00a0\u21a9</p> </li> </ol>"},{"location":"dags_contd/","title":"DAGs cont'd","text":"<p>On this page we will go a little deeper </p> <p>TL;DR</p> <p>Association can flow against arrows, causality cannot.</p> <p>Directed acyclic graphs (DAGs) are an easy way of expressing your beliefs about a set of variables. </p> <p>A DAG has one node per variable and a set of edges connecting the nodes. Also, edges must be directed and, by going around the graph following them, you should not be able to find any loops. </p> <p>Below is a nice DAG that makes intuitive sense.</p> <p></p> <p>Given a node (say weight), a parent is a node that directly maps to it (diet and exercise).</p> <p>Given a node (say weight), a child is a node that is directly mapped by it (blood pressure).</p> <p>TL;DR</p> <p>DAGs do not encode plain statistical independence, but conditional independence.</p> <p>Take the following DAG:</p> <p></p> <p>It does not imply/encode that \\(X1\\) and \\(X4\\) are independent. It instead encodes the fact that, given all its parents (\\(X3\\) and \\(X2\\)), the node \\(X4\\) becomes independent of every one else (\\(X1\\)).</p> <p>Mathematically, \\(X1 \\perp X4 \\; | \\; (X3, X2)\\).</p> <p>Thinking back at the blood pressure example, the graph says blood pressure is indeed dependent on the diet even if diet is not its parent. However, if one fixes a given weight and exercise level, then the diet would have no influence on an individual's blood pressure!</p> <p>TL;DR</p> <p>Data alone (without any expert knowledge) is insufficient to arrive at a single DAG.</p> <p>Say you're given the data below, which clearly show \\(X1\\) and \\(X2\\) are strongly associated. Which DAG would represent it best?</p> <p></p> <p>\\(X \\rightarrow Y\\) would be a reasonable first try... but if I told you \\(X\\) is body weight and \\(Y\\) is monthly chocolate consumption, then perhaps \\(Y \\rightarrow X\\)?</p> <p>Only because the plot shows \\(X\\) on the horizontal axis, it doesn't mean it is the cause of \\(Y\\) like we're used to thinking...</p> <p>What if a nutritionist comes and says a third variable is missing, \\(Z\\), which represent one's metabolism. And that a better DAG would be \\(Y \\rightarrow Z \\rightarrow X\\)?</p> <p>If even in the 2-variable case we require more assumptions to draw a sensible DAG, imagine how difficult the task would be with 20 interconnected variables. The process of finding DAGs from data and additional assumptions is called causal discovery.</p> <p>TL;DR</p> <p>A DAG highlights links, but an SCM tells you exactly how variables are linked, functionally.</p> <p>DAGs tell you that two variables are linked, but won't tell you exactly how. A structural causal model (SCM), on the other hand, does exactly that.</p> <p>Say you have a set of variables \\(X_1,...,X_4\\). A SCM is a collection of equations linking them:</p> \\[\\begin{align} X_1 &amp;= f_1(N_1) \\nonumber \\\\ X_2 &amp;= f_2(N_2) \\nonumber \\\\ X_3 &amp;= f_3(X_1, X_2, N_3) \\nonumber \\\\ X_4 &amp;= f_4(X_2, X_3, N_4) \\nonumber \\end{align}\\] <p>where \\(N_1,...,N_4\\) are exogenous variables, also called noise variables. Noise variables are assumed to be jointly independent.</p> <p>Each SCM is associated with a unique DAG.</p> <p>TL;DR</p> <p>Association can flow against arrrows, causality cannot.</p>"},{"location":"dags_with_math/","title":"DAGs with math","text":"<p>Our goal here is to formalize core concepts involving DAGs.</p> <p>For this, consider a DAG denoted by \\(G\\) with nodes \\((V_1,\\dots,V_n)\\). Descendants and parents of node \\(V_i\\) are denoted respectively by \\(\\text{Desc}_i\\) and \\(\\text{Par}_i\\).</p> <p>Pied Piper</p> <p>bla</p>"},{"location":"ddml/","title":"Debiased/Double Machine Learning","text":"DDML = outcome modeling + treatment modeling"},{"location":"feature_selection/","title":"Feature selection","text":"<p>TL;DR</p> <p>All confounders must be controlled for, that is, included in your model as features.</p> <p>Failing to do that will lead to biased estimates, for instance concluding that ice cream sales are linked to shark attacks.</p> <p></p> <p>TL;DR</p> <p>How about including all you have? Well, it turns out that's also a bad idea sometimes...</p> <p>When you have a collider between treatment and outcome for example, that variable is best left alone. </p> <p>In this notebook, we explore how education (E) could affect wages (W). It turns out we also have access to how much money our subjects invest (I), and decided to add that to our model since it could provide some extra insights, right? </p> <p>Well, here's the DAG we have at hand</p> <p>Education influences wage levels, and more educated people also tend to invest more. Also, people with higher income also tend to invest more. </p> <p>In our simulations, we set the real factor linking education to wages to be \\(20\\), which where we are at if we only use \\(E\\) to predict \\(I\\) (blue distribution). However, look at what happens when we add the I variable (orange distribution)</p> <p>Not only is it biased, but it's turned negative! Such an analysis would conclude that the more you study, the lower your chances of earning more.</p> <p></p> <p>TL;DR</p> <p>Some variables are neutral, including them or not doesn't make a difference.</p> <p></p> <p>TL;DR</p> <p>The backdoor criterion tells us which variables to include in our models.</p> <p></p> <p>TL;DR</p> <p>All adjustment sets are equal, but some are more equal than others.</p> <p></p> <p>TL;DR</p> <p>To estimate causal effects well, you need to carefully select your features/predictors/regressors.</p> <p>Modern machine learning advocates for including all you can in your model, trying to achieve the lowest possible (test) error.</p> <p>This is a fair strategy if you are aiming at capturing patterns and predicting labels. </p> <p>If, however, your goals are more causal oriented (see the causal questions page), for instance:</p> <ul> <li>Study the main drivers of your output variable</li> <li>Design a policy based on your model to influence your output</li> <li>Understand what would have been if one of your variables had taken a different value</li> </ul> <p>then the ML approach can fall short of delivering a good answer. </p>"},{"location":"identification/","title":"Identification","text":"<p>Conditions for identifiability</p> <p>Key Conditions for Identifiability</p> <pre><code>Consistency: The observed outcome equals the potential outcome under the observed treatment.\n\nPositivity: Every treatment level has a positive probability for each level of covariates.\n\nExchangeability / Ignorability: No unmeasured confounding (in the potential outcomes framework).\n\nGraphical Criteria: Like backdoor or front-door adjustment sets (in structural causal models).\n</code></pre> <p>If these hold, identifiability is possible.</p> <p>Also, full observability does not imply identifiability.</p>"},{"location":"learners/","title":"Learners","text":"Learners (or meta-learners) are approaches used to estimate CATEs."},{"location":"learners/#discuss-s-learners-t-learners-x-learners","title":"Discuss S-learners, T-learners, X-learners","text":""},{"location":"notebooks/","title":"Notebooks","text":"<p>Here's a list of all jupyter notebooks and what they cover.</p> Name Complexity Topic Sharks and ice cream\ud83c\udf36\ufe0fA basic example showing association is not causation. Fertilizer and crop yield\ud83c\udf36\ufe0f\ud83c\udf36\ufe0fConfounding causing bias in Bayesian estimation. Education and wage\ud83c\udf36\ufe0f\ud83c\udf36\ufe0fCollider bias causing a positive effect to appear negative. Sleeping pills\ud83c\udf36\ufe0f\ud83c\udf36\ufe0fUsing the S-learner and T-learner to estimate CATEs. Uplift modelling\ud83c\udf36\ufe0f\ud83c\udf36\ufe0f\ud83c\udf36\ufe0fA more complex CATE estimation example. SHAP explanations\ud83c\udf36\ufe0f\ud83c\udf36\ufe0fUsing SHAP to explain a neural network."},{"location":"potential_outcomes/","title":"Potential outcomes","text":"<p>The potential outcomes (PO) model (aka Rubin Causal Model) was proposed by Donald Rubin, a famous psychologist/statistician.</p> <p>There is a group of people sitting at a crossroads point, a bifurcation. What happens to each of them is captured by the \\(Y_i\\) variables. Every person could either take the left path (\\(T=0\\)) or go right (\\(T=1\\)), and that'd lead them to the outcomes \\(Y_i(0)\\) or \\(Y_i(1)\\). </p> <ul> <li>Person \\(7\\) goes left and you measure their outcome \\(Y_7 = Y_7(0)\\)</li> <li>But what would have happened if they had gone right? </li> <li>Sadly, you will never measure both \\(Y_7(0)\\) and \\(Y_7(1)\\)<sup>1</sup>...</li> <li>Can you maybe say something about \\(Y(0)\\), i.e. what happens across individuals if they take the left path?</li> <li>Maybe, if enough data is captured, you could estimate \\(E[Y(0)]\\)?</li> <li>On average, is it better to go left or right?</li> <li>Can you put a number to \\(E[Y(0) - Y(1)]\\)?</li> </ul> <p>TL;DR</p> <p>The PO approach is all about measuring what happened \\(Y\\), and then inferring what could have been, \\(Y(0)\\) and \\(Y(1)\\).</p> <p>Of course, for every individual, the value \\(Y_i\\) will either match \\(Y_i(0)\\) or \\(Y_i(1)\\), but you'll never have the complete picture. One of the two outcomes will be missing. We refer to the missing one as the counterfactual outcome.</p> <p>One key concept here is the distinction between a potential outcome \\(Y(1)\\) and conditioning on a treatment \\(Y|T=1\\). The difference is illustrated by the diagram below</p> <p>Conditioning \\(Y|T=1\\) limits your dataset to those points where the units had \\(T=1\\). On the other hand, the quantity \\(Y(1)\\) is a thought experiment where all units received the treatment \\(T=1\\). </p> <p>Because your dataset \\(Y\\) contains some parts of the puzzle, you can estimate lots of interesting quantities under the right supporting assumptions.</p> <p>TL;DR</p> <p>Identification is the process of inferring things about \\(Y(0)\\) and/or \\(Y(1)\\) from the observational data you have, \\(Y\\).</p> <p>The average treatment effect (ATE) is defined as the expected difference </p> \\[\\tau = E[Y(1) - Y(0)]\\] <p>This is what you want to know when you ask yourself \"does eating one apple a day really keep the doctor away???\"</p> <p>Here's one simple idea: how about computing the average outcome among apple lovers \\(E[Y|T=1]\\) and subtracting that from the apple haters \\(E[Y|T=0]\\) we have in our sample set? That should be similar to \\(\\tau\\), right?</p> <p>Well, it turns out this can sometimes go very very wrong...</p> <p>If you miss important variables in your analysis, those could confound your groups and mess-up your results! Imagine that, by chance, all smokers ended up in your \\(T=0\\) group, whereas all the young athletes loved fruits and had \\(T=1\\). In that case you'll certainly conclude the apples kept the doctor away.</p> <p>You have two ways out: either balancing your groups<sup>2</sup> or taking the additional variables (smoking, doing sports, etc) explicitly into account. The more general principle at play here, what guarantees we can perform causal inference, is the one that follows.</p> <p>Tip</p> <p>Exchangeability \\(Y(0), Y(1) \\perp T\\) and Conditional Exchangeability \\(Y(0), Y(1) \\perp T \\, | \\, X\\) are key to identification.</p> <ol> <li> <p>That's called the fundamental problem of causal inference.\u00a0\u21a9</p> </li> <li> <p>Randomized controlled trials (RCTs) do exactly that.\u00a0\u21a9</p> </li> </ol>"},{"location":"probability_refresher/","title":"Probability refresher","text":"<p>Some basic definitions and properties needed to understand the material. Here, \\(A\\) and \\(B\\) are random variables, and \\(\\text{E}[\\;]\\) denotes the expected value operator. \\(\\alpha\\) and \\(\\beta\\) are two real numbers.</p> <p>CHAIN RULE</p> \\[p(A,B) = p(A) \\, p(B|A)\\] <p>INDEPENDENCE of \\(A\\) and \\(B\\)</p> \\[p(A,B) = p(A) \\, p(B)\\] <p>CONDITIONAL PROBABILITY</p> \\[p(A|B) = \\frac{p(A,B)}{p(B)}\\] <p>BAYE'S RULE</p> \\[p(A|B) = \\frac{p(B|A) \\, p(A)}{p(B)}\\] <p>LINEARITY of \\(\\text{E}[\\;]\\)</p> \\[\\text{E}[\\alpha A + \\beta B] = \\alpha\\text{E}[A] + \\beta\\text{E}[B]\\] <p>LAW OF TOTAL EXPECTATION</p> \\[\\text{E}[A] = \\text{E}[\\text{E}[A|B]]\\]"},{"location":"propensity_scores/","title":"Propensity scores","text":"<p>TL;DR</p> <p>Propensity scores are likelihoods. The likelihood of a certain type of unit receiving the treatment.</p> <p>Experiments are usually design balancing groups of treated \\(T=1\\) vs control people \\(T=0\\). And making sure that, if our population has some important features \\(X\\), those will be equally represented in both groups.</p> <p>Imagine testing the effectiveness of a new dietary supplement. Given some characteristic \\(X = \\text{vegan}\\), you'd want to see roughly the same number of these individuals in the treated and untreated groups. </p> <p>In observational studies, groups are not balanced and propensity scores measure that unbalance. Formally,</p> \\[e(x) \\triangleq P(T = 1 | X = x)\\] <p>If \\(e(x) = 0.5\\) for all \\(x\\), this means the treatment is actually independent of \\(x\\) and we've truly randomized it, guaranteeing no confounding!</p> <p>TL;DR</p> <p>Instead of controlling for \\(X\\), you can control for \\(e(X)\\) and that is great.</p> <p>TL;DR</p> <p>Inverse-probability weighting (IPW) is a method that uses propensity scores to estimate causal effects.</p>"},{"location":"resources/","title":"Resources","text":""},{"location":"resources/#software-packages","title":"Software packages","text":"<p>DoWhy is developed by Microsoft, and with it you can define causal graphs, perform identification, estimate effects, and attempt refutation. DoWhy forces you to state your causal assumptions via a DAG and rigorously go through all causal inference steps.</p> <p>causal-learn can be used to learn DAGs from data (and assumptions). It implements various DAG learning methods (constraint-based, score-based, permutation-based, etc), and provides utilities to carry out independence tests and evaluate learned graphs.</p> <p>causalml is a python package for effect estimation with a focus on ML, especially tree-based methods. As opposed to <code>DoWhy</code>, it is less formal with assumptions and does not offer extensive identification and refutation tools. It is aimed at data scientists and tech firms, instead of economists.</p> <p>networkx is the go-to python package for graph creation and manipulation. Also, it is not limited to DAGs. With networkx, you can analyze graphs by computing centrality measures, and carrying out structural and connectivity analyses for example.</p>"},{"location":"resources/#books","title":"Books","text":"<ul> <li>(2000) Causality - Models, Reasoning and Inference. J. Pearl.</li> <li>(2010) Causal Inference - What If. M. A. Hern\u00e1n, J. M. Robins.</li> <li>(2017) Elements of Causal Inference - Foundations and Learning Algorithms. J. Peters, D. Janzing, B. Sch\u00f6lkopf.</li> <li>(2024) Causal Inference: A Statistical Learning Approach. S. Wager. </li> </ul>"},{"location":"resources/#videos","title":"Videos","text":"<ul> <li>(2019) MIT Lectures on Causal Inference for Healthcare. [YouTube]</li> <li>(2017) Lectures on Causality series, J. Peters. [YouTube]</li> <li>(2015) Towards Causal Machine Learning, B. Sch\u00f6lkopf. [YouTube]</li> <li>(2021) Machine Learning and Causal Inference, Stanford. S. Wager. [YouTube]</li> </ul>"},{"location":"resources/#articles-slide-decks-repos","title":"Articles, slide decks, repos","text":"<ul> <li>(2009) Causal inference in statistics: An overview. J. Pearl</li> <li>(2019) Causality for Machine Learning. B. Sch\u00f6lkopf. [paper]</li> <li>(2023) Statistical Rethinking Course, R. McElreath. [slides, YouTube]</li> <li>(2021) Causal Inference: An overview. A. Deng. [repo]</li> <li>(2022) Causal Inference for the Brave and True. M. Facure. [repo]</li> </ul>"},{"location":"shapley_contd/","title":"Shapley cont'd","text":""},{"location":"shapley_contd/#shapley-values-vs-causal-effects","title":"Shapley values vs. causal effects","text":"<p>Shapley values explain the effects of \\(X_1, \\dots, X_n\\) on \\(Y\\), but they require you to specify values for all of the features. In other words, they explain your model \\(f\\) around a fixed point in the domain. The fact that Shapley computations average out multiple \\(X\\) values via the expectation doesn't change the fact those are always contrasted to the user-given fixed point.</p> <p>Causal effects, on the other hand, capture the influence of \\(X\\) on \\(Y\\) across the whole domain and do not require pre-specifying a set of feature values. Indeed, take the ATE expression for a binary treatment \\(\\tau = \\text{E}[Y(0) - Y(1)]\\). Assuming the treatment \\(X\\) is binary, it consider both values and contrasts both \\(Y\\) distributions.</p> <p>To better understand what's going on here, let's go back go a very simple linear example.</p> <p>Example</p> <p>Take \\(Y = f(X) = 5 X_1 + 3 X_2\\).</p> <p>If you were to analyze \\(f\\) around \\(X_1 = 1\\), \\(X_2 = 10\\), you'd get the Shapley values \\(\\phi_1 = 5\\) and \\(\\phi_2 = 30\\), assuming your baseline is \\(\\phi_0 = 0\\), which would happen if both features had distributions centered around zero. Now if you take \\(X_1 = 2\\), \\(X_2 = 20\\) you get \\(\\phi_1 = 10\\) and \\(\\phi_2 = 60\\), and so on...</p> <p>Shapley values vary and can be directly tied to the output... you could say they share the same measurement units! \ud83d\udccf</p> <p>What's the causal effect of \\(X_1\\) on \\(Y\\)? Well, under unconfoundedness, it's... \\(5\\). And the causal effect of \\(X_2\\) on \\(Y\\) is... \\(3\\). If we're talking ATEs, those don't vary across the domain<sup>1</sup>.</p> <p>The causal effect is not a measure of direct contribution to \\(Y\\), but of the features derivative.</p>"},{"location":"shapley_contd/#shapley-properties","title":"Shapley properties","text":"<p>How do Shapley values behave, though? What properties can we expect them to have?</p> <p>Here's a summary:</p> Property Explanation Math Efficiency The sum of all Shapley values equals the function output \\(\\sum \\phi_i = f(x)\\) Symmetry Features with the same contributions get equal Shapley values \\(f(S \\cup \\{i\\}) = f(S \\cup \\{j\\}), \\forall S \\implies \\phi_i = \\phi_j\\) Null player Features that don't contribute have zero Shapley values \\(f(S \\cup \\{i\\}) = f(S), \\forall S \\implies \\phi_i = 0\\) Linearity Shapley values respect linearity of \\(f\\) \\(f = \\alpha g + \\beta h \\implies \\phi_{f,i} = \\alpha\\phi_{g,i} + \\beta\\phi_{h,i}\\) <p>Additional properties are listed in this paper and on the following wikipedia page.</p> <p>What is important to keep in mind is that some Shapley versions do not satisfy the extended set of properties. Still, those are supposed to help you build an intuition around how they behave and how they should be interpreted in practice.</p> <ol> <li> <p>As opposed to ATEs, CATEs do vary depending on auxiliary (context) variables. Still, the derivative interpretation still holds in that case.\u00a0\u21a9</p> </li> </ol>"},{"location":"shapley_values/","title":"Shapley values","text":""},{"location":"shapley_values/#introduction","title":"Introduction","text":"<p>Shapley values were originally proposed in the 50s as a way of distributing a total prize among a series of players participating in a game. If you imagine the prize is the model output \\(y\\), and the players are the individual features \\(x_i\\), you can re-use the same theory to better understand ML models!</p> <p>Picture this. Your model produced an output \\(f(x)\\), and you want to understand why. Shapley values decompose your prediction into parts</p> \\[f(x) = \\phi_0 + \\sum_{i} \\phi_i\\] <p>where each \\(\\phi_i\\) summarizes the contribution of feature \\(x_i\\) to the output! and \\(\\phi_0\\) is a baseline constant value.</p> <p>Example</p> <p>You have a model to predict someone's expected yearly salary and want to explain why for person \\(X\\), the output was $ 89'000. Shapley could then give you a decomposition such as</p> Feature Shapley value \\(\\phi_0\\) 45'000 age = 42 +33'000 education = MSc +4'000 eyes = brown -1'000 fav cheese = gouda -3'000 children = 3 +11'000 Total \ud83d\udcb0 89'000 <p>where \\(\\phi_0\\) is the average salary predicted by the model.</p> <p>That's kind of cool, right? Even if your model isn't linear, Shapley gives you the isolated contributions of each feature to the predicted value. </p>"},{"location":"shapley_values/#how-does-the-method-work","title":"How does the method work?","text":"<p>The method is grounded in game theory \ud83c\udfb2 and statistics \ud83d\udcca.</p> <p>It regards \\(X\\) and \\(f(X)\\) as random variables, and computes the baseline \\(\\phi_0\\) as the expected value </p> \\[\\phi_0 = E[f(X)]\\] <p>whereas each individual feature contribution \\(\\phi_i\\) is given by </p> \\[\\phi_i\u200b=\\sum_{S\u2286N\u2216{i}} \\frac{\u200b\\vert S\\vert! \\, (\\vert N \\vert\u2212 \\vert S \\vert\u22121)!}{\\vert N \\vert!} \\, \\Big(f(S\u222a\\{i\\})\u2212f(S)\\Big)\\] <p>The formula above looks intimidating, but it's actually a simple weighted sum. For any so called coalition \\(S\\), the first terms weights its importance, and the second term is the difference in function values when the feature \\(X_i\\) is included vs when it's not included.</p> <p>So it's a simple delta! computed and weighted across all possibles combinations of features. </p> <p>Example</p> <p>You have the following values \\(X_1 = 10\\), \\(X_2 = 20\\), \\(X_3 = 30\\). Here are all coallitions for \\(i=1\\)</p> \\(S\\) \\(f(S)\\) \\(S \\cup \\{i\\}\\) \\(f(S \\cup \\{i\\})\\) [ \\(\\emptyset\\) ] \\(f(\\,\\cdot\\,,\\,\\cdot\\,,\\,\\cdot\\,)\\) [\\(1\\)] \\(f(10,\\,\\cdot\\,,\\,\\cdot\\,)\\) [ \\(2\\) ] \\(f(\\,\\cdot\\,,20,\\,\\cdot\\,)\\) [\\(1\\),\\(2\\)] \\(f(10,20,\\,\\cdot\\,)\\) [ \\(3\\) ] \\(f(\\,\\cdot\\,,\\,\\cdot\\,,30)\\) [\\(1\\),\\(3\\)] \\(f(10,\\,\\cdot\\,,30)\\) [ \\(2,3\\) ] \\(f(\\,\\cdot\\,,20,30)\\) [\\(1\\),\\(2\\),\\(3\\)] \\(f(10,20,30)\\) <p>So a coallition \\(S\\) can be thought of as the set of players active in the game.</p> <p>But what does \\(f(\\,\\cdot\\,,20,\\,\\cdot\\,)\\) even mean? How can we make that evaluate to a scalar in a sensible way?</p> <p>Well, there are multiple ways of doing that and, up to this date, people debate what the best thing to do is. Next, we explore some of the possibilities.</p>"},{"location":"shapley_values/#the-many-possible-flavors","title":"The many possible flavors","text":"<p>In this section we will see how to turn partially-evaluated function e.g. \\(f(10, \\,\\cdot\\,,\\,\\cdot\\,)\\) into scalars in a reasonable way.</p> <p>How about setting the components \\(x_2, x_3\\) to zero? Or, more in general, defining a baseline vector \\(\\bar x\\) from which to borrow components every time we need them? In a demographic model, this could be your average individual, and in a computer vision model, your average input image. That's known as the baseline approach.</p> <p>Some would argue that this is not realistic. That if we think our features have some intrinsic distribution, we should fill the gaps in \\(f(\\,10,\\cdot\\,,\\,\\cdot\\,)\\) by sampling from the distribution of the missing values, and summarize what we've seen by reporting an average.</p> <p>Which distribution should it be, though?</p> <ul> <li>The marginal \\(p(x_2, x_3)\\) ?</li> <li>The marginals \\(p(x_2), p(x_3)\\)?</li> <li>The conditional \\(p(x_2, x_3 | \\, x_1 = 10)\\)?</li> </ul> <p>What if you don't have a distribution for your features, but only know max/min values for them. Should you maybe sample the domain uniformly?</p> <p>All these approaches are possible, but the resulting Shapley values should be interpreted accordingly<sup>1</sup>. </p> <p></p>"},{"location":"shapley_values/#a-computational-example","title":"A computational example","text":"<p>In this notebook, we have a simple 2-layer Neural Network that was trained to learn a certain dataset.</p> <p>To try and explain our black-box model, we use SHAP: first, instantiate a so-called \"explainer\", passing your model <code>mlp</code> and a dataset <code>X</code>. Next, you pass you dataset to the explainer again, which will compute the values for the entire dataset. To see what they look like for the \\(20\\)th data point, you can use a nice waterfall plot</p> <pre><code>import shap\n\nexplainer = shap.Explainer(mlp.predict, X)\nshap_values = explainer(X)\nshap.plots.waterfall(shap_values[20])\n</code></pre> <p>Here we have the features \\(x_1 = 6.119, x_2 = 6.576, x_3 = 7.916\\), linked to Shapley values \\(\\phi_0 = 132.635\\), \\(\\phi_1 = 42.45\\), \\(\\phi_2 = -19.09\\) and \\(\\phi_3 = 10.65\\), for a final prediction of \\(f(x) = 166.649\\).</p> <p>But that's only for a single datapoint. If you wanna know the rest of the story, how the Shapley values look across the entire dataset \\(X\\), you can call the <code>summary_plot</code> method</p> <pre><code>shap.summary_plot(shap_values, X)\n</code></pre> <p>The plots tell us \\(x_1\\) seems to have overall the highest impact on the predictions (largest spread). Also, \\(x_1\\) and \\(x_3\\) have a positive impact on the model output for higher feature values (red), whereas \\(x_2\\) has a negative effect on the output (note how the blue and red colors are reversed). Looking at our ground-truth</p> \\[f(x_1, x_2, x_3) = 5 x_1^2 - 10 x_2 + 5 x_3\\] <p>it turns out these explanations are very much aligned with it<sup>2</sup><sup>3</sup>! \ud83d\ude07</p> <ol> <li> <p>If for example you disregard a part of your domain where \\(f\\) depends heavily on \\(x_2\\), this won't be reflected on your \\(\\phi_2\\) value (and other \\(\\phi_i\\) as well).\u00a0\u21a9</p> </li> <li> <p>N.B. the package is trying to explain the model, not the ground-truth. If the training was flawed or the data had too much noise, the model would be a bad representation of it, and the Shapley values wouldn't reflect the ground-truth at all.\u00a0\u21a9</p> </li> <li> <p>Also, if you were wondering, SHAP defaults to marginally sampling the group of missing features, i.e., sampling from \\(p(x_2,x_3)\\) when \\(x_1\\) is given.\u00a0\u21a9</p> </li> </ol>"},{"location":"when_regression_goes_wrong/","title":"When regression goes wrong","text":"<p>Intro</p> <p>Here's an example of how even ordinary linear regression with two variables can be dangerous!</p> <p>Being more precise, we will see that no business decisions can be made based on one of the models...</p> <p>You're a data scientist at an office supply company (maybe Dunder Mifflin \ud83d\udcce) and are given this dataset by your manager</p> <p>Clearly, both variables are linked and there's a neat linear trend in the plot. You open a jupyter notebook and fit a linear model using statsmodels, being careful to even investigate the p-values of the estimated coefficients. The table you get reassures you: the CC parameter is not only positive, but also has a very low p-value<sup>1</sup>! The standard error is small and the whole confidence interval is positive.</p> <p>There's just one thing that bothers you... Nobody has told you yet what the variables stand for! \ud83e\udd14\ud83e\udd14</p> <p>You go turn some rocks and find out CC stands for coffee consumption and OS for office supply sales. What's more concerning, your boss is thinking of sending clients complimentary coffee bags in the hopes of boosting your sales. Now that got you worried because if the strategy fails, people will think your analyses are really flawed as you can't even get a linear model right!</p> <p>After some careful thinking, you realize maybe this link between coffee consumption and sales can be explained by the company size, which you were missing in your model. Clients with a larger headcount also buy more from you, but offering them free coffee won't really affect their purchasing patterns...</p> <p>After putting together this new column and fitting a new model, voil\u00e0, you arrive at</p> <p>showing that coffee consumption has essentially no effect on sales (the confidence interval goes between \\(-0.026\\) and \\(0.019\\) and the p-value is very high, \\(0.775\\)). On the other hand, company size explains all the sales variation (positive coefficient of \\(0.5022\\) and p-value of \\(&lt;0.001\\)).</p> <p>You manage to convince your boss to drop the coffee distribution, the day is saved. \ud83c\udf1f</p> <p>Final remarks</p> <p>The first model (coffee consumption to sales) was statistically sound, no problem with that. What you can't do is draw causal conclusions from its coefficients, or changing \\(X\\) in the hopes of steering the \\(Y\\) variable. Adding company size as a variable made the coefficients match our intuition, our knowledge of how the world works, and that was useful.</p> <p>Some questions linger:</p> <ul> <li>Is the second model \"causal\"?</li> <li>Should we look for more variables?</li> <li>Should we always add all variables we have to the model?</li> <li>Under which assumptions can I rest assured my model is interpretable?</li> </ul> <ol> <li> <p>This indicates that the association you've found was not due to mere chance.\u00a0\u21a9</p> </li> </ol>"},{"location":"when_regression_goes_wrong_2/","title":"When regression goes wrong 2","text":"<p>Intro</p> <p>After going through the coffee and paper sales pickle, you've learned your lesson: never miss an important variable! Maybe we could take this to the extreme and simply adhere to</p> <p> Models should have access to as many variables as possible, and ML will figure out their true relationship! </p> <p>Well... Not so fast!</p> <p>You are asked to study some new dataset, composed of the following variables:</p> <ul> <li> <p>Education \\(E\\): how many years in total different people studies</p> </li> <li> <p>Wage \\(W\\): how much they make per year</p> </li> <li> <p>Investment \\(I\\): how much they have invested in any type of financial instrument</p> </li> </ul> <p>And people want to know: if you study more, will get a better salary in the future? Here's what the data tells you:</p> <p>All variables seem to be well behaved, and you can see clear positive association between any two of them. \u2705</p> <p>Let's fit a model to see if we can measure the strength of these relationships. And, just to be on the safe side, you do it using Bayesian statistics, to see the true level of uncertainty around your estimates.</p> <p>You define the following model</p> \\[ \\begin{aligned} W &amp;= \\alpha + \\beta_E \\, E  + \\beta_I \\, I  \\end{aligned} \\] <p>and the priors \\(\\alpha \\sim N(0,5)\\), \\(\\beta_E \\sim N(0,5)\\) and \\(\\beta_I \\sim N(0,5)\\), which can lead to both negative or positive final values for those coefficients. After all, we are open to both conclusions.</p> <p>You take your data and run MCMC to see how the data is gonna transform your prior distribution. To your surprise, you get the following plot:</p> <p>This is really upsetting because even though the pairplot above hinted at the relationship being positive (the more educated, the higher the wage), you see your fancy Bayesian machine pointing at a clearly negative coefficient! \ud83d\ude2d</p> <p>Let's then just drop that extra variable \\(I\\) and see what happens. Sure enough, as soon as you do that, voil\u00e0, a much better plot presents itself to you. Since I created the data generating process, I also plotted the true causal effect for you to see. The causal effect was \\(+20\\) all along and the simpler model captured it correctly.</p> <p>Final remarks</p> <p>Adding all variables didn't cut it... </p> <p>We wanted to simply get a linear coefficient right in such a simple setting and we failed! Not only that, but the bias was so strong that the sign was reversed!</p> <p>The solution was to drop one of the variables, but why? \ud83e\udd14\ud83e\udd14</p> <p>There must be a good explanation for this, a rigorous method for arriving at reliabe, unbiased coefficients. Well, there is!</p>"},{"location":"why_causality_matters/","title":"Why causality matters","text":"<p>TL;DR</p> <p>Because it is useful in many areas: economics, medicine, marketing, just to name a few.</p> <p>Causal analysis helps us answer questions like:</p> <ul> <li> <p>\ud83c\udfe5 What is the effect of smoking on the likelihood of developing lung cancer?</p> </li> <li> <p>\ud83d\udcca Does raising the minimum wage reduce employment?</p> </li> <li> <p>\ud83e\udde0 Do smaller class sizes cause better student outcomes?</p> </li> <li> <p>\ud83d\udcc8 Does personalized advertising lead to higher conversion rates?</p> </li> </ul> <p>So, in essence, causal inference helps us understand and predict what will happen if we intervene on some variable.</p> <p></p> <p>TL;DR</p> <p>Because causal models succeed \ud83d\udcaa when non-causal models fail \u2639\ufe0f.</p> <p>If your goal is to change variable \\(Y\\) by acting on variable \\(X\\), you need causal analysis.</p> <p>Throwing every variable you have at your model can lead to serious interpretability issues, and make you believe you can drive \\(Y\\) when you actually can't. Sometimes it reverses signs in linear models, suggesting the link between a given \\(X\\) and a \\(Y\\) is positive when it's actually negative...<sup>1</sup> </p> <p>Causal inference tool help us build models that generalize well and with which we can make robust interventions<sup>2</sup>.</p> <p></p> <p>TL;DR</p> <p>Because causality is fascinating! \u2b50</p> <p>We, humans, think causally: </p> <ul> <li>Drinking coffee makes me feel more stressed.</li> <li>Teens these days spend too much time on social media, this is making them feel lonely.</li> <li>Did covid vaccines really help with the pandemic?</li> </ul> <p>By studying causality, you gain the statistical knowledge necessary to analyze those statements more rigorously, in the hopes of validating/invalidating them. </p> <p>Maybe whenever you're stressed at work you end up visiting the coffee machine more often. So coffee isn't really to blame for your mood\u2014your boss is! \u2615 \ud83d\udc40</p> <ol> <li> <p>There are tasks in which causal analysis is not required, of course. Some of those are discussed in the non-causal questions page.\u00a0\u21a9</p> </li> <li> <p>Regulatory bodies for example require pharmaceutical companies to present causal proofs (via clinical trials) that new drugs indeed have the intended effect on patients. Merely training an ML model to show a positive association isn't enough!  \u21a9</p> </li> </ol>"},{"location":"notebooks/education_wage_investments/","title":"Education and wage","text":"In\u00a0[\u00a0]: Copied! <pre>import warnings\n\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport numpy as np\nimport pandas as pd\nimport pymc as pm\nimport seaborn as sns\n\nnp.random.seed(111)\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.plotting_context(\"notebook\")\n</pre> import warnings  import matplotlib.pyplot as plt import networkx as nx import numpy as np import pandas as pd import pymc as pm import seaborn as sns  np.random.seed(111) warnings.filterwarnings('ignore') plt.style.use('seaborn-v0_8-whitegrid') sns.plotting_context(\"notebook\") In\u00a0[39]: Copied! <pre>EDU = 'education'\nWAGE = 'wage'\nINV = '\\ninvestments'\nnodes = [EDU, WAGE, INV]\nedges = [(EDU, WAGE), (EDU, INV), (WAGE, INV)]\n\nG = nx.DiGraph()\nG.add_nodes_from(nodes)\nG.add_edges_from(edges)\n\n# Position nodes in a diamond layout\npos = {EDU: (0, 0), WAGE: (1, 0), INV: (0.5, 0.5),}\nbasic_settings = {\n    \"node_color\": 'white',\n    \"node_size\": 15000,\n    \"font_size\": 20,\n    \"edgecolors\": 'white',\n    \"linewidths\": 2.5,\n    \"arrowsize\": 30,\n    \"width\": 3,\n    \"edge_color\": 'k',\n    \"arrows\": True,\n}\nplt.figure(figsize=(8, 4))\nnx.draw(G, pos, with_labels=True, **basic_settings)\n</pre> EDU = 'education' WAGE = 'wage' INV = '\\ninvestments' nodes = [EDU, WAGE, INV] edges = [(EDU, WAGE), (EDU, INV), (WAGE, INV)]  G = nx.DiGraph() G.add_nodes_from(nodes) G.add_edges_from(edges)  # Position nodes in a diamond layout pos = {EDU: (0, 0), WAGE: (1, 0), INV: (0.5, 0.5),} basic_settings = {     \"node_color\": 'white',     \"node_size\": 15000,     \"font_size\": 20,     \"edgecolors\": 'white',     \"linewidths\": 2.5,     \"arrowsize\": 30,     \"width\": 3,     \"edge_color\": 'k',     \"arrows\": True, } plt.figure(figsize=(8, 4)) nx.draw(G, pos, with_labels=True, **basic_settings) In\u00a0[44]: Copied! <pre>n_samples = 1000\nTRUE_CAUSAL_EFFECT = 20.0\n\ndef wages_ground_truth(education):\n    return 10000 + TRUE_CAUSAL_EFFECT * education + np.random.normal(0, 80, education.shape)\n\ndef investments_ground_truth(education, wage):\n    return 1000 + 50 * education + 2 * wage + np.random.normal(0, 80, education.shape)\n\neducation = np.random.normal(loc=10, scale=2, size=n_samples)\nwages = wages_ground_truth(education)\ninvestments = investments_ground_truth(education, wages)\n\ndata = pd.DataFrame({\n    'education': education,\n    'wage': wages,\n    'investments': investments\n})\n\nsns.pairplot(data)\n</pre> n_samples = 1000 TRUE_CAUSAL_EFFECT = 20.0  def wages_ground_truth(education):     return 10000 + TRUE_CAUSAL_EFFECT * education + np.random.normal(0, 80, education.shape)  def investments_ground_truth(education, wage):     return 1000 + 50 * education + 2 * wage + np.random.normal(0, 80, education.shape)  education = np.random.normal(loc=10, scale=2, size=n_samples) wages = wages_ground_truth(education) investments = investments_ground_truth(education, wages)  data = pd.DataFrame({     'education': education,     'wage': wages,     'investments': investments })  sns.pairplot(data) Out[44]: <pre>&lt;seaborn.axisgrid.PairGrid at 0x159f11be0&gt;</pre> In\u00a0[\u00a0]: Copied! <pre># Standardize variables for MCMC\nstd_data = data.copy()\nstd_data['education_std'] = (data['education'] - data['education'].mean()) / data['education'].std()\nstd_data['wage_std'] = (data['wage'] - data['wage'].mean()) / data['wage'].std()\nstd_data['investments_std'] = (data['investments'] - data['investments'].mean()) / data['investments'].std()\n\nn_samples = 5000\ntune = 1000\n\n# Wage ~ Education \nwith pm.Model() as model_unbiased:\n    alpha = pm.Normal('alpha', mu=0, sigma=10)\n    beta_edu = pm.Normal('beta_edu', mu=0, sigma=10)\n    sigma = pm.HalfNormal('sigma', sigma=5)\n    mu = alpha + beta_edu * std_data['education_std']\n    y = pm.Normal('y', mu=mu, sigma=sigma, observed=std_data['wage_std'])\n    trace_unbiased = pm.sample(n_samples, tune=tune, return_inferencedata=True)\n\n# Wage ~ Education + Investments\nwith pm.Model() as model_collider:\n    alpha = pm.Normal('alpha', mu=0, sigma=10)\n    beta_edu = pm.Normal('beta_edu', mu=0, sigma=10)\n    beta_inv = pm.Normal('beta_inv', mu=0, sigma=10)\n    sigma = pm.HalfNormal('sigma', sigma=5)\n    mu = alpha + beta_edu * std_data['education_std'] + beta_inv * std_data['investments_std']\n    y = pm.Normal('y', mu=mu, sigma=sigma, observed=std_data['wage_std'])\n    trace_collider = pm.sample(n_samples, tune=tune, return_inferencedata=True)\n</pre> # Standardize variables for MCMC std_data = data.copy() std_data['education_std'] = (data['education'] - data['education'].mean()) / data['education'].std() std_data['wage_std'] = (data['wage'] - data['wage'].mean()) / data['wage'].std() std_data['investments_std'] = (data['investments'] - data['investments'].mean()) / data['investments'].std()  n_samples = 5000 tune = 1000  # Wage ~ Education  with pm.Model() as model_unbiased:     alpha = pm.Normal('alpha', mu=0, sigma=10)     beta_edu = pm.Normal('beta_edu', mu=0, sigma=10)     sigma = pm.HalfNormal('sigma', sigma=5)     mu = alpha + beta_edu * std_data['education_std']     y = pm.Normal('y', mu=mu, sigma=sigma, observed=std_data['wage_std'])     trace_unbiased = pm.sample(n_samples, tune=tune, return_inferencedata=True)  # Wage ~ Education + Investments with pm.Model() as model_collider:     alpha = pm.Normal('alpha', mu=0, sigma=10)     beta_edu = pm.Normal('beta_edu', mu=0, sigma=10)     beta_inv = pm.Normal('beta_inv', mu=0, sigma=10)     sigma = pm.HalfNormal('sigma', sigma=5)     mu = alpha + beta_edu * std_data['education_std'] + beta_inv * std_data['investments_std']     y = pm.Normal('y', mu=mu, sigma=sigma, observed=std_data['wage_std'])     trace_collider = pm.sample(n_samples, tune=tune, return_inferencedata=True) In\u00a0[49]: Copied! <pre># Extract posterior samples\nunbiased_effect = trace_unbiased.posterior['beta_edu'].values.flatten()\ncollider_effect = trace_collider.posterior['beta_edu'].values.flatten()\n\n# Rescale to original units\nstd_wage = data['wage'].std()\nstd_edu = data['education'].std()\nunbiased_effect_rescaled = unbiased_effect * std_wage / std_edu\ncollider_effect_rescaled = collider_effect * std_wage / std_edu\n\n\nplt.figure(figsize=(10, 4))\nsns.kdeplot(unbiased_effect_rescaled, fill=True, label='Ignoring Investment', alpha=0.7)\nsns.kdeplot(collider_effect_rescaled, fill=True, label='Including Investment', alpha=0.7)\nplt.axvline(x=TRUE_CAUSAL_EFFECT, color='red', linestyle='--', label='True Causal Effect')\nplt.title('Posterior distributions of the Education Coefficient')\nplt.xlabel('Value')\nplt.ylabel('Density')\nplt.legend()\n\nprint(\"Unbiased model effect estimate: {:.2f} (95% CI: [{:.2f}, {:.2f}])\".format(\n    unbiased_effect_rescaled.mean(),\n    np.percentile(unbiased_effect_rescaled, 2.5),\n    np.percentile(unbiased_effect_rescaled, 97.5)\n))\nprint(\"Collider model effect estimate: {:.2f} (95% CI: [{:.2f}, {:.2f}])\".format(\n    collider_effect_rescaled.mean(),\n    np.percentile(collider_effect_rescaled, 2.5),\n    np.percentile(collider_effect_rescaled, 97.5)\n))\nprint(\"True causal effect: {:.2f}\".format(TRUE_CAUSAL_EFFECT))\n</pre> # Extract posterior samples unbiased_effect = trace_unbiased.posterior['beta_edu'].values.flatten() collider_effect = trace_collider.posterior['beta_edu'].values.flatten()  # Rescale to original units std_wage = data['wage'].std() std_edu = data['education'].std() unbiased_effect_rescaled = unbiased_effect * std_wage / std_edu collider_effect_rescaled = collider_effect * std_wage / std_edu   plt.figure(figsize=(10, 4)) sns.kdeplot(unbiased_effect_rescaled, fill=True, label='Ignoring Investment', alpha=0.7) sns.kdeplot(collider_effect_rescaled, fill=True, label='Including Investment', alpha=0.7) plt.axvline(x=TRUE_CAUSAL_EFFECT, color='red', linestyle='--', label='True Causal Effect') plt.title('Posterior distributions of the Education Coefficient') plt.xlabel('Value') plt.ylabel('Density') plt.legend()  print(\"Unbiased model effect estimate: {:.2f} (95% CI: [{:.2f}, {:.2f}])\".format(     unbiased_effect_rescaled.mean(),     np.percentile(unbiased_effect_rescaled, 2.5),     np.percentile(unbiased_effect_rescaled, 97.5) )) print(\"Collider model effect estimate: {:.2f} (95% CI: [{:.2f}, {:.2f}])\".format(     collider_effect_rescaled.mean(),     np.percentile(collider_effect_rescaled, 2.5),     np.percentile(collider_effect_rescaled, 97.5) )) print(\"True causal effect: {:.2f}\".format(TRUE_CAUSAL_EFFECT)) <pre>Unbiased model effect estimate: 19.25 (95% CI: [16.73, 21.73])\nCollider model effect estimate: -17.07 (95% CI: [-18.61, -15.53])\nTrue causal effect: 20.00\n</pre>"},{"location":"notebooks/education_wage_investments/#education-and-wage","title":"Education and wage\u00b6","text":"<p>An example of how collider bias can reverse the sign of a relationship, tainting our effect estimates.</p>"},{"location":"notebooks/education_wage_investments/#define-the-dag-and-the-simulation-mechanism","title":"Define the DAG and the simulation mechanism\u00b6","text":"<p>The variables here are: education level, wage, and investment funds.</p> <p>We assume the causal structure: education affects wage (E \u2192 W), and both education and wage affect investments (E \u2192 I \u2190 W).</p> <p>We are looking to understand what effect education level has on wages.</p>"},{"location":"notebooks/education_wage_investments/#bayesian-linear-regression","title":"Bayesian linear regression\u00b6","text":"<p>We'll fit two models:</p> <ul> <li>Wage ~ Education (does not condition on Investments)</li> <li>Wage ~ Education + Investments (conditions on the collider)</li> </ul>"},{"location":"notebooks/education_wage_investments/#comparing-results","title":"Comparing results\u00b6","text":"<p>Let's compare the posterior distributions of the education effect from both models and see what we get.</p>"},{"location":"notebooks/education_wage_investments/#conclusions","title":"Conclusions\u00b6","text":"<p>The blue model did not consider investment and yielded a good causal effect estimate. Its estimated posterior for the wage coefficient was not only positive, but also almost centered around the true value (20)!</p> <p>When investment was included (orange), the posterior coefficient distribution became negative, which is terrible.</p> <p>These results were expected from the DAG, as conditioning on a colider opens a non-causal path between the treatment (education) and the output variable (wage). The right approach to measuring the causal effect between them must be ignoring the collider variable.</p>"},{"location":"notebooks/fertilizer_and_crop_yield/","title":"Fertilizer and crop yield","text":"In\u00a0[1]: Copied! <pre>import warnings\n\nimport arviz as az\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pymc as pm\nimport seaborn as sns\n\n# Set random seed for reproducibility\nnp.random.seed(42)\nwarnings.filterwarnings('ignore')\n\n# Set plot style\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_context(\"talk\")\n</pre> import warnings  import arviz as az import matplotlib.pyplot as plt import numpy as np import pandas as pd import pymc as pm import seaborn as sns  # Set random seed for reproducibility np.random.seed(42) warnings.filterwarnings('ignore')  # Set plot style plt.style.use('seaborn-v0_8-whitegrid') sns.set_context(\"talk\") In\u00a0[2]: Copied! <pre>n_samples = 1000\ntrue_effect_fertilizer = 5\n\n# Generate soil pH levels (the confounder)\npH = np.random.normal(loc=7, scale=1, size=n_samples)\n\n# Generate fertilizer use (treatment) influenced by pH\n# Higher pH makes fertilizer use more likely\nprob_fertilizer = 1 / (1 + np.exp(-(pH - 7)))\nfertilizer = np.random.binomial(n=1, p=prob_fertilizer, size=n_samples)\n\n# Generate crop yield (outcome) influenced by both pH and fertilizer\n# pH has a nonlinear effect on yield, with optimal growth around pH 6.5\npH_effect = -2 * (pH - 6.5) ** 2 + 5\ncrop_yield = (\n    10 + pH_effect + true_effect_fertilizer * fertilizer + np.random.normal(0, 2, n_samples)\n)\n\n# Create a DataFrame with all variables\ndata = pd.DataFrame({\"pH\": pH, \"fertilizer\": fertilizer, \"crop_yield\": crop_yield})\ndata.head()\n</pre> n_samples = 1000 true_effect_fertilizer = 5  # Generate soil pH levels (the confounder) pH = np.random.normal(loc=7, scale=1, size=n_samples)  # Generate fertilizer use (treatment) influenced by pH # Higher pH makes fertilizer use more likely prob_fertilizer = 1 / (1 + np.exp(-(pH - 7))) fertilizer = np.random.binomial(n=1, p=prob_fertilizer, size=n_samples)  # Generate crop yield (outcome) influenced by both pH and fertilizer # pH has a nonlinear effect on yield, with optimal growth around pH 6.5 pH_effect = -2 * (pH - 6.5) ** 2 + 5 crop_yield = (     10 + pH_effect + true_effect_fertilizer * fertilizer + np.random.normal(0, 2, n_samples) )  # Create a DataFrame with all variables data = pd.DataFrame({\"pH\": pH, \"fertilizer\": fertilizer, \"crop_yield\": crop_yield}) data.head() Out[2]: pH fertilizer crop_yield 0 7.496714 1 17.394704 1 6.861736 0 13.233982 2 7.647689 1 18.003971 3 8.523030 1 14.495601 4 6.765847 0 11.108306 In\u00a0[10]: Copied! <pre># Plot distributions and relationships\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\n# Plot pH distribution\nsns.histplot(data=data, x='pH', kde=True, ax=axes[0, 0])\naxes[0, 0].set_title('Distribution of Soil pH')\n\n# Plot relationship between pH and fertilizer\nsns.boxplot(data=data, x='fertilizer', y='pH', ax=axes[0, 1])\naxes[0, 1].set_title('Soil pH by Fertilizer Use')\n\n# Plot relationship between fertilizer and crop yield\nsns.boxplot(data=data, x='fertilizer', y='crop_yield', ax=axes[1, 0])\naxes[1, 0].set_title('Crop Yield by Fertilizer Use')\n\n# Plot relationship between pH and crop yield, colored by fertilizer\nsns.scatterplot(data=data, x='pH', y='crop_yield', hue='fertilizer', ax=axes[1, 1])\naxes[1, 1].set_title('Crop Yield vs pH by Fertilizer Use')\n\nplt.tight_layout()\nplt.show()\n\n# Calculate some summary statistics to see the confounding effect\nno_fertilizer_mean = data[data.fertilizer == 0].crop_yield.mean()\nfertilizer_mean = data[data.fertilizer == 1].crop_yield.mean()\nprint(f\"Average crop yield without fertilizer: {no_fertilizer_mean:.2f}\")\nprint(f\"Average crop yield with fertilizer: {fertilizer_mean:.2f}\\n\")\nprint(f\"Naive difference in means, which is biased: {fertilizer_mean - no_fertilizer_mean:.2f}\")\nprint(f\"True causal effect: {true_effect_fertilizer}\") \n</pre> # Plot distributions and relationships fig, axes = plt.subplots(2, 2, figsize=(15, 12))  # Plot pH distribution sns.histplot(data=data, x='pH', kde=True, ax=axes[0, 0]) axes[0, 0].set_title('Distribution of Soil pH')  # Plot relationship between pH and fertilizer sns.boxplot(data=data, x='fertilizer', y='pH', ax=axes[0, 1]) axes[0, 1].set_title('Soil pH by Fertilizer Use')  # Plot relationship between fertilizer and crop yield sns.boxplot(data=data, x='fertilizer', y='crop_yield', ax=axes[1, 0]) axes[1, 0].set_title('Crop Yield by Fertilizer Use')  # Plot relationship between pH and crop yield, colored by fertilizer sns.scatterplot(data=data, x='pH', y='crop_yield', hue='fertilizer', ax=axes[1, 1]) axes[1, 1].set_title('Crop Yield vs pH by Fertilizer Use')  plt.tight_layout() plt.show()  # Calculate some summary statistics to see the confounding effect no_fertilizer_mean = data[data.fertilizer == 0].crop_yield.mean() fertilizer_mean = data[data.fertilizer == 1].crop_yield.mean() print(f\"Average crop yield without fertilizer: {no_fertilizer_mean:.2f}\") print(f\"Average crop yield with fertilizer: {fertilizer_mean:.2f}\\n\") print(f\"Naive difference in means, which is biased: {fertilizer_mean - no_fertilizer_mean:.2f}\") print(f\"True causal effect: {true_effect_fertilizer}\")  <pre>Average crop yield without fertilizer: 13.45\nAverage crop yield with fertilizer: 16.64\n\nNaive difference in means, which is biased: 3.18\nTrue causal effect: 5\n</pre> In\u00a0[\u00a0]: Copied! <pre># Standardize variables for better MCMC convergence\ndata_std = data.copy()\ndata_std[\"pH_std\"] = (data[\"pH\"] - data[\"pH\"].mean()) / data[\"pH\"].std()\ndata_std[\"crop_yield_std\"] = (data[\"crop_yield\"] - data[\"crop_yield\"].mean()) / data[\n    \"crop_yield\"\n].std()\n\n# 1. Naive model (ignoring the confounder)\nwith pm.Model() as naive_model:\n    # Priors\n    alpha = pm.Normal(\"alpha\", mu=0, sigma=10)\n    beta_fertilizer = pm.Normal(\"beta_fertilizer\", mu=0, sigma=10)\n    sigma = pm.HalfNormal(\"sigma\", sigma=5)\n    # Linear model\n    mu = alpha + beta_fertilizer * data_std[\"fertilizer\"]\n    # Likelihood\n    y = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=data_std[\"crop_yield_std\"])\n    # Inference\n    naive_trace = pm.sample(2000, tune=1000, return_inferencedata=True)\n\n# 2. Adjusted model (controlling for the confounder)\nwith pm.Model() as adjusted_model:\n    # Priors\n    alpha = pm.Normal(\"alpha\", mu=0, sigma=10)\n    beta_fertilizer = pm.Normal(\"beta_fertilizer\", mu=0, sigma=10)\n    beta_pH = pm.Normal(\"beta_pH\", mu=0, sigma=10)\n    sigma = pm.HalfNormal(\"sigma\", sigma=5)\n    # Linear model with pH and pH squared to capture nonlinear effects\n    mu = (\n        alpha\n        + beta_fertilizer * data_std[\"fertilizer\"]\n        + beta_pH * data_std[\"pH_std\"]\n    )\n    # Likelihood\n    y = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=data_std[\"crop_yield_std\"])\n    # Inference\n    adjusted_trace = pm.sample(5000, tune=1000, return_inferencedata=True)\n</pre> # Standardize variables for better MCMC convergence data_std = data.copy() data_std[\"pH_std\"] = (data[\"pH\"] - data[\"pH\"].mean()) / data[\"pH\"].std() data_std[\"crop_yield_std\"] = (data[\"crop_yield\"] - data[\"crop_yield\"].mean()) / data[     \"crop_yield\" ].std()  # 1. Naive model (ignoring the confounder) with pm.Model() as naive_model:     # Priors     alpha = pm.Normal(\"alpha\", mu=0, sigma=10)     beta_fertilizer = pm.Normal(\"beta_fertilizer\", mu=0, sigma=10)     sigma = pm.HalfNormal(\"sigma\", sigma=5)     # Linear model     mu = alpha + beta_fertilizer * data_std[\"fertilizer\"]     # Likelihood     y = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=data_std[\"crop_yield_std\"])     # Inference     naive_trace = pm.sample(2000, tune=1000, return_inferencedata=True)  # 2. Adjusted model (controlling for the confounder) with pm.Model() as adjusted_model:     # Priors     alpha = pm.Normal(\"alpha\", mu=0, sigma=10)     beta_fertilizer = pm.Normal(\"beta_fertilizer\", mu=0, sigma=10)     beta_pH = pm.Normal(\"beta_pH\", mu=0, sigma=10)     sigma = pm.HalfNormal(\"sigma\", sigma=5)     # Linear model with pH and pH squared to capture nonlinear effects     mu = (         alpha         + beta_fertilizer * data_std[\"fertilizer\"]         + beta_pH * data_std[\"pH_std\"]     )     # Likelihood     y = pm.Normal(\"y\", mu=mu, sigma=sigma, observed=data_std[\"crop_yield_std\"])     # Inference     adjusted_trace = pm.sample(5000, tune=1000, return_inferencedata=True) <pre>Initializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [alpha, beta_fertilizer, sigma]\n</pre> <pre></pre> <pre>Sampling 4 chains for 1_000 tune and 2_000 draw iterations (4_000 + 8_000 draws total) took 1 seconds.\nInitializing NUTS using jitter+adapt_diag...\nMultiprocess sampling (4 chains in 4 jobs)\nNUTS: [alpha, beta_fertilizer, beta_pH, sigma]\n</pre> <pre></pre> <pre>Sampling 4 chains for 1_000 tune and 5_000 draw iterations (4_000 + 20_000 draws total) took 2 seconds.\n</pre> In\u00a0[27]: Copied! <pre># Extract the posterior samples for the fertilizer effect\nnaive_effect = naive_trace.posterior[\"beta_fertilizer\"].values.flatten()\nadjusted_effect = adjusted_trace.posterior[\"beta_fertilizer\"].values.flatten()\n\n# Rescale effects to original units (undo standardization)\nstd_y = data[\"crop_yield\"].std()\nnaive_effect_rescaled = naive_effect * std_y\nadjusted_effect_rescaled = adjusted_effect * std_y\n\n# Plot the posterior distributions\nplt.figure(figsize=(12, 6))\nsns.kdeplot(naive_effect_rescaled, fill=True, label=\"Naive model\", alpha=0.7)\nsns.kdeplot(\n    adjusted_effect_rescaled, fill=True, label=\"Adjusted model\", alpha=0.7\n)\nplt.axvline(x=true_effect_fertilizer, color=\"k\", linestyle=\"--\", label=\"True causal effect\")\nplt.title(\"Posterior distributions\")\nplt.xlabel(\"Effect on crop yield\")\nplt.ylabel(\"Density\")\nplt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n\n# Calculate summary statistics\nprint(\n    \"Naive model effect estimate: {:.2f} (95% CI: [{:.2f}, {:.2f}])\".format(\n        naive_effect_rescaled.mean(),\n        np.percentile(naive_effect_rescaled, 2.5),\n        np.percentile(naive_effect_rescaled, 97.5),\n    )\n)\nprint(\n    \"Adjusted model effect estimate: {:.2f} (95% CI: [{:.2f}, {:.2f}])\".format(\n        adjusted_effect_rescaled.mean(),\n        np.percentile(adjusted_effect_rescaled, 2.5),\n        np.percentile(adjusted_effect_rescaled, 97.5),\n    )\n)\nprint(\"True causal effect: {:.2f}\".format(true_effect_fertilizer))\n</pre> # Extract the posterior samples for the fertilizer effect naive_effect = naive_trace.posterior[\"beta_fertilizer\"].values.flatten() adjusted_effect = adjusted_trace.posterior[\"beta_fertilizer\"].values.flatten()  # Rescale effects to original units (undo standardization) std_y = data[\"crop_yield\"].std() naive_effect_rescaled = naive_effect * std_y adjusted_effect_rescaled = adjusted_effect * std_y  # Plot the posterior distributions plt.figure(figsize=(12, 6)) sns.kdeplot(naive_effect_rescaled, fill=True, label=\"Naive model\", alpha=0.7) sns.kdeplot(     adjusted_effect_rescaled, fill=True, label=\"Adjusted model\", alpha=0.7 ) plt.axvline(x=true_effect_fertilizer, color=\"k\", linestyle=\"--\", label=\"True causal effect\") plt.title(\"Posterior distributions\") plt.xlabel(\"Effect on crop yield\") plt.ylabel(\"Density\") plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))  # Calculate summary statistics print(     \"Naive model effect estimate: {:.2f} (95% CI: [{:.2f}, {:.2f}])\".format(         naive_effect_rescaled.mean(),         np.percentile(naive_effect_rescaled, 2.5),         np.percentile(naive_effect_rescaled, 97.5),     ) ) print(     \"Adjusted model effect estimate: {:.2f} (95% CI: [{:.2f}, {:.2f}])\".format(         adjusted_effect_rescaled.mean(),         np.percentile(adjusted_effect_rescaled, 2.5),         np.percentile(adjusted_effect_rescaled, 97.5),     ) ) print(\"True causal effect: {:.2f}\".format(true_effect_fertilizer)) <pre>Naive model effect estimate: 3.18 (95% CI: [2.72, 3.65])\nAdjusted model effect estimate: 4.94 (95% CI: [4.49, 5.39])\nTrue causal effect: 5.00\n</pre> In\u00a0[19]: Copied! <pre># Forest plot for naive model\naz.plot_forest(naive_trace, var_names=['alpha', 'beta_fertilizer', 'sigma'], \n               figsize=(10, 4), combined=True)\nplt.title('Naive Model Parameters')\nplt.show()\n\n# Forest plot for adjusted model\naz.plot_forest(adjusted_trace, var_names=['alpha', 'beta_fertilizer', 'beta_pH', 'sigma'], \n               figsize=(10, 6), combined=True)\nplt.title('Adjusted Model Parameters')\nplt.show()\n\n# Summary statistics\nnaive_summary = az.summary(naive_trace, var_names=['alpha', 'beta_fertilizer', 'sigma'])\nadjusted_summary = az.summary(adjusted_trace, var_names=['alpha', 'beta_fertilizer', 'beta_pH', 'sigma'])\n\nprint(\"Naive Model Summary:\")\nprint(naive_summary)\nprint(\"\\nAdjusted Model Summary:\")\nprint(adjusted_summary)\n</pre> # Forest plot for naive model az.plot_forest(naive_trace, var_names=['alpha', 'beta_fertilizer', 'sigma'],                 figsize=(10, 4), combined=True) plt.title('Naive Model Parameters') plt.show()  # Forest plot for adjusted model az.plot_forest(adjusted_trace, var_names=['alpha', 'beta_fertilizer', 'beta_pH', 'sigma'],                 figsize=(10, 6), combined=True) plt.title('Adjusted Model Parameters') plt.show()  # Summary statistics naive_summary = az.summary(naive_trace, var_names=['alpha', 'beta_fertilizer', 'sigma']) adjusted_summary = az.summary(adjusted_trace, var_names=['alpha', 'beta_fertilizer', 'beta_pH', 'sigma'])  print(\"Naive Model Summary:\") print(naive_summary) print(\"\\nAdjusted Model Summary:\") print(adjusted_summary) <pre>Naive Model Summary:\n                  mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\nalpha           -0.372  0.041  -0.448   -0.296      0.001    0.000    4207.0   \nbeta_fertilizer  0.768  0.058   0.659    0.875      0.001    0.001    4012.0   \nsigma            0.925  0.021   0.887    0.964      0.000    0.000    6365.0   \n\n                 ess_tail  r_hat  \nalpha              4981.0    1.0  \nbeta_fertilizer    5245.0    1.0  \nsigma              5527.0    1.0  \n\nAdjusted Model Summary:\n                  mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\nalpha           -0.577  0.037  -0.645   -0.508        0.0      0.0   13007.0   \nbeta_fertilizer  1.192  0.055   1.092    1.300        0.0      0.0   12421.0   \nbeta_pH         -0.515  0.028  -0.566   -0.463        0.0      0.0   15403.0   \nsigma            0.797  0.018   0.764    0.830        0.0      0.0   16281.0   \n\n                 ess_tail  r_hat  \nalpha             14019.0    1.0  \nbeta_fertilizer   13486.0    1.0  \nbeta_pH           15852.0    1.0  \nsigma             14313.0    1.0  \n</pre>"},{"location":"notebooks/fertilizer_and_crop_yield/#fertilizer-and-crop-yield","title":"Fertilizer and crop yield\u00b6","text":"<p>We'll explore how not controlling for confounders affects our estimates in a Bayesian regression scenario. More specifically, the posterior distribution of the parameters is shown to be biased.</p> <p>Causal Model:</p> <ul> <li>Treatment (F): Fertilizer use (binary: 0 or 1)</li> <li>Outcome (C): Crop yield (continuous)</li> <li>Confounder (pH): Soil pH level (continuous)</li> </ul>"},{"location":"notebooks/fertilizer_and_crop_yield/#define-the-simulation-mechanism","title":"Define the simulation mechanism\u00b6","text":"<p>We'll define a data-generating process where:</p> <ol> <li>pH affects both fertilizer use and crop yield</li> <li>Fertilizer affects crop yield</li> </ol> <p>This creates a classic confounding scenario where pH is a common cause of both treatment and outcome.</p>"},{"location":"notebooks/fertilizer_and_crop_yield/#explore-the-data","title":"Explore the data\u00b6","text":""},{"location":"notebooks/fertilizer_and_crop_yield/#bayesian-linear-regression","title":"Bayesian linear regression\u00b6","text":"<p>Now we'll implement two Bayesian linear regression models:</p> <ol> <li>Naive model: Ignores the confounder (pH)</li> <li>Adjusted model: Controls for the confounder (pH)</li> </ol> <p>We'll compare how well each model recovers the true causal effect of fertilizer on crop yield.</p>"},{"location":"notebooks/fertilizer_and_crop_yield/#compare-results","title":"Compare results\u00b6","text":"<p>Now we'll examine the posterior distributions of the fertilizer effect from both models and compare them to the true causal effect.</p>"},{"location":"notebooks/fertilizer_and_crop_yield/#explore-the-full-posterior-distributions","title":"Explore the full posterior distributions\u00b6","text":""},{"location":"notebooks/fertilizer_and_crop_yield/#conclusions","title":"Conclusions\u00b6","text":"<p>From our analysis, we can draw the following conclusions:</p> <ol> <li><p>Naive model (ignoring pH): When we ignore the confounder (soil pH), our estimate of the fertilizer effect is biased. The posterior distribution of the effect does not correctly center on the true causal effect.</p> </li> <li><p>Adjusted model (controlling for pH): When we control for the confounder, our estimate is much closer to the true causal effect, and the true value falls within our credible interval.</p> </li> </ol> <p>So... controlling for confounders is essential for obtaining unbiased estimates of causal effects. When we ignore confounders, we get a misleading picture of the relationship between treatment and outcome.</p>"},{"location":"notebooks/medical_treatment/","title":"Causal Inference Example: Medication Effect on Blood Pressure","text":"In\u00a0[1]: Copied! <pre># Import required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Set plot style\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_context(\"talk\")\n</pre> # Import required libraries import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns import statsmodels.api as sm from statsmodels.formula.api import ols  # Set random seed for reproducibility np.random.seed(42)  # Set plot style plt.style.use('seaborn-v0_8-whitegrid') sns.set_context(\"talk\") In\u00a0[2]: Copied! <pre>def generate_medical_data(n_samples=1000, true_effect_medication=3, random_seed=None):\n    \"\"\"\n    Generate synthetic medical data with a known causal structure.\n    \n    Parameters:\n    - n_samples: Number of patients\n    - true_effect_medication: True causal effect of medication on BP reduction\n    - random_seed: Seed for random number generation\n    \n    Returns:\n    - DataFrame with age, medication_dose, and bp_reduction\n    \"\"\"\n    if random_seed is not None:\n        np.random.seed(random_seed)\n    \n    # Generate patient ages (the confounder)\n    age = np.random.normal(loc=50, scale=10, size=n_samples)\n    \n    # Generate medication dosage (treatment) influenced by age\n    # Older patients tend to get higher doses\n    age_effect_on_med = 0.05  # Slope of age effect on medication\n    med_base = 2  # Base medication level\n    med_noise = np.random.normal(0, 0.5, n_samples)\n    medication_dose = med_base + age_effect_on_med * (age - 50) + med_noise\n    \n    # Generate blood pressure reduction (outcome) influenced by both age and medication\n    # Age has a negative effect (older patients see less reduction)\n    age_effect_on_bp = -0.1  # Slope of age effect on BP reduction\n    bp_base = 10  # Base BP reduction\n    bp_noise = np.random.normal(0, 1, n_samples)\n    bp_reduction = (bp_base + \n                   age_effect_on_bp * (age - 50) + \n                   true_effect_medication * medication_dose + \n                   bp_noise)\n    \n    # Create DataFrame\n    data = pd.DataFrame({\n        'age': age,\n        'medication_dose': medication_dose,\n        'bp_reduction': bp_reduction\n    })\n    \n    return data, true_effect_medication\n\n# Generate our synthetic data\ndata, true_effect = generate_medical_data(n_samples=1000, true_effect_medication=3)\n\n# Display the first few rows\ndata.head()\n</pre> def generate_medical_data(n_samples=1000, true_effect_medication=3, random_seed=None):     \"\"\"     Generate synthetic medical data with a known causal structure.          Parameters:     - n_samples: Number of patients     - true_effect_medication: True causal effect of medication on BP reduction     - random_seed: Seed for random number generation          Returns:     - DataFrame with age, medication_dose, and bp_reduction     \"\"\"     if random_seed is not None:         np.random.seed(random_seed)          # Generate patient ages (the confounder)     age = np.random.normal(loc=50, scale=10, size=n_samples)          # Generate medication dosage (treatment) influenced by age     # Older patients tend to get higher doses     age_effect_on_med = 0.05  # Slope of age effect on medication     med_base = 2  # Base medication level     med_noise = np.random.normal(0, 0.5, n_samples)     medication_dose = med_base + age_effect_on_med * (age - 50) + med_noise          # Generate blood pressure reduction (outcome) influenced by both age and medication     # Age has a negative effect (older patients see less reduction)     age_effect_on_bp = -0.1  # Slope of age effect on BP reduction     bp_base = 10  # Base BP reduction     bp_noise = np.random.normal(0, 1, n_samples)     bp_reduction = (bp_base +                     age_effect_on_bp * (age - 50) +                     true_effect_medication * medication_dose +                     bp_noise)          # Create DataFrame     data = pd.DataFrame({         'age': age,         'medication_dose': medication_dose,         'bp_reduction': bp_reduction     })          return data, true_effect_medication  # Generate our synthetic data data, true_effect = generate_medical_data(n_samples=1000, true_effect_medication=3)  # Display the first few rows data.head() Out[2]: age medication_dose bp_reduction 0 54.967142 2.948035 17.672212 1 48.617357 2.393185 17.173300 2 56.476885 2.353659 15.620870 3 65.230299 2.438047 15.483148 4 47.658466 2.232035 15.036644 In\u00a0[3]: Copied! <pre># Plot distributions and relationships\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\n# Plot age distribution\nsns.histplot(data=data, x='age', kde=True, ax=axes[0, 0])\naxes[0, 0].set_title('Distribution of Patient Age')\n\n# Plot relationship between age and medication dose\nsns.scatterplot(data=data, x='age', y='medication_dose', ax=axes[0, 1])\naxes[0, 1].set_title('Medication Dose vs Age')\n\n# Plot relationship between medication dose and BP reduction\nsns.scatterplot(data=data, x='medication_dose', y='bp_reduction', ax=axes[1, 0])\naxes[1, 0].set_title('BP Reduction vs Medication Dose')\n\n# Plot relationship between age and BP reduction\nsns.scatterplot(data=data, x='age', y='bp_reduction', ax=axes[1, 1])\naxes[1, 1].set_title('BP Reduction vs Age')\n\nplt.tight_layout()\nplt.show()\n\n# Calculate correlation matrix\ncorrelation = data.corr()\nprint(\"Correlation Matrix:\")\nprint(correlation)\n</pre> # Plot distributions and relationships fig, axes = plt.subplots(2, 2, figsize=(15, 12))  # Plot age distribution sns.histplot(data=data, x='age', kde=True, ax=axes[0, 0]) axes[0, 0].set_title('Distribution of Patient Age')  # Plot relationship between age and medication dose sns.scatterplot(data=data, x='age', y='medication_dose', ax=axes[0, 1]) axes[0, 1].set_title('Medication Dose vs Age')  # Plot relationship between medication dose and BP reduction sns.scatterplot(data=data, x='medication_dose', y='bp_reduction', ax=axes[1, 0]) axes[1, 0].set_title('BP Reduction vs Medication Dose')  # Plot relationship between age and BP reduction sns.scatterplot(data=data, x='age', y='bp_reduction', ax=axes[1, 1]) axes[1, 1].set_title('BP Reduction vs Age')  plt.tight_layout() plt.show()  # Calculate correlation matrix correlation = data.corr() print(\"Correlation Matrix:\") print(correlation) <pre>Correlation Matrix:\n                      age  medication_dose  bp_reduction\nage              1.000000         0.685715      0.245466\nmedication_dose  0.685715         1.000000      0.756641\nbp_reduction     0.245466         0.756641      1.000000\n</pre> In\u00a0[4]: Copied! <pre># 1. Naive model (ignoring the confounder)\nnaive_model = ols('bp_reduction ~ medication_dose', data=data).fit()\nprint(\"Naive Model Summary (ignoring age):\")\nprint(naive_model.summary().tables[1])  # Just print the coefficients table\n\n# 2. Adjusted model (controlling for the confounder)\nadjusted_model = ols('bp_reduction ~ medication_dose + age', data=data).fit()\nprint(\"\\nAdjusted Model Summary (controlling for age):\")\nprint(adjusted_model.summary().tables[1])  # Just print the coefficients table\n\n# Extract and compare the medication coefficient estimates\nnaive_effect = naive_model.params['medication_dose']\nnaive_ci = naive_model.conf_int().loc['medication_dose']\n\nadjusted_effect = adjusted_model.params['medication_dose']\nadjusted_ci = adjusted_model.conf_int().loc['medication_dose']\n\nprint(\"\\nComparison of Estimates:\")\nprint(f\"True causal effect: {true_effect:.2f}\")\nprint(f\"Naive estimate: {naive_effect:.2f} (95% CI: [{naive_ci[0]:.2f}, {naive_ci[1]:.2f}])\")\nprint(f\"Adjusted estimate: {adjusted_effect:.2f} (95% CI: [{adjusted_ci[0]:.2f}, {adjusted_ci[1]:.2f}])\")\n</pre> # 1. Naive model (ignoring the confounder) naive_model = ols('bp_reduction ~ medication_dose', data=data).fit() print(\"Naive Model Summary (ignoring age):\") print(naive_model.summary().tables[1])  # Just print the coefficients table  # 2. Adjusted model (controlling for the confounder) adjusted_model = ols('bp_reduction ~ medication_dose + age', data=data).fit() print(\"\\nAdjusted Model Summary (controlling for age):\") print(adjusted_model.summary().tables[1])  # Just print the coefficients table  # Extract and compare the medication coefficient estimates naive_effect = naive_model.params['medication_dose'] naive_ci = naive_model.conf_int().loc['medication_dose']  adjusted_effect = adjusted_model.params['medication_dose'] adjusted_ci = adjusted_model.conf_int().loc['medication_dose']  print(\"\\nComparison of Estimates:\") print(f\"True causal effect: {true_effect:.2f}\") print(f\"Naive estimate: {naive_effect:.2f} (95% CI: [{naive_ci[0]:.2f}, {naive_ci[1]:.2f}])\") print(f\"Adjusted estimate: {adjusted_effect:.2f} (95% CI: [{adjusted_ci[0]:.2f}, {adjusted_ci[1]:.2f}])\") <pre>Naive Model Summary (ignoring age):\n===================================================================================\n                      coef    std err          t      P&gt;|t|      [0.025      0.975]\n-----------------------------------------------------------------------------------\nIntercept          11.9697      0.120     99.947      0.000      11.735      12.205\nmedication_dose     2.0302      0.056     36.559      0.000       1.921       2.139\n===================================================================================\n\nAdjusted Model Summary (controlling for age):\n===================================================================================\n                      coef    std err          t      P&gt;|t|      [0.025      0.975]\n-----------------------------------------------------------------------------------\nIntercept          14.8869      0.164     90.680      0.000      14.565      15.209\nmedication_dose     2.9796      0.062     47.687      0.000       2.857       3.102\nage                -0.0968      0.004    -22.158      0.000      -0.105      -0.088\n===================================================================================\n\nComparison of Estimates:\nTrue causal effect: 3.00\nNaive estimate: 2.03 (95% CI: [1.92, 2.14])\nAdjusted estimate: 2.98 (95% CI: [2.86, 3.10])\n</pre> In\u00a0[5]: Copied! <pre># Create a plot to compare estimates\nplt.figure(figsize=(10, 6))\n\n# Plot the estimates with confidence intervals\nmodels = ['Naive Model', 'Adjusted Model', 'True Effect']\nestimates = [naive_effect, adjusted_effect, true_effect]\nlower_ci = [naive_ci[0], adjusted_ci[0], true_effect]  # No CI for true effect\nupper_ci = [naive_ci[1], adjusted_ci[1], true_effect]  # No CI for true effect\nerrors = [(est - low, up - est) for est, low, up in zip(estimates, lower_ci, upper_ci)]\n\n# Convert errors to the format expected by plt.errorbar\nlower_errors = [errors[i][0] for i in range(len(errors))]\nupper_errors = [errors[i][1] for i in range(len(errors))]\nasymmetric_errors = [lower_errors, upper_errors]\n\nplt.errorbar(models, estimates, yerr=asymmetric_errors, fmt='o', capsize=10, \n             markersize=10, elinewidth=2, capthick=2)\n\nplt.axhline(y=true_effect, color='r', linestyle='--', alpha=0.5, label='True Effect')\nplt.ylabel('Effect of Medication Dose on BP Reduction')\nplt.title('Comparison of Estimated Causal Effects')\nplt.grid(True, axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n</pre> # Create a plot to compare estimates plt.figure(figsize=(10, 6))  # Plot the estimates with confidence intervals models = ['Naive Model', 'Adjusted Model', 'True Effect'] estimates = [naive_effect, adjusted_effect, true_effect] lower_ci = [naive_ci[0], adjusted_ci[0], true_effect]  # No CI for true effect upper_ci = [naive_ci[1], adjusted_ci[1], true_effect]  # No CI for true effect errors = [(est - low, up - est) for est, low, up in zip(estimates, lower_ci, upper_ci)]  # Convert errors to the format expected by plt.errorbar lower_errors = [errors[i][0] for i in range(len(errors))] upper_errors = [errors[i][1] for i in range(len(errors))] asymmetric_errors = [lower_errors, upper_errors]  plt.errorbar(models, estimates, yerr=asymmetric_errors, fmt='o', capsize=10,               markersize=10, elinewidth=2, capthick=2)  plt.axhline(y=true_effect, color='r', linestyle='--', alpha=0.5, label='True Effect') plt.ylabel('Effect of Medication Dose on BP Reduction') plt.title('Comparison of Estimated Causal Effects') plt.grid(True, axis='y', linestyle='--', alpha=0.7) plt.tight_layout() plt.show() In\u00a0[6]: Copied! <pre># Test with different sample sizes\nsample_sizes = [100, 500, 1000, 5000]\nnaive_estimates = []\nadjusted_estimates = []\n\nfor size in sample_sizes:\n    # Generate data with this sample size\n    sample_data, _ = generate_medical_data(n_samples=size, true_effect_medication=true_effect, random_seed=42)\n    \n    # Fit naive model\n    naive = ols('bp_reduction ~ medication_dose', data=sample_data).fit()\n    naive_estimates.append(naive.params['medication_dose'])\n    \n    # Fit adjusted model\n    adjusted = ols('bp_reduction ~ medication_dose + age', data=sample_data).fit()\n    adjusted_estimates.append(adjusted.params['medication_dose'])\n\n# Plot the results\nplt.figure(figsize=(10, 6))\nplt.plot(sample_sizes, naive_estimates, 'o-', label='Naive Model')\nplt.plot(sample_sizes, adjusted_estimates, 's-', label='Adjusted Model')\nplt.axhline(y=true_effect, color='r', linestyle='--', label='True Effect')\nplt.xscale('log')\nplt.xlabel('Sample Size (log scale)')\nplt.ylabel('Estimated Effect')\nplt.title('Effect Estimates vs. Sample Size')\nplt.legend()\nplt.grid(True, which=\"both\", linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n</pre> # Test with different sample sizes sample_sizes = [100, 500, 1000, 5000] naive_estimates = [] adjusted_estimates = []  for size in sample_sizes:     # Generate data with this sample size     sample_data, _ = generate_medical_data(n_samples=size, true_effect_medication=true_effect, random_seed=42)          # Fit naive model     naive = ols('bp_reduction ~ medication_dose', data=sample_data).fit()     naive_estimates.append(naive.params['medication_dose'])          # Fit adjusted model     adjusted = ols('bp_reduction ~ medication_dose + age', data=sample_data).fit()     adjusted_estimates.append(adjusted.params['medication_dose'])  # Plot the results plt.figure(figsize=(10, 6)) plt.plot(sample_sizes, naive_estimates, 'o-', label='Naive Model') plt.plot(sample_sizes, adjusted_estimates, 's-', label='Adjusted Model') plt.axhline(y=true_effect, color='r', linestyle='--', label='True Effect') plt.xscale('log') plt.xlabel('Sample Size (log scale)') plt.ylabel('Estimated Effect') plt.title('Effect Estimates vs. Sample Size') plt.legend() plt.grid(True, which=\"both\", linestyle='--', alpha=0.7) plt.tight_layout() plt.show()"},{"location":"notebooks/medical_treatment/#causal-inference-example-medication-effect-on-blood-pressure","title":"Causal Inference Example: Medication Effect on Blood Pressure\u00b6","text":"<p>This notebook demonstrates a simple causal inference example using synthetic medical data and ordinary least squares regression. We'll explore how controlling for confounders leads to unbiased estimates of causal effects.</p> <p>Causal Model:</p> <ul> <li>Treatment (M): Medication dosage (continuous)</li> <li>Outcome (BP): Blood pressure reduction (continuous)</li> <li>Confounder (A): Patient age (continuous)</li> </ul> <p>We'll define a true data-generating process with a linear relationship, then estimate the causal effect both with and without controlling for the confounder.</p>"},{"location":"notebooks/medical_treatment/#1-define-the-true-causal-model","title":"1. Define the True Causal Model\u00b6","text":"<p>We'll create a separate function to generate our synthetic data. The true data-generating process is:</p> <ol> <li>Age affects both medication dosage and blood pressure reduction</li> <li>Medication affects blood pressure reduction</li> <li>The true causal effect of medication on blood pressure reduction is known</li> </ol> <p>This creates a classic confounding scenario where age is a common cause of both treatment and outcome.</p>"},{"location":"notebooks/medical_treatment/#2-explore-the-data","title":"2. Explore the Data\u00b6","text":"<p>Let's visualize the relationships between our variables to understand the confounding structure.</p>"},{"location":"notebooks/medical_treatment/#3-linear-regression-models","title":"3. Linear Regression Models\u00b6","text":"<p>Now we'll implement two linear regression models:</p> <ol> <li>Naive model: Ignores the confounder (age)</li> <li>Adjusted model: Controls for the confounder (age)</li> </ol> <p>We'll compare how well each model recovers the true causal effect of medication on blood pressure reduction.</p>"},{"location":"notebooks/medical_treatment/#4-visualize-the-estimates","title":"4. Visualize the Estimates\u00b6","text":"<p>Let's create a plot to compare the estimates from both models with the true causal effect.</p>"},{"location":"notebooks/medical_treatment/#5-testing-robustness-varying-the-sample-size","title":"5. Testing Robustness: Varying the Sample Size\u00b6","text":"<p>Let's see how the estimates change with different sample sizes.</p>"},{"location":"notebooks/medical_treatment/#6-conclusions","title":"6. Conclusions\u00b6","text":"<p>From our analysis, we can draw the following conclusions:</p> <ol> <li><p>Naive model (ignoring age): When we ignore the confounder (patient age), our estimate of the medication effect is biased. We get an incorrect estimate of the causal effect.</p> </li> <li><p>Adjusted model (controlling for age): When we control for the confounder, our estimate is much closer to the true causal effect.</p> </li> </ol> <p>This example demonstrates a key principle in causal inference: controlling for confounders is essential for obtaining unbiased estimates of causal effects. When we ignore confounders, we get a misleading picture of the relationship between treatment and outcome.</p> <p>In this medical example, age affects both the medication dosage that patients receive and their blood pressure response directly. Without accounting for age, we cannot separate the direct effect of medication from the indirect relationship through age.</p>"},{"location":"notebooks/plot_style/","title":"Plot style","text":"In\u00a0[\u00a0]: Copied! In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nfrom cycler import cycler\n</pre> import matplotlib.pyplot as plt from cycler import cycler In\u00a0[\u00a0]: Copied! <pre>plt.rcParams['axes.prop_cycle'] = cycler('color', ['lightblue', 'lightgreen', 'coral'])\n</pre> plt.rcParams['axes.prop_cycle'] = cycler('color', ['lightblue', 'lightgreen', 'coral']) In\u00a0[\u00a0]: Copied! <pre>line_params = {\n    'color': 'gray',\n    'linewidth': 2,\n    'linestyle': '--',\n}\n</pre> line_params = {     'color': 'gray',     'linewidth': 2,     'linestyle': '--', } In\u00a0[\u00a0]: Copied! <pre>scatter_params = {\n    's': 50,\n    'color': 'lightblue',\n    'edgecolors': 'gray',\n    'alpha': 0.8\n}\n</pre> scatter_params = {     's': 50,     'color': 'lightblue',     'edgecolors': 'gray',     'alpha': 0.8 }"},{"location":"notebooks/shap_example/","title":"SHAP explanations","text":"In\u00a0[1]: Copied! <pre>import warnings\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport shap\nfrom sklearn.exceptions import ConvergenceWarning\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neural_network import MLPRegressor\n\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n</pre> import warnings  import matplotlib.pyplot as plt import numpy as np import pandas as pd import shap from sklearn.exceptions import ConvergenceWarning from sklearn.metrics import mean_squared_error from sklearn.model_selection import train_test_split from sklearn.neural_network import MLPRegressor  warnings.filterwarnings(\"ignore\", category=ConvergenceWarning) <pre>/Users/emiliomaddalena/Documents/github/causal-inference-studies/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n</pre> In\u00a0[7]: Copied! <pre>np.random.seed(42)\nn_samples = 1000\n\nX1 = np.random.uniform(0, 10, n_samples)\nX2 = np.random.uniform(0, 10, n_samples)\nX3 = np.random.uniform(0, 10, n_samples)\n\n\n# Define the target with a non-linear relationship\ndef f(X1, X2, X3):\n    return 5 * X1**2 - 10 * X2 + 5 * X3\n\nY = f(X1, X2, X3) + np.random.normal(0, 2, n_samples)\nX = pd.DataFrame({\"X1\": X1, \"X2\": X2, \"X3\": X3})\n</pre> np.random.seed(42) n_samples = 1000  X1 = np.random.uniform(0, 10, n_samples) X2 = np.random.uniform(0, 10, n_samples) X3 = np.random.uniform(0, 10, n_samples)   # Define the target with a non-linear relationship def f(X1, X2, X3):     return 5 * X1**2 - 10 * X2 + 5 * X3  Y = f(X1, X2, X3) + np.random.normal(0, 2, n_samples) X = pd.DataFrame({\"X1\": X1, \"X2\": X2, \"X3\": X3}) In\u00a0[8]: Copied! <pre>X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n\nmlp = MLPRegressor(\n    hidden_layer_sizes=(32, 16),\n    activation=\"relu\",\n    max_iter=1,\n    warm_start=True,\n    random_state=42,\n)\nn_epochs = 10000\n\ntest_losses = []\ntrain_losses = []\nfor epoch in range(n_epochs):\n    mlp.fit(X_train, y_train)\n    train_losses.append(mean_squared_error(y_train, mlp.predict(X_train)))\n    test_losses.append(mean_squared_error(y_test, mlp.predict(X_test)))\n    if (epoch + 1) % 5000 == 0:\n        print(f\"Epoch {epoch+1}, Training MSE: {test_losses[-1]:.4f}\")\n\nplt.plot(test_losses, label=\"Test Loss\")\nplt.plot(train_losses, label=\"Train Loss\")\nplt.legend()\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Test MSE\")\nplt.title(\"Test Loss Across Epochs\")\nplt.yscale(\"log\")\nplt.show()\n</pre> X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)  mlp = MLPRegressor(     hidden_layer_sizes=(32, 16),     activation=\"relu\",     max_iter=1,     warm_start=True,     random_state=42, ) n_epochs = 10000  test_losses = [] train_losses = [] for epoch in range(n_epochs):     mlp.fit(X_train, y_train)     train_losses.append(mean_squared_error(y_train, mlp.predict(X_train)))     test_losses.append(mean_squared_error(y_test, mlp.predict(X_test)))     if (epoch + 1) % 5000 == 0:         print(f\"Epoch {epoch+1}, Training MSE: {test_losses[-1]:.4f}\")  plt.plot(test_losses, label=\"Test Loss\") plt.plot(train_losses, label=\"Train Loss\") plt.legend() plt.xlabel(\"Epoch\") plt.ylabel(\"Test MSE\") plt.title(\"Test Loss Across Epochs\") plt.yscale(\"log\") plt.show() <pre>Epoch 5000, Training MSE: 16.7202\nEpoch 10000, Training MSE: 13.3218\n</pre> In\u00a0[9]: Copied! <pre>idxs = np.random.choice(len(X_test), size=40, replace=False)\nX_sample = X_test.iloc[idxs]\ny_true = f(X_sample[\"X1\"], X_sample[\"X2\"], X_sample[\"X3\"])\ny_pred = mlp.predict(X_sample)\n\n#plt.figure(figsize=(6, 6))\nplt.scatter(y_true, y_pred, alpha=0.7)\nplt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', label='Ideal')\nplt.xlabel(\"True Values\")\nplt.ylabel(\"Predicted Values\")\nplt.title(\"True vs Predicted Values\")\nplt.grid()\n</pre> idxs = np.random.choice(len(X_test), size=40, replace=False) X_sample = X_test.iloc[idxs] y_true = f(X_sample[\"X1\"], X_sample[\"X2\"], X_sample[\"X3\"]) y_pred = mlp.predict(X_sample)  #plt.figure(figsize=(6, 6)) plt.scatter(y_true, y_pred, alpha=0.7) plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', label='Ideal') plt.xlabel(\"True Values\") plt.ylabel(\"Predicted Values\") plt.title(\"True vs Predicted Values\") plt.grid() In\u00a0[10]: Copied! <pre># Create a SHAP explainer\nexplainer = shap.Explainer(mlp.predict, X)\nshap_values = explainer(X)\n</pre> # Create a SHAP explainer explainer = shap.Explainer(mlp.predict, X) shap_values = explainer(X) In\u00a0[11]: Copied! <pre># Explain the output number 20\ni = 20\nprint(shap_values[i].data)\nshap.plots.waterfall(shap_values[i])\n\nshap.initjs()\nshap.force_plot(shap_values.base_values[i], shap_values.values[i], feature_names=['X1', 'X2', 'X3'])\n</pre> # Explain the output number 20 i = 20 print(shap_values[i].data) shap.plots.waterfall(shap_values[i])  shap.initjs() shap.force_plot(shap_values.base_values[i], shap_values.values[i], feature_names=['X1', 'X2', 'X3']) <pre>[6.11852895 6.97420267 9.63394434]\n</pre> Out[11]: Visualization omitted, Javascript library not loaded!   Have you run `initjs()` in this notebook? If this notebook was from another   user you must also trust this notebook (File -&gt; Trust notebook). If you are viewing   this notebook on github the Javascript has been stripped for security. If you are using   JupyterLab this error is because a JupyterLab extension has not yet been written.  In\u00a0[12]: Copied! <pre># Explain all of the examples\nshap.summary_plot(shap_values, X)\n</pre> # Explain all of the examples shap.summary_plot(shap_values, X) <pre>/var/folders/pt/2bxzkxcx2199r7zn3rhd3qt40000gn/T/ipykernel_26835/3448107941.py:2: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n  shap.summary_plot(shap_values, X)\n</pre>"},{"location":"notebooks/shap_example/#shap-explanations","title":"SHAP explanations\u00b6","text":"<p>In this notebook we use SHAP to explain the predictions of a NN model.</p> <p>Interpretability is important in many fields. With SHAP we can decompose the value of a prediction $f(x)$ into components, assigning them each of the features $x_i$.</p> <p>SHAP is a great tool because it is model agnostic. It doesn't require a closed-form description of your model, but only being able to call/evaluate it at different locations!</p>"},{"location":"notebooks/shap_example/#generate-synthetic-data","title":"Generate synthetic data\u00b6","text":""},{"location":"notebooks/shap_example/#train-a-simple-nn-regressor","title":"Train a simple NN regressor\u00b6","text":""},{"location":"notebooks/shap_example/#assess-performance-on-the-test-set","title":"Assess performance on the test set\u00b6","text":""},{"location":"notebooks/shap_example/#explain-the-model-with-shap","title":"Explain the model with SHAP\u00b6","text":""},{"location":"notebooks/shap_example/#conclusions","title":"Conclusions\u00b6","text":"<p>SHAP is very cool, but what exactly can we conclude from its outputs?</p> <p>It sheds some light on which features are more important than others from a high-level perspective - that's for sure. $x_1$ seems to have a larger impact on the predictions compared to $x_2$ or $x_3$...</p> <p>\u26a0\ufe0f Question: Can we interpret these insights causally?</p> <p>\ud83d\udeab Answer: No, we can't!</p> <p>If the model wasn't built in a causal way, it is still confounded, no matter what type of explainability tool you throw at it...</p>"},{"location":"notebooks/sharks_and_ice_creams/","title":"Sharks and ice cream","text":"<p>A confounding variable can induce association between variables that are not causally linked. To tackle this problem, you have to control for all confounders, that is, include them in your model.</p> In\u00a0[2]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nfrom plot_style import line_params, scatter_params\n</pre> import matplotlib.pyplot as plt import numpy as np import pandas as pd import statsmodels.api as sm from plot_style import line_params, scatter_params In\u00a0[3]: Copied! <pre>np.random.seed(42)\nn = 300\n\n# Temperature is indedependent and influences both variables\ntemp = np.random.uniform(10, 30, size=n)  # Temperature in degrees Celsius\nice_sales = 10 * temp + np.random.normal(0, 10, size=n)\nshark_attacks = 0.5 * temp + np.random.normal(0, 2, size=n)\n\ndf = pd.DataFrame({\"temp\": temp, \"ice_sales\": ice_sales, \"shark_attacks\": shark_attacks})\n\n# Scatter plot: ice_sales vs. shark_attacks with naive regression line\nplt.scatter(df[\"ice_sales\"], df[\"shark_attacks\"], **scatter_params)\nplt.xlabel(\"ice cream sales\")\nplt.ylabel(\"shark attacks\")\n\n# Naive correlation between ice cream sales and shark attacks\ncorr = df[\"ice_sales\"].corr(df[\"shark_attacks\"])\nprint(f\"Correlation between variables = {corr:.3f}. Very high!\")\n</pre> np.random.seed(42) n = 300  # Temperature is indedependent and influences both variables temp = np.random.uniform(10, 30, size=n)  # Temperature in degrees Celsius ice_sales = 10 * temp + np.random.normal(0, 10, size=n) shark_attacks = 0.5 * temp + np.random.normal(0, 2, size=n)  df = pd.DataFrame({\"temp\": temp, \"ice_sales\": ice_sales, \"shark_attacks\": shark_attacks})  # Scatter plot: ice_sales vs. shark_attacks with naive regression line plt.scatter(df[\"ice_sales\"], df[\"shark_attacks\"], **scatter_params) plt.xlabel(\"ice cream sales\") plt.ylabel(\"shark attacks\")  # Naive correlation between ice cream sales and shark attacks corr = df[\"ice_sales\"].corr(df[\"shark_attacks\"]) print(f\"Correlation between variables = {corr:.3f}. Very high!\") <pre>Correlation between variables = 0.801. Very high!\n</pre> In\u00a0[\u00a0]: Copied! <pre># Naive regression\nX1 = sm.add_constant(df['ice_sales'])\nmodel1 = sm.OLS(df['shark_attacks'], X1).fit()\n\nprint(\"\\nNaive regression (shark_attacks ~ ice_sales):\")\nprint(model1.summary())\n\nx_vals = np.linspace(df[\"ice_sales\"].min(), df[\"ice_sales\"].max(), 100)\ny_vals = model1.params['const'] + model1.params[\"ice_sales\"] * x_vals\nplt.plot(x_vals, y_vals, **line_params)\nplt.scatter(df[\"ice_sales\"], df[\"shark_attacks\"], **scatter_params)\nplt.xlabel(\"ice cream sales\")\nplt.ylabel(\"shark attacks\")\n</pre> # Naive regression X1 = sm.add_constant(df['ice_sales']) model1 = sm.OLS(df['shark_attacks'], X1).fit()  print(\"\\nNaive regression (shark_attacks ~ ice_sales):\") print(model1.summary())  x_vals = np.linspace(df[\"ice_sales\"].min(), df[\"ice_sales\"].max(), 100) y_vals = model1.params['const'] + model1.params[\"ice_sales\"] * x_vals plt.plot(x_vals, y_vals, **line_params) plt.scatter(df[\"ice_sales\"], df[\"shark_attacks\"], **scatter_params) plt.xlabel(\"ice cream sales\") plt.ylabel(\"shark attacks\") <pre>\nNaive regression (shark_attacks ~ ice_sales):\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:          shark_attacks   R-squared:                       0.642\nModel:                            OLS   Adj. R-squared:                  0.641\nMethod:                 Least Squares   F-statistic:                     534.0\nDate:                Tue, 26 Aug 2025   Prob (F-statistic):           2.09e-68\nTime:                        07:17:17   Log-Likelihood:                -637.45\nNo. Observations:                 300   AIC:                             1279.\nDf Residuals:                     298   BIC:                             1286.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          1.0371      0.404      2.566      0.011       0.242       1.832\nice_sales      0.0449      0.002     23.108      0.000       0.041       0.049\n==============================================================================\nOmnibus:                        0.251   Durbin-Watson:                   2.087\nProb(Omnibus):                  0.882   Jarque-Bera (JB):                0.299\nSkew:                           0.069   Prob(JB):                        0.861\nKurtosis:                       2.929   Cond. No.                         716.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n</pre> Out[\u00a0]: <pre>Text(0, 0.5, 'shark attacks')</pre> In\u00a0[\u00a0]: Copied! <pre># Fit linear model\nX2 = sm.add_constant(df[[\"ice_sales\", \"temp\"]])\nmodel2 = sm.OLS(df[\"shark_attacks\"], X2).fit()\n\nprint(\"\\nRegression (shark_attacks ~ ice_sales, temp):\")\nprint(model2.summary())\n\n# Prepare grid for regression plane\nice_grid, temp_grid = np.meshgrid(\n    np.linspace(df[\"ice_sales\"].min(), df[\"ice_sales\"].max(), 30),\n    np.linspace(df[\"temp\"].min(), df[\"temp\"].max(), 30),\n)\nshark_pred = (\n    model2.params[\"const\"]\n    + model2.params[\"ice_sales\"] * ice_grid\n    + model2.params[\"temp\"] * temp_grid\n)\n\n# 3D plot\nfig = plt.figure()\nax = fig.add_subplot(111, projection=\"3d\")\nax.scatter(\n    df[\"ice_sales\"],\n    df[\"temp\"],\n    df[\"shark_attacks\"],\n    **scatter_params\n)\nax.plot_surface(ice_grid, temp_grid, shark_pred, color=\"gray\", alpha=0.5)\nax.set_xlabel(\"ice cream sales\")\nax.set_ylabel(\"temperature\")\nax.set_zlabel(\"shark attacks\")\n</pre> # Fit linear model X2 = sm.add_constant(df[[\"ice_sales\", \"temp\"]]) model2 = sm.OLS(df[\"shark_attacks\"], X2).fit()  print(\"\\nRegression (shark_attacks ~ ice_sales, temp):\") print(model2.summary())  # Prepare grid for regression plane ice_grid, temp_grid = np.meshgrid(     np.linspace(df[\"ice_sales\"].min(), df[\"ice_sales\"].max(), 30),     np.linspace(df[\"temp\"].min(), df[\"temp\"].max(), 30), ) shark_pred = (     model2.params[\"const\"]     + model2.params[\"ice_sales\"] * ice_grid     + model2.params[\"temp\"] * temp_grid )  # 3D plot fig = plt.figure() ax = fig.add_subplot(111, projection=\"3d\") ax.scatter(     df[\"ice_sales\"],     df[\"temp\"],     df[\"shark_attacks\"],     **scatter_params ) ax.plot_surface(ice_grid, temp_grid, shark_pred, color=\"gray\", alpha=0.5) ax.set_xlabel(\"ice cream sales\") ax.set_ylabel(\"temperature\") ax.set_zlabel(\"shark attacks\")  <pre>\nRegression (shark_attacks ~ ice_sales, temp):\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:          shark_attacks   R-squared:                       0.662\nModel:                            OLS   Adj. R-squared:                  0.660\nMethod:                 Least Squares   F-statistic:                     291.0\nDate:                Tue, 26 Aug 2025   Prob (F-statistic):           1.06e-70\nTime:                        07:32:23   Log-Likelihood:                -628.71\nNo. Observations:                 300   AIC:                             1263.\nDf Residuals:                     297   BIC:                             1275.\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          0.6378      0.404      1.577      0.116      -0.158       1.434\nice_sales     -0.0033      0.012     -0.287      0.775      -0.026       0.019\ntemp           0.5022      0.119      4.222      0.000       0.268       0.736\n==============================================================================\nOmnibus:                        0.106   Durbin-Watson:                   2.077\nProb(Omnibus):                  0.948   Jarque-Bera (JB):                0.182\nSkew:                           0.041   Prob(JB):                        0.913\nKurtosis:                       2.911   Cond. No.                         742.\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n</pre> Out[\u00a0]: <pre>Text(0.5, 0, 'shark attacks')</pre> In\u00a0[\u00a0]: Copied! <pre>import plotly.graph_objs as go\n\n# Scatter points\nscatter = go.Scatter3d(\n    x=df[\"ice_sales\"],\n    y=df[\"temp\"],\n    z=df[\"shark_attacks\"],\n    mode=\"markers\",\n    marker=dict(size=4, color=\"lightblue\", line=dict(width=0.5, color=\"gray\")),\n    name=\"Data\",\n)\n\n# Regression plane\nsurface = go.Surface(\n    x=ice_grid,\n    y=temp_grid,\n    z=shark_pred,\n    opacity=0.5,\n    colorscale=\"Greys\",\n    name=\"Regression Plane\",\n    showscale=False,\n)\n\nfig = go.Figure(data=[scatter, surface])\nfig.update_layout(\n    scene=dict(\n        xaxis_title=\"ice cream sales\", yaxis_title=\"temperature\", zaxis_title=\"shark attacks\"\n    ),\n    margin=dict(l=0, r=0, b=0, t=0),\n)\n</pre> import plotly.graph_objs as go  # Scatter points scatter = go.Scatter3d(     x=df[\"ice_sales\"],     y=df[\"temp\"],     z=df[\"shark_attacks\"],     mode=\"markers\",     marker=dict(size=4, color=\"lightblue\", line=dict(width=0.5, color=\"gray\")),     name=\"Data\", )  # Regression plane surface = go.Surface(     x=ice_grid,     y=temp_grid,     z=shark_pred,     opacity=0.5,     colorscale=\"Greys\",     name=\"Regression Plane\",     showscale=False, )  fig = go.Figure(data=[scatter, surface]) fig.update_layout(     scene=dict(         xaxis_title=\"ice cream sales\", yaxis_title=\"temperature\", zaxis_title=\"shark attacks\"     ),     margin=dict(l=0, r=0, b=0, t=0), ) In\u00a0[\u00a0]: Copied! <pre># 5. Partial regression plot: residuals after removing temperature effect\nice_model = sm.OLS(df['ice_sales'], sm.add_constant(df['temp'])).fit()\nshark_model = sm.OLS(df['shark_attacks'], sm.add_constant(df['temp'])).fit()\nres_ice = pd.Series(ice_model.resid, name='res_ice')\nres_shark = pd.Series(shark_model.resid, name='res_shark')\nres_df = pd.DataFrame({'res_ice': res_ice, 'res_shark': res_shark})\n\n# Fit regression on residuals\npartial_model = sm.OLS(res_df['res_shark'], sm.add_constant(res_df['res_ice'])).fit()\nprint(partial_model.summary())\n\nplt.figure()\nplt.scatter(res_df['res_ice'], res_df['res_shark'], **scatter_params)\nx_vals2 = np.linspace(res_df['res_ice'].min(), res_df['res_ice'].max(), 100)\ny_vals2 = partial_model.params['const'] + partial_model.params['res_ice'] * x_vals2\nplt.plot(x_vals2, y_vals2, **line_params)\nplt.xlabel('residual ice cream sales')\nplt.ylabel('residual shark attacks')\nplt.title('including temperature')\n</pre> # 5. Partial regression plot: residuals after removing temperature effect ice_model = sm.OLS(df['ice_sales'], sm.add_constant(df['temp'])).fit() shark_model = sm.OLS(df['shark_attacks'], sm.add_constant(df['temp'])).fit() res_ice = pd.Series(ice_model.resid, name='res_ice') res_shark = pd.Series(shark_model.resid, name='res_shark') res_df = pd.DataFrame({'res_ice': res_ice, 'res_shark': res_shark})  # Fit regression on residuals partial_model = sm.OLS(res_df['res_shark'], sm.add_constant(res_df['res_ice'])).fit() print(partial_model.summary())  plt.figure() plt.scatter(res_df['res_ice'], res_df['res_shark'], **scatter_params) x_vals2 = np.linspace(res_df['res_ice'].min(), res_df['res_ice'].max(), 100) y_vals2 = partial_model.params['const'] + partial_model.params['res_ice'] * x_vals2 plt.plot(x_vals2, y_vals2, **line_params) plt.xlabel('residual ice cream sales') plt.ylabel('residual shark attacks') plt.title('including temperature') <pre>                            OLS Regression Results                            \n==============================================================================\nDep. Variable:              res_shark   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.003\nMethod:                 Least Squares   F-statistic:                   0.08246\nDate:                Tue, 26 Aug 2025   Prob (F-statistic):              0.774\nTime:                        07:36:36   Log-Likelihood:                -628.71\nNo. Observations:                 300   AIC:                             1261.\nDf Residuals:                     298   BIC:                             1269.\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst      -7.536e-15      0.114  -6.61e-14      1.000      -0.224       0.224\nres_ice       -0.0033      0.012     -0.287      0.774      -0.026       0.019\n==============================================================================\nOmnibus:                        0.106   Durbin-Watson:                   2.077\nProb(Omnibus):                  0.948   Jarque-Bera (JB):                0.182\nSkew:                           0.041   Prob(JB):                        0.913\nKurtosis:                       2.911   Cond. No.                         9.86\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n</pre> Out[\u00a0]: <pre>Text(0.5, 1.0, 'including temperature')</pre>"},{"location":"notebooks/sharks_and_ice_creams/#sharks-and-ice-cream","title":"Sharks and ice cream\u00b6","text":""},{"location":"notebooks/sharks_and_ice_creams/#define-the-simulation-mechanism","title":"Define the simulation mechanism\u00b6","text":"<p>The variables here are: ice cream sales, shark attacks, and temperature.</p> <p>We assume the causal structure: temperature affects ice cream (TEMP \u2192 ICE), and temperature affects shark attacks (TEMP \u2192 SHARK).</p>"},{"location":"notebooks/sharks_and_ice_creams/#train-model-1","title":"Train model 1\u00b6","text":"<p>The first model predicts shark_attacks from ice_sales</p>"},{"location":"notebooks/sharks_and_ice_creams/#train-model-2","title":"Train model 2\u00b6","text":"<p>The second model predicts shark_attacks from ice_sales and temperature</p>"},{"location":"notebooks/sharks_and_ice_creams/#visualize-fit-in-3d","title":"Visualize fit in 3D\u00b6","text":"<p>(Doesn't render on a browser, but it's a cool visual)</p>"},{"location":"notebooks/sharks_and_ice_creams/#check-residual-model","title":"Check residual model\u00b6","text":"<p>Train a model on the residuals</p>"},{"location":"notebooks/sharks_and_ice_creams/#conclusion","title":"Conclusion\u00b6","text":"<p>We know ice cream sales have nothing to do with shark attack rates... but training a model on these two variables will suggest there is! \ud83e\udd88\ud83c\udf68</p> <p>Next time you train a model and want to use it to make better decisions, be careful. If your goal is to change X to affect Y, make sure you didn't forget to include any confounders in your analysis.</p>"},{"location":"notebooks/sleeping_pills/","title":"Sleeping pills","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\n\nRANDOM_STATE = 123\nnp.random.seed(RANDOM_STATE)\n</pre> import matplotlib.pyplot as plt import numpy as np import pandas as pd from sklearn.ensemble import RandomForestRegressor from sklearn.metrics import mean_squared_error from sklearn.model_selection import train_test_split  RANDOM_STATE = 123 np.random.seed(RANDOM_STATE) In\u00a0[2]: Copied! <pre>def generate_age(n):\n    \"\"\"Age of the subjects.\n    \n    Subjects will be uniformily distributed, centered around 18 years of age.\n    \"\"\"\n    return np.random.uniform(18, 90, size=n)\n\ndef baseline_quality(age):\n    \"\"\"Baseline sleep quality as a function of age.\n    \n    The sleep quality without any intervention.\n    \"\"\"\n    return 4.0 - 0.04 * (age - 40) - 0.4 * np.sin(1e-1*(age - 40))\n\ndef true_cate(age):\n    \"\"\"Pill effect as a function of age.\n    \n    The true (nonlinear) CATE: A bell-shaped function that yields little to no effect \n    until the age of 40. Then a positive effect, peaking at 70. Followed by reducing \n    effectiveness until the age of 90.\n    \"\"\"\n    return 1.5 * np.exp(-((age - 70) ** 2) / (2 * 12 ** 2))\n\ndef propensity(age):\n    \"\"\"How likely people are to use the pill.\n\n    Older people are more likely to make use of the drug.\n    \"\"\"\n    return 0.05 + 0.4 / (1 + np.exp(-(age - 55) / 10.0))\n\ndef measurement_noise(n):\n    \"\"\"Measurement noise.\"\"\"\n    return np.random.normal(scale=0.25, size=n)\n</pre> def generate_age(n):     \"\"\"Age of the subjects.          Subjects will be uniformily distributed, centered around 18 years of age.     \"\"\"     return np.random.uniform(18, 90, size=n)  def baseline_quality(age):     \"\"\"Baseline sleep quality as a function of age.          The sleep quality without any intervention.     \"\"\"     return 4.0 - 0.04 * (age - 40) - 0.4 * np.sin(1e-1*(age - 40))  def true_cate(age):     \"\"\"Pill effect as a function of age.          The true (nonlinear) CATE: A bell-shaped function that yields little to no effect      until the age of 40. Then a positive effect, peaking at 70. Followed by reducing      effectiveness until the age of 90.     \"\"\"     return 1.5 * np.exp(-((age - 70) ** 2) / (2 * 12 ** 2))  def propensity(age):     \"\"\"How likely people are to use the pill.      Older people are more likely to make use of the drug.     \"\"\"     return 0.05 + 0.4 / (1 + np.exp(-(age - 55) / 10.0))  def measurement_noise(n):     \"\"\"Measurement noise.\"\"\"     return np.random.normal(scale=0.25, size=n) In\u00a0[3]: Copied! <pre># Visualize the true relationships\n\nages = np.linspace(18, 90, 300)\nbaseline = baseline_quality(ages)\ntrue_effects = true_cate(ages)\npropensities = propensity(ages)\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 3, 1)\nplt.plot(ages, baseline, label=\"Sleep quality\", color=\"black\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Sleep quality\")\nplt.title(\"Baseline quality of sleep\")\nplt.grid()\nplt.subplot(1, 3, 2)\nplt.plot(ages, true_effects, label=\"True CATE\", color=\"blue\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"CATE\")\nplt.title(\"True treatment effect\")\nplt.grid()\nplt.subplot(1, 3, 3)\nplt.plot(ages, propensities, label=\"Propensity\", color=\"orange\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"Propensity\")\nplt.title(\"Propensity score\")\nplt.grid()\nplt.tight_layout()\n</pre> # Visualize the true relationships  ages = np.linspace(18, 90, 300) baseline = baseline_quality(ages) true_effects = true_cate(ages) propensities = propensity(ages) plt.figure(figsize=(12, 5)) plt.subplot(1, 3, 1) plt.plot(ages, baseline, label=\"Sleep quality\", color=\"black\") plt.xlabel(\"Age\") plt.ylabel(\"Sleep quality\") plt.title(\"Baseline quality of sleep\") plt.grid() plt.subplot(1, 3, 2) plt.plot(ages, true_effects, label=\"True CATE\", color=\"blue\") plt.xlabel(\"Age\") plt.ylabel(\"CATE\") plt.title(\"True treatment effect\") plt.grid() plt.subplot(1, 3, 3) plt.plot(ages, propensities, label=\"Propensity\", color=\"orange\") plt.xlabel(\"Age\") plt.ylabel(\"Propensity\") plt.title(\"Propensity score\") plt.grid() plt.tight_layout() In\u00a0[4]: Copied! <pre># Generate data\nn = 3000\nage = generate_age(n)\ntrue_effect = true_cate(age)\nbaseline = baseline_quality(age)\nepsilon = measurement_noise(n)\np = propensity(age)\n\nT = np.random.binomial(1, p)\nY = baseline + T * true_effect + epsilon\n\ndf = pd.DataFrame({\"age\": age, \"T\": T, \"Y\": Y, \"true_effect\": true_effect, \"propensity\": p})\ndf.head()\n</pre> # Generate data n = 3000 age = generate_age(n) true_effect = true_cate(age) baseline = baseline_quality(age) epsilon = measurement_noise(n) p = propensity(age)  T = np.random.binomial(1, p) Y = baseline + T * true_effect + epsilon  df = pd.DataFrame({\"age\": age, \"T\": T, \"Y\": Y, \"true_effect\": true_effect, \"propensity\": p}) df.head() Out[4]: age T Y true_effect propensity 0 68.145781 0 2.774833 1.482200 0.365311 1 38.602032 0 4.087382 0.048920 0.114997 2 34.333305 1 4.760301 0.018105 0.094952 3 57.694663 1 3.766806 0.886651 0.276785 4 69.801766 1 4.303596 1.499795 0.375840 In\u00a0[5]: Copied! <pre>plt.figure(figsize=(8, 6))\nplt.scatter(\n    df.loc[df[\"T\"] == 0, \"age\"],\n    df.loc[df[\"T\"] == 0, \"Y\"],\n    c=\"blue\",\n    alpha=0.5,\n    label=\"Don't take the pill\",\n)\nplt.scatter(\n    df.loc[df[\"T\"] == 1, \"age\"],\n    df.loc[df[\"T\"] == 1, \"Y\"],\n    c=\"red\",\n    alpha=0.5,\n    label=\"Take the pill\",\n)\nplt.legend()\nplt.xlabel(\"Age\")\nplt.ylabel(\"Sleep quality (Y)\")\nplt.title(\"The observational data available\")\nplt.grid()\n</pre> plt.figure(figsize=(8, 6)) plt.scatter(     df.loc[df[\"T\"] == 0, \"age\"],     df.loc[df[\"T\"] == 0, \"Y\"],     c=\"blue\",     alpha=0.5,     label=\"Don't take the pill\", ) plt.scatter(     df.loc[df[\"T\"] == 1, \"age\"],     df.loc[df[\"T\"] == 1, \"Y\"],     c=\"red\",     alpha=0.5,     label=\"Take the pill\", ) plt.legend() plt.xlabel(\"Age\") plt.ylabel(\"Sleep quality (Y)\") plt.title(\"The observational data available\") plt.grid() In\u00a0[6]: Copied! <pre>plt.figure(figsize=(18, 5))\nplt.subplot(1, 3, 1)\nplt.hist(df[\"age\"], bins=30, color=\"gray\", edgecolor=\"black\", alpha=0.7)\nplt.xlabel(\"Age\")\nplt.ylabel(\"Num of subjects\")\nplt.title(\"Age distribution\")\nplt.subplot(1, 3, 2)\nplt.hist(df[\"Y\"], bins=30, color=\"gray\", edgecolor=\"black\",alpha=0.7)\nplt.xlabel(\"Sleep quality (Y)\")\nplt.ylabel(\"Num of subjects\")\nplt.title(\"Sleep quality (Y)\")\nplt.subplot(1, 3, 3)\nplt.hist(df[\"T\"], bins=2, color=\"gray\", edgecolor=\"black\",alpha=0.7)\nplt.xticks([0, 1])\nplt.xlabel(\"Treatment (T)\")\nplt.ylabel(\"Num of subjects\")\nplt.title(\"Treatment distribution\")\n</pre> plt.figure(figsize=(18, 5)) plt.subplot(1, 3, 1) plt.hist(df[\"age\"], bins=30, color=\"gray\", edgecolor=\"black\", alpha=0.7) plt.xlabel(\"Age\") plt.ylabel(\"Num of subjects\") plt.title(\"Age distribution\") plt.subplot(1, 3, 2) plt.hist(df[\"Y\"], bins=30, color=\"gray\", edgecolor=\"black\",alpha=0.7) plt.xlabel(\"Sleep quality (Y)\") plt.ylabel(\"Num of subjects\") plt.title(\"Sleep quality (Y)\") plt.subplot(1, 3, 3) plt.hist(df[\"T\"], bins=2, color=\"gray\", edgecolor=\"black\",alpha=0.7) plt.xticks([0, 1]) plt.xlabel(\"Treatment (T)\") plt.ylabel(\"Num of subjects\") plt.title(\"Treatment distribution\") Out[6]: <pre>Text(0.5, 1.0, 'Treatment distribution')</pre> In\u00a0[70]: Copied! <pre># Split the data\ntest_frac = 0.3\ntrain, test = train_test_split(df, test_size=test_frac, random_state=RANDOM_STATE)\n\n# Extract numpy arrays\nX_train = train[\"age\"].values.reshape(-1, 1)\nX_test = test[\"age\"].values.reshape(-1, 1)\nT_train = train[\"T\"].values.reshape(-1, 1)\nT_test = test[\"T\"].values.reshape(-1, 1)\nY_train = train[\"Y\"].values.reshape(-1)\nY_test = test[\"Y\"].values.reshape(-1)\n</pre> # Split the data test_frac = 0.3 train, test = train_test_split(df, test_size=test_frac, random_state=RANDOM_STATE)  # Extract numpy arrays X_train = train[\"age\"].values.reshape(-1, 1) X_test = test[\"age\"].values.reshape(-1, 1) T_train = train[\"T\"].values.reshape(-1, 1) T_test = test[\"T\"].values.reshape(-1, 1) Y_train = train[\"Y\"].values.reshape(-1) Y_test = test[\"Y\"].values.reshape(-1) In\u00a0[73]: Copied! <pre># These will  be shared by all metalearners\nregularization_params = {\n    \"max_depth\": 20, # limit depth to avoid overfitting\n    \"n_estimators\": 500, # number of trees in the forest\n    \"min_samples_leaf\": 20, # minimum samples per leaf to avoid overfitting\n}\n\n# S-learner: single model regarding treatment as just another feature\ns_model = RandomForestRegressor(random_state=RANDOM_STATE, **regularization_params)\nX_train_aug = np.concatenate([X_train, T_train], axis=1)\ns_model.fit(X_train_aug, Y_train)\n\n# Set T=1, then and T=0 and compute the difference between the values\nX_test_t1 = np.concatenate([X_test, np.ones_like(X_test)], axis=1)\nX_test_t0 = np.concatenate([X_test, np.zeros_like(X_test)], axis=1)\ncate_s = s_model.predict(X_test_t1) - s_model.predict(X_test_t0)\n\n# T-learner: two separate models trained on treated and control groups independently\nmodel_treated = RandomForestRegressor(random_state=RANDOM_STATE, **regularization_params)\nmodel_control = RandomForestRegressor(random_state=RANDOM_STATE, **regularization_params)\n\n# Get the relevant data for each group\nX_train_treated = X_train[T_train[:, 0] == 1].reshape(-1, 1)\nX_train_control = X_train[T_train[:, 0] == 0].reshape(-1, 1)\nY_train_treated = Y_train[T_train[:, 0] == 1]\nY_train_control = Y_train[T_train[:, 0] == 0]\nmodel_treated.fit(X_train_treated, Y_train_treated)\nmodel_control.fit(X_train_control, Y_train_control)\n\n# Predict potential outcomes on test set\ncate_t = model_treated.predict(X_test) - model_control.predict(X_test)\n</pre> # These will  be shared by all metalearners regularization_params = {     \"max_depth\": 20, # limit depth to avoid overfitting     \"n_estimators\": 500, # number of trees in the forest     \"min_samples_leaf\": 20, # minimum samples per leaf to avoid overfitting }  # S-learner: single model regarding treatment as just another feature s_model = RandomForestRegressor(random_state=RANDOM_STATE, **regularization_params) X_train_aug = np.concatenate([X_train, T_train], axis=1) s_model.fit(X_train_aug, Y_train)  # Set T=1, then and T=0 and compute the difference between the values X_test_t1 = np.concatenate([X_test, np.ones_like(X_test)], axis=1) X_test_t0 = np.concatenate([X_test, np.zeros_like(X_test)], axis=1) cate_s = s_model.predict(X_test_t1) - s_model.predict(X_test_t0)  # T-learner: two separate models trained on treated and control groups independently model_treated = RandomForestRegressor(random_state=RANDOM_STATE, **regularization_params) model_control = RandomForestRegressor(random_state=RANDOM_STATE, **regularization_params)  # Get the relevant data for each group X_train_treated = X_train[T_train[:, 0] == 1].reshape(-1, 1) X_train_control = X_train[T_train[:, 0] == 0].reshape(-1, 1) Y_train_treated = Y_train[T_train[:, 0] == 1] Y_train_control = Y_train[T_train[:, 0] == 0] model_treated.fit(X_train_treated, Y_train_treated) model_control.fit(X_train_control, Y_train_control)  # Predict potential outcomes on test set cate_t = model_treated.predict(X_test) - model_control.predict(X_test) In\u00a0[75]: Copied! <pre># 5) Evaluation: compare estimated CATE to true CATE on test set\ntrue_cate_test = test[\"true_effect\"].values\n\npehe_s = np.sqrt(mean_squared_error(true_cate_test, cate_s))  # root PEHE for S-learner\npehe_t = np.sqrt(mean_squared_error(true_cate_test, cate_t))  # root PEHE for T-learner\n\n# ATE estimates\nate_true = np.mean(true_cate_test)\nate_s = np.mean(cate_s)\nate_t = np.mean(cate_t)\n\nprint(f\"PEHE (S-learner): {pehe_s:.4f}\")\nprint(f\"PEHE (T-learner): {pehe_t:.4f}\")\nprint(f\"ATE true: {ate_true:.4f}, S-learner ATE: {ate_s:.4f}, T-learner ATE: {ate_t:.4f}\")\n\n# 6) Visualization\n# Sort test points by age for smooth plotting\norder = np.argsort(X_test[:, 0])\nage_sorted = X_test[order, 0]\ntrue_sorted = true_cate_test[order]\ncate_s_sorted = cate_s[order]\ncate_t_sorted = cate_t[order]\n\nplt.figure(figsize=(10, 6))\nplt.plot(age_sorted, true_sorted, label=\"True CATE\", linewidth=3)\nplt.plot(age_sorted, cate_s_sorted, label=\"S-learner estimated CATE\", linestyle=\"--\")\nplt.plot(age_sorted, cate_t_sorted, label=\"T-learner estimated CATE\", linestyle=\":\")\nplt.xlabel(\"Age\")\nplt.ylabel(\"CATE (effect of treatment on quality of sleep)\")\nplt.title(\"True vs Estimated CATE as a function of age\")\nplt.legend()\nplt.grid()\n\n# Scatter of individual estimates vs true\nmin_val, max_val = -0.2, 1.5\nplt.figure(figsize=(7, 7))\nplt.scatter(true_cate_test, cate_s, alpha=0.3, label=\"S-learner\", s=20)\nplt.scatter(true_cate_test, cate_t, alpha=0.3, label=\"T-learner\", s=20)\nplt.plot([min_val, max_val], [min_val, max_val], 'k--')\nplt.xlim([min_val, max_val])\nplt.ylim([min_val, max_val])\nplt.title(\"Individual treatment effects\")\nplt.xlabel(\"True ITEs\")\nplt.ylabel(\"Estimated ITEs\")\nplt.legend()\nplt.grid()\n</pre> # 5) Evaluation: compare estimated CATE to true CATE on test set true_cate_test = test[\"true_effect\"].values  pehe_s = np.sqrt(mean_squared_error(true_cate_test, cate_s))  # root PEHE for S-learner pehe_t = np.sqrt(mean_squared_error(true_cate_test, cate_t))  # root PEHE for T-learner  # ATE estimates ate_true = np.mean(true_cate_test) ate_s = np.mean(cate_s) ate_t = np.mean(cate_t)  print(f\"PEHE (S-learner): {pehe_s:.4f}\") print(f\"PEHE (T-learner): {pehe_t:.4f}\") print(f\"ATE true: {ate_true:.4f}, S-learner ATE: {ate_s:.4f}, T-learner ATE: {ate_t:.4f}\")  # 6) Visualization # Sort test points by age for smooth plotting order = np.argsort(X_test[:, 0]) age_sorted = X_test[order, 0] true_sorted = true_cate_test[order] cate_s_sorted = cate_s[order] cate_t_sorted = cate_t[order]  plt.figure(figsize=(10, 6)) plt.plot(age_sorted, true_sorted, label=\"True CATE\", linewidth=3) plt.plot(age_sorted, cate_s_sorted, label=\"S-learner estimated CATE\", linestyle=\"--\") plt.plot(age_sorted, cate_t_sorted, label=\"T-learner estimated CATE\", linestyle=\":\") plt.xlabel(\"Age\") plt.ylabel(\"CATE (effect of treatment on quality of sleep)\") plt.title(\"True vs Estimated CATE as a function of age\") plt.legend() plt.grid()  # Scatter of individual estimates vs true min_val, max_val = -0.2, 1.5 plt.figure(figsize=(7, 7)) plt.scatter(true_cate_test, cate_s, alpha=0.3, label=\"S-learner\", s=20) plt.scatter(true_cate_test, cate_t, alpha=0.3, label=\"T-learner\", s=20) plt.plot([min_val, max_val], [min_val, max_val], 'k--') plt.xlim([min_val, max_val]) plt.ylim([min_val, max_val]) plt.title(\"Individual treatment effects\") plt.xlabel(\"True ITEs\") plt.ylabel(\"Estimated ITEs\") plt.legend() plt.grid() <pre>PEHE (S-learner): 0.0731\nPEHE (T-learner): 0.1145\nATE true: 0.5793, S-learner ATE: 0.5468, T-learner ATE: 0.5567\n</pre>"},{"location":"notebooks/sleeping_pills/#sleeping-pills","title":"Sleeping pills\u00b6","text":"<p>A pharma company just designed a new pill to help you sleep. They got data, but it doesn't come from a randomized control trial. They want to know: Does the drug work? Does it help people of different ages equally or differently?</p> <p>We will make use of the S-learner and the T-learner approaches to estimate the drug's conditional treatment effect (CATE), and try to answer those questions rigorously. The underlying ML model used in both cases will be random forests.</p> <p>Here's our causal model:</p> <ul> <li>Treatment (pill): taking or not taking the new med (binary: 0 or 1)</li> <li>Outcome (qual): the quality of sleep (continuous)</li> <li>Feature/Confounder (age): The age of the subject (discrete)</li> </ul>"},{"location":"notebooks/sleeping_pills/#define-the-simulation-mechanism","title":"Define the simulation mechanism\u00b6","text":"<p>Here we define the age of our subjects, how well people sleep normally (under no medication) as a function of age, and how the pill actually helps them.</p> <p>We also define the tendency of people of different ages to take this med, and how noisy our measuring mechanism is when it comes to assessing people's sleep quality.</p> <p>\u26a0\ufe0f The pill effect varies depending on the person's age, i.e., it has a heterogeneous effect.</p> <p>\u26a0\ufe0f The fact that older people are more likely to take the pill makes age a confounder!</p>"},{"location":"notebooks/sleeping_pills/#generate-and-explore-the-data","title":"Generate and explore the data\u00b6","text":""},{"location":"notebooks/sleeping_pills/#train-metalearners-using-random-forest-models","title":"Train metalearners using random forest models\u00b6","text":"<p>An S-learner is a straightforward approach that regards the treatment as being just another feature. So in this case you concatenate <code>age</code> and <code>treatment</code> together and train your favorite model - That's it.</p> <p>The final CATE function is the difference between treating and not treating the subjects.</p> <p>A T-learner, in constrast, uses one model per treatment value. In this case we only have \"taking the pill\" and \"not taking it\", so very simple. For each case, we don't need the treatment variable anymore since it doesn't vary within that group. This leads us to only pass the <code>age</code> as the only feature for the models.</p> <p>The final CATE function is the difference between individual models.</p>"},{"location":"notebooks/sleeping_pills/#evaluate-the-two-approaches-based-on-different-metrics","title":"Evaluate the two approaches based on different metrics\u00b6","text":"<p>Performance is evaluated by inspecting the predicted ATE, the obtained CATE functions, and the ITEs on the test set.</p>"},{"location":"notebooks/sleeping_pills/#discussion","title":"Discussion\u00b6","text":"<p>Estimating CATEs amounts to estimating a function, a conditional expectation one.</p> <p>The S-learner and T-learner approaches to estimating CATEs are easy to understand and can be effective when the treatment is binary or discrete with only a few levels. In this notebook we were able to evaluate well our strategies because we had access to the ground-truth, but because of the fundamental problem of causal inference, true ITEs are never available!</p> <p>\u26a0\ufe0f After picking your favorite metalearner strategy, you still have to deal with training your model well, just like in classical ML!</p> <p>\u26a0\ufe0f Take your time considering issues like model selection, under/overfitting, hyperparameter tuning, feature selection, scaling, encoding, etc.</p>"},{"location":"notebooks/uplift_modelling/","title":"Uplift modelling","text":"<p>The business problem:</p> <p>We are concerted with giving or not giving users a 5% discount voucher.</p> <p>If we give it to everyone, we'll likely get more bookings, but at the same time we hurt our margins. So the best way to proceed is to give the coupons only to those customers that were unsure about the decision and that will actually convert after receiving it. Also, not giving the coupons to customers that were already going to book something no matter what!</p> <p>The causal problem:</p> <p>Our treatment $T$ is offering customers this coupon, a binary variable.</p> <p>Our outcome $Y$ is the customer finalizing their booking or not, also a binary variable.</p> <p>Additionally, we have access to a number of other variables $X$ characterizing the user, the channel that brough them to the platform, the specific ongoing session, and so on... We believe some of them could be valuable in deciding the effectiveness of the intervention. In other words, the effect isn't uniform but varies depending on some of these factors.</p> In\u00a0[1]: Copied! <pre>import warnings\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import mean_absolute_error, root_mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom uplift_modelling_utils import binned_validation, data_generating_process, uplift_curve\n\nnp.random.seed(111)\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.plotting_context(\"talk\", font_scale=1.2)\n</pre> import warnings  import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor from sklearn.linear_model import LogisticRegression from sklearn.metrics import mean_absolute_error, root_mean_squared_error from sklearn.model_selection import train_test_split from uplift_modelling_utils import binned_validation, data_generating_process, uplift_curve  np.random.seed(111) warnings.filterwarnings('ignore') plt.style.use('seaborn-v0_8-whitegrid') sns.plotting_context(\"talk\", font_scale=1.2) Out[1]: <pre>{'axes.linewidth': 1.875,\n 'grid.linewidth': 1.5,\n 'lines.linewidth': 2.25,\n 'lines.markersize': 9.0,\n 'patch.linewidth': 1.5,\n 'xtick.major.width': 1.875,\n 'ytick.major.width': 1.875,\n 'xtick.minor.width': 1.5,\n 'ytick.minor.width': 1.5,\n 'xtick.major.size': 9.0,\n 'ytick.major.size': 9.0,\n 'xtick.minor.size': 6.0,\n 'ytick.minor.size': 6.0,\n 'font.size': 21.599999999999998,\n 'axes.labelsize': 21.599999999999998,\n 'axes.titlesize': 21.599999999999998,\n 'xtick.labelsize': 19.8,\n 'ytick.labelsize': 19.8,\n 'legend.fontsize': 19.8,\n 'legend.title_fontsize': 21.599999999999998}</pre> In\u00a0[13]: Copied! <pre># Observational (targeted / unbalanced)\ndata, metadata = data_generating_process(20000, setting=\"observational\")\ndata.head()\n</pre> # Observational (targeted / unbalanced) data, metadata = data_generating_process(20000, setting=\"observational\") data.head() Out[13]: client_id Y T true_uplift channel device lead_time funnel_depth price_sort_used past_coupon_user tenure_days dest_tier hour_local recent_ad_exposure 0 0 0 0 0.039828 email mobile_web 45 0 0 1 449 tier1 11 1 1 1 0 0 0.196222 paid_search desktop 3 2 0 1 1178 tier2 13 0 2 2 1 1 0.420412 paid_search mobile_web 45 2 1 0 20 tier1 18 1 3 3 0 1 0.338939 paid_search mobile_web 21 1 1 0 575 tier2 19 0 4 4 0 0 0.436834 paid_search mobile_web 45 2 1 0 932 tier1 15 0 In\u00a0[14]: Copied! <pre># Quick sanity checks\nprint(\"Dataset:\")\nprint(\" n =\", len(data))\nprint(\" treat_rate =\", data[\"T\"].mean().round(4))\nprint(\" conv_rate_T1 =\", data.loc[data[\"T\"] == 1, \"Y\"].mean().round(4))\nprint(\" conv_rate_T0 =\", data.loc[data[\"T\"] == 0, \"Y\"].mean().round(4))\nprint(\" ATE (naive) =\", (data.loc[data[\"T\"] == 1, \"Y\"].mean() - data.loc[data[\"T\"] == 0, \"Y\"].mean()).round(4))\n</pre> # Quick sanity checks print(\"Dataset:\") print(\" n =\", len(data)) print(\" treat_rate =\", data[\"T\"].mean().round(4)) print(\" conv_rate_T1 =\", data.loc[data[\"T\"] == 1, \"Y\"].mean().round(4)) print(\" conv_rate_T0 =\", data.loc[data[\"T\"] == 0, \"Y\"].mean().round(4)) print(\" ATE (naive) =\", (data.loc[data[\"T\"] == 1, \"Y\"].mean() - data.loc[data[\"T\"] == 0, \"Y\"].mean()).round(4))  <pre>Dataset:\n n = 20000\n treat_rate = 0.1898\n conv_rate_T1 = 0.29\n conv_rate_T0 = 0.108\n ATE (naive) = 0.182\n</pre> In\u00a0[15]: Copied! <pre># One hot encode \"channel\" and \"device\"\ndata = pd.get_dummies(data, columns=[\"channel\", \"device\"], drop_first=True, dtype=int)\n# Ordinal encode \"dest_tier\"\ndata.loc[:, \"dest_tier\"] = data[\"dest_tier\"].map({\"tier1\": 1, \"tier2\": 2, \"tier3\": 3})\n\ndata\n</pre> # One hot encode \"channel\" and \"device\" data = pd.get_dummies(data, columns=[\"channel\", \"device\"], drop_first=True, dtype=int) # Ordinal encode \"dest_tier\" data.loc[:, \"dest_tier\"] = data[\"dest_tier\"].map({\"tier1\": 1, \"tier2\": 2, \"tier3\": 3})  data Out[15]: client_id Y T true_uplift lead_time funnel_depth price_sort_used past_coupon_user tenure_days dest_tier hour_local recent_ad_exposure channel_direct channel_email channel_organic channel_paid_search device_desktop device_mobile_web 0 0 0 0 0.039828 45 0 0 1 449 1 11 1 0 1 0 0 0 1 1 1 0 0 0.196222 3 2 0 1 1178 2 13 0 0 0 0 1 1 0 2 2 1 1 0.420412 45 2 1 0 20 1 18 1 0 0 0 1 0 1 3 3 0 1 0.338939 21 1 1 0 575 2 19 0 0 0 0 1 0 1 4 4 0 0 0.436834 45 2 1 0 932 1 15 0 0 0 0 1 0 1 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 19995 19995 1 0 0.390284 0 2 1 0 348 1 17 1 0 0 0 1 1 0 19996 19996 0 0 0.070274 7 1 1 1 1592 1 10 0 0 1 0 0 1 0 19997 19997 0 1 0.302809 30 1 0 0 1242 1 22 0 0 0 0 1 1 0 19998 19998 0 0 0.021376 90 0 0 0 474 3 15 0 0 0 1 0 1 0 19999 19999 0 0 0.135958 45 1 1 0 686 1 17 0 0 1 0 0 1 0 <p>20000 rows \u00d7 18 columns</p> In\u00a0[16]: Copied! <pre>def train_test_split_df(df: pd.DataFrame, features: list, test_size=0.25, seed=123):\n    x = df[features].values\n    y = df[\"Y\"].astype(float).values\n    t = df[\"T\"].astype(float).values\n    u = df[\"true_uplift\"].astype(float).values\n    return train_test_split(x, y, t, u, test_size=test_size, random_state=seed, stratify=t)\n\n\nX_train, X_test, y_train, y_test, t_train, t_test, u_train, u_test = train_test_split_df(\n    data,\n    features=[col for col in data.columns if col not in [\"client_id\", \"Y\", \"T\", \"true_uplift\"]],\n    test_size=0.25,\n)\n</pre> def train_test_split_df(df: pd.DataFrame, features: list, test_size=0.25, seed=123):     x = df[features].values     y = df[\"Y\"].astype(float).values     t = df[\"T\"].astype(float).values     u = df[\"true_uplift\"].astype(float).values     return train_test_split(x, y, t, u, test_size=test_size, random_state=seed, stratify=t)   X_train, X_test, y_train, y_test, t_train, t_test, u_train, u_test = train_test_split_df(     data,     features=[col for col in data.columns if col not in [\"client_id\", \"Y\", \"T\", \"true_uplift\"]],     test_size=0.25, ) <p>All learners map $R_x$ to $R$, a set of features $x$ to the predicted uplift, a continuous scalar value.</p> In\u00a0[17]: Copied! <pre>class TLearner:\n    \"\"\"A simple T-Learner implementation.\"\"\"\n\n    def __init__(self, model_factory=lambda: GradientBoostingClassifier(random_state=7)) -&gt; None:\n        \"\"\"Specify the model class (factory) to be used for the two models.\"\"\"\n        self.m1 = model_factory()\n        self.m0 = model_factory()\n\n    def fit(self, x: np.ndarray, t: np.ndarray, y: np.ndarray) -&gt; None:\n        \"\"\"Fit the control and treatment models.\"\"\"\n        self.m1.fit(x[t == 1], y[t == 1])\n        self.m0.fit(x[t == 0], y[t == 0])\n\n    def predict_uplift(self, x: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Predict the uplift (treatment effect) for each sample in x.\"\"\"\n        p1 = self.m1.predict_proba(x)[:, 1]\n        p0 = self.m0.predict_proba(x)[:, 1]\n        return p1 - p0\n\n# T-learner\nt_learner = TLearner()\nt_learner.fit(X_train, t_train, y_train)\n</pre> class TLearner:     \"\"\"A simple T-Learner implementation.\"\"\"      def __init__(self, model_factory=lambda: GradientBoostingClassifier(random_state=7)) -&gt; None:         \"\"\"Specify the model class (factory) to be used for the two models.\"\"\"         self.m1 = model_factory()         self.m0 = model_factory()      def fit(self, x: np.ndarray, t: np.ndarray, y: np.ndarray) -&gt; None:         \"\"\"Fit the control and treatment models.\"\"\"         self.m1.fit(x[t == 1], y[t == 1])         self.m0.fit(x[t == 0], y[t == 0])      def predict_uplift(self, x: np.ndarray) -&gt; np.ndarray:         \"\"\"Predict the uplift (treatment effect) for each sample in x.\"\"\"         p1 = self.m1.predict_proba(x)[:, 1]         p0 = self.m0.predict_proba(x)[:, 1]         return p1 - p0  # T-learner t_learner = TLearner() t_learner.fit(X_train, t_train, y_train) In\u00a0[18]: Copied! <pre>class XLearner:\n    \"\"\"A simple X-Learner implementation.\"\"\"\n\n    def __init__(\n        self,\n        clf_factory=lambda: GradientBoostingClassifier(random_state=7),\n        reg_factory=lambda: GradientBoostingRegressor(random_state=7),\n        prop_factory=lambda: LogisticRegression(max_iter=300),\n    ) -&gt; None:\n        \"\"\"Specify the model classes (factories) to be used.\"\"\"\n        self.m1 = clf_factory()\n        self.m0 = clf_factory()\n        self.g1 = reg_factory()\n        self.g0 = reg_factory()\n        self.prop = prop_factory()\n\n    def fit(self, x: np.ndarray, t: np.ndarray, y: np.ndarray) -&gt; None:\n        \"\"\"Fit the two outcome models, the two treatment effect models, and the propensity model.\"\"\"\n        self.m1.fit(x[t == 1], y[t == 1])\n        self.m0.fit(x[t == 0], y[t == 0])\n        \n        # Estimate unobserved counterfactuals\n        y1_t1 = y[t == 1]\n        y0_t1 = self.m0.predict_proba(x[t == 1])[:, 1]\n        tau_t1 = y1_t1 - y0_t1  \n        \n        y0_t0 = y[t == 0]\n        y1_t0 = self.m1.predict_proba(x[t == 0])[:, 1]\n        tau_t0 = y1_t0 - y0_t0 \n\n        self.g1.fit(x[t == 1], tau_t1)\n        self.g0.fit(x[t == 0], tau_t0)\n\n        self.prop.fit(x, t)\n\n    def predict_uplift(self, x: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Predict the uplift for a given set of features.\"\"\"\n        e = np.clip(self.prop.predict_proba(x)[:, 1], 1e-3, 1 - 1e-3)\n        tau1 = self.g1.predict(x)\n        tau0 = self.g0.predict(x)\n        return e * tau0 + (1.0 - e) * tau1\n    \nx_learner = XLearner()\nx_learner.fit(X_train, t_train, y_train)\n</pre> class XLearner:     \"\"\"A simple X-Learner implementation.\"\"\"      def __init__(         self,         clf_factory=lambda: GradientBoostingClassifier(random_state=7),         reg_factory=lambda: GradientBoostingRegressor(random_state=7),         prop_factory=lambda: LogisticRegression(max_iter=300),     ) -&gt; None:         \"\"\"Specify the model classes (factories) to be used.\"\"\"         self.m1 = clf_factory()         self.m0 = clf_factory()         self.g1 = reg_factory()         self.g0 = reg_factory()         self.prop = prop_factory()      def fit(self, x: np.ndarray, t: np.ndarray, y: np.ndarray) -&gt; None:         \"\"\"Fit the two outcome models, the two treatment effect models, and the propensity model.\"\"\"         self.m1.fit(x[t == 1], y[t == 1])         self.m0.fit(x[t == 0], y[t == 0])                  # Estimate unobserved counterfactuals         y1_t1 = y[t == 1]         y0_t1 = self.m0.predict_proba(x[t == 1])[:, 1]         tau_t1 = y1_t1 - y0_t1                    y0_t0 = y[t == 0]         y1_t0 = self.m1.predict_proba(x[t == 0])[:, 1]         tau_t0 = y1_t0 - y0_t0           self.g1.fit(x[t == 1], tau_t1)         self.g0.fit(x[t == 0], tau_t0)          self.prop.fit(x, t)      def predict_uplift(self, x: np.ndarray) -&gt; np.ndarray:         \"\"\"Predict the uplift for a given set of features.\"\"\"         e = np.clip(self.prop.predict_proba(x)[:, 1], 1e-3, 1 - 1e-3)         tau1 = self.g1.predict(x)         tau0 = self.g0.predict(x)         return e * tau0 + (1.0 - e) * tau1      x_learner = XLearner() x_learner.fit(X_train, t_train, y_train) In\u00a0[\u00a0]: Copied! <pre># Predict uplift on test\ntau_T = t_learner.predict_uplift(X_test)\ntau_X = x_learner.predict_uplift(X_test)\n\nuplift = pd.DataFrame(\n    {\n        \"u_true\": u_test,\n        \"tau_T\": tau_T,\n        \"tau_X\": tau_X,\n    }\n)\n</pre> # Predict uplift on test tau_T = t_learner.predict_uplift(X_test) tau_X = x_learner.predict_uplift(X_test)  uplift = pd.DataFrame(     {         \"u_true\": u_test,         \"tau_T\": tau_T,         \"tau_X\": tau_X,     } ) In\u00a0[57]: Copied! <pre>fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n\n# Scatter plot\naxes[0].scatter(\n    uplift[\"u_true\"],\n    uplift[\"tau_T\"],\n    alpha=0.3,\n    s=12,\n    label=\"T-learner\",\n)\naxes[0].scatter(\n    uplift[\"u_true\"],\n    uplift[\"tau_X\"],\n    alpha=0.3,\n    s=12,\n    label=\"X-learner\",\n)\nline = np.linspace(-0.6, 0.8, 100)\naxes[0].plot(line, line, ls=\"--\", c=\"gray\", lw=1.5, zorder=-2)\naxes[0].set_xlabel(\"True uplift (pointwise)\")\naxes[0].set_ylabel(\"Predicted uplift (pointwise)\")\naxes[0].set_title(\"Pointwise testing\")\naxes[0].legend(loc=\"best\")\naxes[0].set_xlim([-0.4, 0.8])\naxes[0].set_ylim([-0.4, 0.8])\n\n\n# Plot with shared bins (same groups across models)\ncal = binned_validation(\n    y_true=uplift[\"u_true\"].values,\n    scores={\n        \"T-learner\": uplift[\"tau_T\"].values,\n        \"X-learner\": uplift[\"tau_X\"].values,\n    },\n    n_bins=40,\n    bin_var=\"true\"\n)\nfor name, g in cal.groupby(\"model\"):\n    axes[1].plot(g[\"mean_true\"], g[\"mean_pred\"], \"o-\", label=name)\naxes[1].plot(line, line, ls=\"--\", c=\"gray\", lw=1.5, zorder=-2)\naxes[1].set_ylabel(\"Predicted uplift (bin mean)\")\naxes[1].set_xlabel(\"True uplift (bin mean)\")\naxes[1].set_title(\"Binned testing\")\naxes[1].legend(loc=\"best\")\naxes[1].set_xlim([-0.1, 0.5])\naxes[1].set_ylim([-0.1, 0.5])\n\nplt.tight_layout()\nplt.show()\n</pre> fig, axes = plt.subplots(1, 2, figsize=(10, 4))  # Scatter plot axes[0].scatter(     uplift[\"u_true\"],     uplift[\"tau_T\"],     alpha=0.3,     s=12,     label=\"T-learner\", ) axes[0].scatter(     uplift[\"u_true\"],     uplift[\"tau_X\"],     alpha=0.3,     s=12,     label=\"X-learner\", ) line = np.linspace(-0.6, 0.8, 100) axes[0].plot(line, line, ls=\"--\", c=\"gray\", lw=1.5, zorder=-2) axes[0].set_xlabel(\"True uplift (pointwise)\") axes[0].set_ylabel(\"Predicted uplift (pointwise)\") axes[0].set_title(\"Pointwise testing\") axes[0].legend(loc=\"best\") axes[0].set_xlim([-0.4, 0.8]) axes[0].set_ylim([-0.4, 0.8])   # Plot with shared bins (same groups across models) cal = binned_validation(     y_true=uplift[\"u_true\"].values,     scores={         \"T-learner\": uplift[\"tau_T\"].values,         \"X-learner\": uplift[\"tau_X\"].values,     },     n_bins=40,     bin_var=\"true\" ) for name, g in cal.groupby(\"model\"):     axes[1].plot(g[\"mean_true\"], g[\"mean_pred\"], \"o-\", label=name) axes[1].plot(line, line, ls=\"--\", c=\"gray\", lw=1.5, zorder=-2) axes[1].set_ylabel(\"Predicted uplift (bin mean)\") axes[1].set_xlabel(\"True uplift (bin mean)\") axes[1].set_title(\"Binned testing\") axes[1].legend(loc=\"best\") axes[1].set_xlim([-0.1, 0.5]) axes[1].set_ylim([-0.1, 0.5])  plt.tight_layout() plt.show() In\u00a0[22]: Copied! <pre># Compute metrics\n\nrmse_T = root_mean_squared_error(uplift[\"tau_T\"], uplift[\"u_true\"])\nrmse_X = root_mean_squared_error(uplift[\"tau_X\"], uplift[\"u_true\"])\nmae_T = mean_absolute_error(uplift[\"tau_T\"], uplift[\"u_true\"])\nmae_X = mean_absolute_error(uplift[\"tau_X\"], uplift[\"u_true\"])\nprint(\"RMSE:\", f\"\\nT-learner {rmse_T:.4f}, X-learner: {rmse_X:.4f}\")\nprint(\"MAE:\", f\"\\nT-learner {mae_T:.4f}, X-learner: {mae_X:.4f}\")\n</pre> # Compute metrics  rmse_T = root_mean_squared_error(uplift[\"tau_T\"], uplift[\"u_true\"]) rmse_X = root_mean_squared_error(uplift[\"tau_X\"], uplift[\"u_true\"]) mae_T = mean_absolute_error(uplift[\"tau_T\"], uplift[\"u_true\"]) mae_X = mean_absolute_error(uplift[\"tau_X\"], uplift[\"u_true\"]) print(\"RMSE:\", f\"\\nT-learner {rmse_T:.4f}, X-learner: {rmse_X:.4f}\") print(\"MAE:\", f\"\\nT-learner {mae_T:.4f}, X-learner: {mae_X:.4f}\")  <pre>RMSE: \nT-learner 0.0797, X-learner: 0.0671\nMAE: \nT-learner 0.0539, X-learner: 0.0473\n</pre> In\u00a0[\u00a0]: Copied! <pre># Curves for each model\nf_T, y_T, auuc_T = uplift_curve(u_test, tau_T)\nf_X, y_X, auuc_X = uplift_curve(u_test, tau_X)\n\n# Oracle (best possible) and random baselines\nf_oracle, y_oracle, auuc_oracle = uplift_curve(u_test, u_test)\ny_rand = np.linspace(0, 1, 200)\nauuc_rand = np.trapezoid(y_rand, y_rand)\n\nplt.figure(figsize=(9, 6))\nplt.plot(f_T, y_T, label=f\"T-learner (AUUC={auuc_T:.3f})\", color=\"C0\")\nplt.plot(f_X, y_X, label=f\"X-learner (AUUC={auuc_X:.3f})\", color=\"C1\")\nplt.plot(f_oracle, y_oracle, label=f\"Oracle (AUUC={auuc_oracle:.3f})\", color=\"k\")\nplt.plot(y_rand, y_rand, \"--\", color=\"gray\", label=f\"Random (AUUC={auuc_rand:.3f})\")\n\n# Add a star marker at x=0.4, and y where the X learner curve is at x=0.4\nx_star = 0.4\ny_star = np.interp(x_star, f_X, y_X)    \nplt.plot(\n    x_star,\n    y_star,\n    marker=\"*\",\n    markersize=25,\n    markerfacecolor=\"k\",\n    markeredgecolor=\"k\",\n    markeredgewidth=2,\n    alpha=0.8,\n)\n\nplt.xlabel(\"Targeted fraction of users\")\nplt.ylabel(\"Cumulative share of total uplift captured\")\nplt.title(\"Uplift curves (test set) and AUUC\")\nplt.legend(loc=\"lower right\")\nplt.ylim([min(0, y_T.min(), y_X.min(), y_oracle.min(), 0), 1.05])\nplt.xlim([0, 1])\nplt.grid(True, alpha=0.3)\nplt.show()\n</pre> # Curves for each model f_T, y_T, auuc_T = uplift_curve(u_test, tau_T) f_X, y_X, auuc_X = uplift_curve(u_test, tau_X)  # Oracle (best possible) and random baselines f_oracle, y_oracle, auuc_oracle = uplift_curve(u_test, u_test) y_rand = np.linspace(0, 1, 200) auuc_rand = np.trapezoid(y_rand, y_rand)  plt.figure(figsize=(9, 6)) plt.plot(f_T, y_T, label=f\"T-learner (AUUC={auuc_T:.3f})\", color=\"C0\") plt.plot(f_X, y_X, label=f\"X-learner (AUUC={auuc_X:.3f})\", color=\"C1\") plt.plot(f_oracle, y_oracle, label=f\"Oracle (AUUC={auuc_oracle:.3f})\", color=\"k\") plt.plot(y_rand, y_rand, \"--\", color=\"gray\", label=f\"Random (AUUC={auuc_rand:.3f})\")  # Add a star marker at x=0.4, and y where the X learner curve is at x=0.4 x_star = 0.4 y_star = np.interp(x_star, f_X, y_X)     plt.plot(     x_star,     y_star,     marker=\"*\",     markersize=25,     markerfacecolor=\"k\",     markeredgecolor=\"k\",     markeredgewidth=2,     alpha=0.8, )  plt.xlabel(\"Targeted fraction of users\") plt.ylabel(\"Cumulative share of total uplift captured\") plt.title(\"Uplift curves (test set) and AUUC\") plt.legend(loc=\"lower right\") plt.ylim([min(0, y_T.min(), y_X.min(), y_oracle.min(), 0), 1.05]) plt.xlim([0, 1]) plt.grid(True, alpha=0.3) plt.show()"},{"location":"notebooks/uplift_modelling/#uplift-modelling","title":"Uplift modelling\u00b6","text":"<p>An complex example of how heterogeneous treatment effects are used in ecommerce platforms. \ud83d\ude80\ud83d\ude80\ud83d\ude80</p>"},{"location":"notebooks/uplift_modelling/#collect-data-and-check-basic-properties","title":"Collect data and check basic properties\u00b6","text":"<p>The <code>data_generating_process</code> function returns the <code>data</code> itself, which can be used to train models. It also returns <code>metadata</code>, which is NOT available in practice, but which we can explore here to assess model performance exactly.</p> <p>We draw 60000 samples and see that there seems to be a difference in the booking probability when offering customers a coupon.</p>"},{"location":"notebooks/uplift_modelling/#conclusions","title":"Conclusions\u00b6","text":"<p>TBW</p>"},{"location":"notebooks/uplift_modelling_utils/","title":"Uplift modelling utils","text":"In\u00a0[\u00a0]: Copied! <pre>from typing import Literal\nimport numpy as np\nimport pandas as pd\n</pre> from typing import Literal import numpy as np import pandas as pd In\u00a0[\u00a0]: Copied! <pre>def data_generating_process(\n    n: int,\n    setting: str,\n    seed: int = 123,\n) -&gt; tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"Generate a synthetic dataset for uplift modeling in a lodging marketplace.\n\n    Out of the two frames that are returned, `data` is the one that would be available\n    in practice, as meta_data contains counterfactual information.\n\n    Args:\n        n: number of samples\n        setting: \"observational\" (targeted, unbalanced) or \"rct\" (balanced 50/50)\n        seed: the random seed\n\n    Returns:\n        data: The actual dataset used for modeling, with the following columns:\n            - client_id: unique identifier for each sample\n            - Y: conversion result [binary, 0/1]\n            - T: treatment [binary, 0/1]\n            - Various features commonly available on ecommerce platforms\n        meta_data: Information NOT available in practice, but useful for validation:\n            - client_id: unique identifier for each sample\n            - Y: conversion result [binary, 0/1]\n            - T: treatment [binary, 0/1]\n            - p_treat: treatment propensity used in generation\n            - true_p_y0: conversion probability if untreated\n            - true_p_y1: conversion probability if treated\n            - true_uplift: true individual uplift (p_y1 - p_y0)\n    \"\"\"\n\n    def sigmoid(z):\n        return 1.0 / (1.0 + np.exp(-z))\n\n    rng = np.random.default_rng(seed)\n\n    channels = np.array([\"paid_search\", \"organic\", \"email\", \"direct\", \"app_push\"])\n    devices = np.array([\"mobile_web\", \"desktop\", \"app\"])\n    dest_tiers = np.array([\"tier1\", \"tier2\", \"tier3\"])\n\n    # --- Draw base features ---\n    channel = rng.choice(channels, size=n, p=[0.35, 0.25, 0.15, 0.20, 0.05])\n    device = rng.choice(devices, size=n, p=[0.55, 0.30, 0.15])\n    dest_tier = rng.choice(dest_tiers, size=n, p=[0.50, 0.35, 0.15])\n\n    # Lead time (days to check-in): empirical-ish discrete distribution\n    lead_time = np.clip(\n        rng.choice(\n            [0, 1, 2, 3, 5, 7, 10, 14, 21, 30, 45, 60, 90, 120],\n            size=n,\n            p=[0.06, 0.05, 0.05, 0.05, 0.07, 0.07, 0.08, 0.09, 0.11, 0.12, 0.09, 0.07, 0.05, 0.04],\n        ),\n        0,\n        120,\n    )\n\n    # Funnel depth: 0=landing, 1=search, 2=property details, 3=checkout\n    funnel_depth = rng.choice([0, 1, 2, 3], size=n, p=[0.25, 0.40, 0.28, 0.07])\n\n    # Behavioral/identity features\n    price_sort_used = rng.binomial(1, p=0.35 + 0.15 * (channel == \"paid_search\"))\n    past_coupon_user = rng.binomial(1, p=0.25 + 0.10 * (channel == \"email\"))\n    tenure_days = rng.integers(0, 1800, size=n)\n    hour_local = rng.integers(0, 24, size=n)\n\n    # Recent ad exposure (helps form confounding in observational setting)\n    recent_ad_exposure = rng.binomial(1, p=0.20 + 0.25 * (channel == \"paid_search\"))\n\n    # --- Treatment assignment ---\n    if setting == \"observational\":\n        # Higher propensity for price-sensitive &amp; shallow-funnel sessions, paid channels, recent exposure\n        logit_p_treat = (\n            -3.0\n            + 1.2 * (channel == \"paid_search\")\n            + 0.6 * (channel == \"email\")\n            + 0.5 * (price_sort_used == 1)\n            + 0.4 * (past_coupon_user == 1)\n            + 0.5 * (funnel_depth == 0)\n            + 0.3 * (funnel_depth == 1)\n            - 0.3 * (funnel_depth == 3)\n            + 0.2 * ((lead_time &gt;= 8) &amp; (lead_time &lt;= 60))\n            + 0.8 * (recent_ad_exposure == 1)\n            - 0.2 * (device == \"app\")\n        )\n        p_treat = sigmoid(logit_p_treat)\n        T = rng.binomial(1, p_treat)\n    elif setting == \"rct\":\n        p_treat = np.full(n, 0.5)\n        T = rng.binomial(1, 0.5, size=n)\n    else:\n        raise ValueError(\"setting must be 'observational' or 'rct'\")\n\n    # --- Outcome model (potential outcomes) ---\n    # Lead-time buckets for nonlinearity\n    lt_0_1 = (lead_time &lt;= 1).astype(float)\n    lt_2_7 = ((lead_time &gt;= 2) &amp; (lead_time &lt;= 7)).astype(float)\n    lt_8_30 = ((lead_time &gt;= 8) &amp; (lead_time &lt;= 30)).astype(float)\n    lt_31_90 = ((lead_time &gt;= 31) &amp; (lead_time &lt;= 90)).astype(float)\n    lt_91_120 = ((lead_time &gt;= 91) &amp; (lead_time &lt;= 120)).astype(float)\n\n    # Baseline conversion log-odds (no coupon)\n    baseline_logit = (\n        -3.5\n        + 0.2 * (device == \"desktop\")\n        + 0.1 * (device == \"app\")\n        + 0.4 * (dest_tier == \"tier1\")\n        + 0.2 * (dest_tier == \"tier2\")\n        + 0.15 * lt_0_1\n        + 0.05 * lt_2_7\n        + 0.0 * lt_8_30\n        - 0.05 * lt_31_90\n        - 0.1 * lt_91_120\n        + 0.5 * (funnel_depth == 1)\n        + 1.2 * (funnel_depth == 2)\n        + 2.0 * (funnel_depth == 3)\n        + 0.0002 * tenure_days\n        + 0.05 * np.cos(2 * np.pi * hour_local / 24.0)\n    )\n\n    # True treatment effect on log-odds (uplift_logit): depends on realistic, not all, features\n    uplift_logit = (\n        0.45 * (price_sort_used == 1)\n        + 1.35 * (channel == \"paid_search\")\n        + 0.20 * (channel == \"email\")\n        + 0.25 * ((lead_time &gt;= 8) &amp; (lead_time &lt;= 60))\n        + 0.50 * (funnel_depth == 0)\n        + 0.15 * (funnel_depth == 1)\n        - 0.20 * (funnel_depth == 3)\n        - 0.25 * (past_coupon_user == 1)\n        - 0.15 * (device == \"app\")  # app users a bit less elastic\n        + 0.05\n        * ((price_sort_used == 1) &amp; ((lead_time &gt;= 8) &amp; (lead_time &lt;= 60)))  # mild interaction\n    )\n\n    # Mild idiosyncratic noise\n    rng_noise = np.random.default_rng(seed + 13)\n    uplift_logit += rng_noise.normal(0, 0.02, size=n)\n\n    # Potential outcomes\n    logit_y0 = baseline_logit\n    logit_y1 = baseline_logit + uplift_logit\n    p_y0 = sigmoid(logit_y0)\n    p_y1 = sigmoid(logit_y1)\n\n    # Realized outcome given treatment\n    Y = rng.binomial(1, np.where(T == 1, p_y1, p_y0))\n\n    data = pd.DataFrame(\n        {\n            \"client_id\": np.arange(n),\n            \"Y\": Y,\n            \"T\": T,\n            \"true_uplift\": p_y1 - p_y0,\n            \"channel\": channel,\n            \"device\": device,\n            \"lead_time\": lead_time,\n            \"funnel_depth\": funnel_depth,\n            \"price_sort_used\": price_sort_used,\n            \"past_coupon_user\": past_coupon_user,\n            \"tenure_days\": tenure_days,\n            \"dest_tier\": dest_tier,\n            \"hour_local\": hour_local,\n            \"recent_ad_exposure\": recent_ad_exposure,\n        }\n    )\n    meta_data = pd.DataFrame(\n        {\n            \"client_id\": np.arange(n),\n            \"Y\": Y,\n            \"T\": T,\n            \"p_treat\": p_treat,\n            \"true_p_y0\": p_y0,\n            \"true_p_y1\": p_y1,\n            \"true_uplift\": p_y1 - p_y0,\n        }\n    )\n    return data, meta_data\n</pre> def data_generating_process(     n: int,     setting: str,     seed: int = 123, ) -&gt; tuple[pd.DataFrame, pd.DataFrame]:     \"\"\"Generate a synthetic dataset for uplift modeling in a lodging marketplace.      Out of the two frames that are returned, `data` is the one that would be available     in practice, as meta_data contains counterfactual information.      Args:         n: number of samples         setting: \"observational\" (targeted, unbalanced) or \"rct\" (balanced 50/50)         seed: the random seed      Returns:         data: The actual dataset used for modeling, with the following columns:             - client_id: unique identifier for each sample             - Y: conversion result [binary, 0/1]             - T: treatment [binary, 0/1]             - Various features commonly available on ecommerce platforms         meta_data: Information NOT available in practice, but useful for validation:             - client_id: unique identifier for each sample             - Y: conversion result [binary, 0/1]             - T: treatment [binary, 0/1]             - p_treat: treatment propensity used in generation             - true_p_y0: conversion probability if untreated             - true_p_y1: conversion probability if treated             - true_uplift: true individual uplift (p_y1 - p_y0)     \"\"\"      def sigmoid(z):         return 1.0 / (1.0 + np.exp(-z))      rng = np.random.default_rng(seed)      channels = np.array([\"paid_search\", \"organic\", \"email\", \"direct\", \"app_push\"])     devices = np.array([\"mobile_web\", \"desktop\", \"app\"])     dest_tiers = np.array([\"tier1\", \"tier2\", \"tier3\"])      # --- Draw base features ---     channel = rng.choice(channels, size=n, p=[0.35, 0.25, 0.15, 0.20, 0.05])     device = rng.choice(devices, size=n, p=[0.55, 0.30, 0.15])     dest_tier = rng.choice(dest_tiers, size=n, p=[0.50, 0.35, 0.15])      # Lead time (days to check-in): empirical-ish discrete distribution     lead_time = np.clip(         rng.choice(             [0, 1, 2, 3, 5, 7, 10, 14, 21, 30, 45, 60, 90, 120],             size=n,             p=[0.06, 0.05, 0.05, 0.05, 0.07, 0.07, 0.08, 0.09, 0.11, 0.12, 0.09, 0.07, 0.05, 0.04],         ),         0,         120,     )      # Funnel depth: 0=landing, 1=search, 2=property details, 3=checkout     funnel_depth = rng.choice([0, 1, 2, 3], size=n, p=[0.25, 0.40, 0.28, 0.07])      # Behavioral/identity features     price_sort_used = rng.binomial(1, p=0.35 + 0.15 * (channel == \"paid_search\"))     past_coupon_user = rng.binomial(1, p=0.25 + 0.10 * (channel == \"email\"))     tenure_days = rng.integers(0, 1800, size=n)     hour_local = rng.integers(0, 24, size=n)      # Recent ad exposure (helps form confounding in observational setting)     recent_ad_exposure = rng.binomial(1, p=0.20 + 0.25 * (channel == \"paid_search\"))      # --- Treatment assignment ---     if setting == \"observational\":         # Higher propensity for price-sensitive &amp; shallow-funnel sessions, paid channels, recent exposure         logit_p_treat = (             -3.0             + 1.2 * (channel == \"paid_search\")             + 0.6 * (channel == \"email\")             + 0.5 * (price_sort_used == 1)             + 0.4 * (past_coupon_user == 1)             + 0.5 * (funnel_depth == 0)             + 0.3 * (funnel_depth == 1)             - 0.3 * (funnel_depth == 3)             + 0.2 * ((lead_time &gt;= 8) &amp; (lead_time &lt;= 60))             + 0.8 * (recent_ad_exposure == 1)             - 0.2 * (device == \"app\")         )         p_treat = sigmoid(logit_p_treat)         T = rng.binomial(1, p_treat)     elif setting == \"rct\":         p_treat = np.full(n, 0.5)         T = rng.binomial(1, 0.5, size=n)     else:         raise ValueError(\"setting must be 'observational' or 'rct'\")      # --- Outcome model (potential outcomes) ---     # Lead-time buckets for nonlinearity     lt_0_1 = (lead_time &lt;= 1).astype(float)     lt_2_7 = ((lead_time &gt;= 2) &amp; (lead_time &lt;= 7)).astype(float)     lt_8_30 = ((lead_time &gt;= 8) &amp; (lead_time &lt;= 30)).astype(float)     lt_31_90 = ((lead_time &gt;= 31) &amp; (lead_time &lt;= 90)).astype(float)     lt_91_120 = ((lead_time &gt;= 91) &amp; (lead_time &lt;= 120)).astype(float)      # Baseline conversion log-odds (no coupon)     baseline_logit = (         -3.5         + 0.2 * (device == \"desktop\")         + 0.1 * (device == \"app\")         + 0.4 * (dest_tier == \"tier1\")         + 0.2 * (dest_tier == \"tier2\")         + 0.15 * lt_0_1         + 0.05 * lt_2_7         + 0.0 * lt_8_30         - 0.05 * lt_31_90         - 0.1 * lt_91_120         + 0.5 * (funnel_depth == 1)         + 1.2 * (funnel_depth == 2)         + 2.0 * (funnel_depth == 3)         + 0.0002 * tenure_days         + 0.05 * np.cos(2 * np.pi * hour_local / 24.0)     )      # True treatment effect on log-odds (uplift_logit): depends on realistic, not all, features     uplift_logit = (         0.45 * (price_sort_used == 1)         + 1.35 * (channel == \"paid_search\")         + 0.20 * (channel == \"email\")         + 0.25 * ((lead_time &gt;= 8) &amp; (lead_time &lt;= 60))         + 0.50 * (funnel_depth == 0)         + 0.15 * (funnel_depth == 1)         - 0.20 * (funnel_depth == 3)         - 0.25 * (past_coupon_user == 1)         - 0.15 * (device == \"app\")  # app users a bit less elastic         + 0.05         * ((price_sort_used == 1) &amp; ((lead_time &gt;= 8) &amp; (lead_time &lt;= 60)))  # mild interaction     )      # Mild idiosyncratic noise     rng_noise = np.random.default_rng(seed + 13)     uplift_logit += rng_noise.normal(0, 0.02, size=n)      # Potential outcomes     logit_y0 = baseline_logit     logit_y1 = baseline_logit + uplift_logit     p_y0 = sigmoid(logit_y0)     p_y1 = sigmoid(logit_y1)      # Realized outcome given treatment     Y = rng.binomial(1, np.where(T == 1, p_y1, p_y0))      data = pd.DataFrame(         {             \"client_id\": np.arange(n),             \"Y\": Y,             \"T\": T,             \"true_uplift\": p_y1 - p_y0,             \"channel\": channel,             \"device\": device,             \"lead_time\": lead_time,             \"funnel_depth\": funnel_depth,             \"price_sort_used\": price_sort_used,             \"past_coupon_user\": past_coupon_user,             \"tenure_days\": tenure_days,             \"dest_tier\": dest_tier,             \"hour_local\": hour_local,             \"recent_ad_exposure\": recent_ad_exposure,         }     )     meta_data = pd.DataFrame(         {             \"client_id\": np.arange(n),             \"Y\": Y,             \"T\": T,             \"p_treat\": p_treat,             \"true_p_y0\": p_y0,             \"true_p_y1\": p_y1,             \"true_uplift\": p_y1 - p_y0,         }     )     return data, meta_data In\u00a0[\u00a0]: Copied! <pre>def binned_validation(\n    y_true: np.ndarray,\n    scores: dict[str, np.ndarray],\n    bin_var: Literal[\"true\", \"pred\"] = \"true\",\n    n_bins: int = 20,\n) -&gt; pd.DataFrame:\n    \"\"\"Binned validation plot for multiple models.\n\n    Build shared bins across multiple prediction arrays using the mean rank\n    across models, then compute per-bin mean true uplift and per-model mean predictions.\n\n    Returns a long DataFrame with columns:['bin', 'model', 'mean_true', 'mean_pred', 'count'].\n    \"\"\"\n    # Validate lengths\n    n = len(y_true)\n    for k, v in scores.items():\n        if len(v) != n:\n            raise ValueError(f\"Length mismatch for model '{k}': got {len(v)} vs y_true {n}\")\n\n    # Aggregate rank per sample across models to define shared bins\n    ranks = [pd.Series(v).rank(method=\"average\", pct=True).to_numpy() for v in scores.values()]\n    mean_rank = np.mean(np.column_stack(ranks), axis=1)\n\n    # Quantile bins on the aggregated rank\n    if bin_var == \"pred\":\n        bins = pd.qcut(mean_rank, q=n_bins, labels=False, duplicates=\"drop\")\n    elif bin_var == \"true\":\n        bins = pd.qcut(y_true, q=n_bins, labels=False, duplicates=\"drop\")\n\n    # Build a working frame\n    df = pd.DataFrame({\"bin\": bins, \"y_true\": y_true})\n    for name, v in scores.items():\n        df[name] = v\n\n    # Summarize into long format\n    rows = []\n    for b, g in df.groupby(\"bin\"):\n        mean_true = g[\"y_true\"].mean()\n        cnt = len(g)\n        for name in scores.keys():\n            rows.append(\n                {\n                    \"bin\": int(b),\n                    \"model\": name,\n                    \"mean_true\": float(mean_true),\n                    \"mean_pred\": float(g[name].mean()),\n                    \"count\": int(cnt),\n                }\n            )\n    return pd.DataFrame(rows).sort_values([\"model\", \"bin\"]).reset_index(drop=True)\n</pre> def binned_validation(     y_true: np.ndarray,     scores: dict[str, np.ndarray],     bin_var: Literal[\"true\", \"pred\"] = \"true\",     n_bins: int = 20, ) -&gt; pd.DataFrame:     \"\"\"Binned validation plot for multiple models.      Build shared bins across multiple prediction arrays using the mean rank     across models, then compute per-bin mean true uplift and per-model mean predictions.      Returns a long DataFrame with columns:['bin', 'model', 'mean_true', 'mean_pred', 'count'].     \"\"\"     # Validate lengths     n = len(y_true)     for k, v in scores.items():         if len(v) != n:             raise ValueError(f\"Length mismatch for model '{k}': got {len(v)} vs y_true {n}\")      # Aggregate rank per sample across models to define shared bins     ranks = [pd.Series(v).rank(method=\"average\", pct=True).to_numpy() for v in scores.values()]     mean_rank = np.mean(np.column_stack(ranks), axis=1)      # Quantile bins on the aggregated rank     if bin_var == \"pred\":         bins = pd.qcut(mean_rank, q=n_bins, labels=False, duplicates=\"drop\")     elif bin_var == \"true\":         bins = pd.qcut(y_true, q=n_bins, labels=False, duplicates=\"drop\")      # Build a working frame     df = pd.DataFrame({\"bin\": bins, \"y_true\": y_true})     for name, v in scores.items():         df[name] = v      # Summarize into long format     rows = []     for b, g in df.groupby(\"bin\"):         mean_true = g[\"y_true\"].mean()         cnt = len(g)         for name in scores.keys():             rows.append(                 {                     \"bin\": int(b),                     \"model\": name,                     \"mean_true\": float(mean_true),                     \"mean_pred\": float(g[name].mean()),                     \"count\": int(cnt),                 }             )     return pd.DataFrame(rows).sort_values([\"model\", \"bin\"]).reset_index(drop=True) In\u00a0[\u00a0]: Copied! <pre>def uplift_curve(u_true: np.ndarray, scores: np.ndarray):\n    \"\"\"Uplift curve computation.\n\n    Build uplift curve by sorting by predicted scores (descending) and\n    accumulating the true uplift. Returns fractions, normalized cumulative uplift, AUUC.\n    \"\"\"\n    order = np.argsort(scores)[::-1]\n    u_sorted = u_true[order]\n    n = len(u_sorted)\n    frac = np.arange(1, n + 1) / n\n    cum_u = np.cumsum(u_sorted)\n    total_u = np.sum(u_true)\n\n    # Normalize to show share of total uplift captured (final value ~1 if total uplift &gt; 0)\n    if np.isclose(total_u, 0.0):\n        y = cum_u  # fallback (no normalization possible)\n        auuc = np.trapezoid(y, frac)\n    else:\n        y = cum_u / total_u\n        auuc = np.trapezoid(y, frac)\n\n    return frac, y, auuc\n</pre> def uplift_curve(u_true: np.ndarray, scores: np.ndarray):     \"\"\"Uplift curve computation.      Build uplift curve by sorting by predicted scores (descending) and     accumulating the true uplift. Returns fractions, normalized cumulative uplift, AUUC.     \"\"\"     order = np.argsort(scores)[::-1]     u_sorted = u_true[order]     n = len(u_sorted)     frac = np.arange(1, n + 1) / n     cum_u = np.cumsum(u_sorted)     total_u = np.sum(u_true)      # Normalize to show share of total uplift captured (final value ~1 if total uplift &gt; 0)     if np.isclose(total_u, 0.0):         y = cum_u  # fallback (no normalization possible)         auuc = np.trapezoid(y, frac)     else:         y = cum_u / total_u         auuc = np.trapezoid(y, frac)      return frac, y, auuc"}]}