{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0421c8de",
   "metadata": {},
   "source": [
    "# Uplift modelling\n",
    "\n",
    "An complex example of how heterogeneous treatment effects are used in ecommerce platforms. ðŸš€ðŸš€ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce9902",
   "metadata": {},
   "source": [
    "**The business problem:**\n",
    "\n",
    "We are concerted with *giving or not giving users a 5% discount voucher*.\n",
    "\n",
    "If we give it to everyone, we'll likely get more bookings, but at the same time we hurt our margins. So the best way to proceed is to give the coupons only to those customers that were unsure about the decision and that will actually convert after receiving it. Also, not giving the coupons to customers that were already going to book something no matter what!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3126ea",
   "metadata": {},
   "source": [
    "**The causal problem:**\n",
    "\n",
    "Our treatment $T$ is offering customers this coupon, a binary variable.\n",
    "\n",
    "Our outcome $Y$ is the customer finalizing their booking or not, also a binary variable.\n",
    "\n",
    "Additionally, we have access to a number of other variables $X$ characterizing the user, the channel that brough them to the platform, the specific ongoing session, and so on... We believe some of them could be valuable in deciding the effectiveness of the intervention. In other words, the effect isn't uniform but varies depending on some of these factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d10e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "np.random.seed(111)\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.plotting_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4e5342",
   "metadata": {},
   "source": [
    "### Define the simulation mechanism\n",
    "\n",
    "Two settings are possible: \"observational\" and \"rct\". In the former, samples are not balanced, whereas in the latter, they are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fd4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generating_process(\n",
    "    n: int, \n",
    "    setting: str, \n",
    "    seed: int = 123,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Generate a synthetic dataset for uplift modeling in a lodging marketplace.\n",
    "\n",
    "    Args:\n",
    "        n: number of samples\n",
    "        setting: \"observational\" (targeted, unbalanced) or \"rct\" (balanced 50/50)\n",
    "        seed: the random seed\n",
    "\n",
    "    Returns:\n",
    "        data: The actual dataset used for modeling, with the following columns:\n",
    "            - client_id: unique identifier for each sample\n",
    "            - Y: conversion result [binary, 0/1]\n",
    "            - T: treatment [binary, 0/1]\n",
    "            - Various features commonly available on ecommerce platforms\n",
    "        meta_data: Information NOT available in practice, but useful for validation:\n",
    "            - client_id: unique identifier for each sample\n",
    "            - Y: conversion result [binary, 0/1]\n",
    "            - T: treatment [binary, 0/1]\n",
    "            - p_treat: treatment propensity used in generation\n",
    "            - true_p_y0: conversion probability if untreated \n",
    "            - true_p_y1: conversion probability if treated\n",
    "            - true_uplift: true individual uplift (p_y1 - p_y0)\n",
    "    \"\"\"\n",
    "    def sigmoid(z):\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    channels = np.array([\"paid_search\", \"organic\", \"email\", \"direct\", \"app_push\"])\n",
    "    devices = np.array([\"mobile_web\", \"desktop\", \"app\"])\n",
    "    dest_tiers = np.array([\"tier1\", \"tier2\", \"tier3\"])\n",
    "\n",
    "    # --- Draw base features ---\n",
    "    channel = rng.choice(channels, size=n, p=[0.35, 0.25, 0.15, 0.20, 0.05])\n",
    "    device = rng.choice(devices, size=n, p=[0.55, 0.30, 0.15])\n",
    "    dest_tier = rng.choice(dest_tiers, size=n, p=[0.50, 0.35, 0.15])\n",
    "\n",
    "    # Lead time (days to check-in): empirical-ish discrete distribution\n",
    "    lead_time = np.clip(\n",
    "        rng.choice(\n",
    "            [0, 1, 2, 3, 5, 7, 10, 14, 21, 30, 45, 60, 90, 120],\n",
    "            size=n,\n",
    "            p=[0.06, 0.05, 0.05, 0.05, 0.07, 0.07, 0.08, 0.09, 0.11, 0.12, 0.09, 0.07, 0.05, 0.04],\n",
    "        ),\n",
    "        0,\n",
    "        120,\n",
    "    )\n",
    "\n",
    "    # Funnel depth: 0=landing, 1=search, 2=property details, 3=checkout\n",
    "    funnel_depth = rng.choice([0, 1, 2, 3], size=n, p=[0.25, 0.40, 0.28, 0.07])\n",
    "\n",
    "    # Behavioral/identity features\n",
    "    price_sort_used = rng.binomial(1, p=0.35 + 0.15 * (channel == \"paid_search\"))\n",
    "    past_coupon_user = rng.binomial(1, p=0.25 + 0.10 * (channel == \"email\"))\n",
    "    tenure_days = rng.integers(0, 1800, size=n)\n",
    "    hour_local = rng.integers(0, 24, size=n)\n",
    "\n",
    "    # Recent ad exposure (helps form confounding in observational setting)\n",
    "    recent_ad_exposure = rng.binomial(1, p=0.20 + 0.25 * (channel == \"paid_search\"))\n",
    "\n",
    "    # --- Treatment assignment ---\n",
    "    if setting == \"observational\":\n",
    "        # Higher propensity for price-sensitive & shallow-funnel sessions, paid channels, recent exposure\n",
    "        logit_p_treat = (\n",
    "            -1.0\n",
    "            + 1.2 * (channel == \"paid_search\")\n",
    "            + 0.6 * (channel == \"email\")\n",
    "            + 0.5 * (price_sort_used == 1)\n",
    "            + 0.4 * (past_coupon_user == 1)\n",
    "            + 0.5 * (funnel_depth == 0)\n",
    "            + 0.3 * (funnel_depth == 1)\n",
    "            - 0.3 * (funnel_depth == 3)\n",
    "            + 0.2 * ((lead_time >= 8) & (lead_time <= 60))\n",
    "            + 0.8 * (recent_ad_exposure == 1)\n",
    "            - 0.2 * (device == \"app\")\n",
    "        )\n",
    "        p_treat = sigmoid(logit_p_treat)\n",
    "        T = rng.binomial(1, p_treat)\n",
    "    elif setting == \"rct\":\n",
    "        p_treat = np.full(n, 0.5)\n",
    "        T = rng.binomial(1, 0.5, size=n)\n",
    "    else:\n",
    "        raise ValueError(\"setting must be 'observational' or 'rct'\")\n",
    "\n",
    "    # --- Outcome model (potential outcomes) ---\n",
    "    # Lead-time buckets for nonlinearity\n",
    "    lt_0_1 = (lead_time <= 1).astype(float)\n",
    "    lt_2_7 = ((lead_time >= 2) & (lead_time <= 7)).astype(float)\n",
    "    lt_8_30 = ((lead_time >= 8) & (lead_time <= 30)).astype(float)\n",
    "    lt_31_90 = ((lead_time >= 31) & (lead_time <= 90)).astype(float)\n",
    "    lt_91_120 = ((lead_time >= 91) & (lead_time <= 120)).astype(float)\n",
    "\n",
    "    # Baseline conversion log-odds (no coupon)\n",
    "    baseline_logit = (\n",
    "        -3.5\n",
    "        + 0.2 * (device == \"desktop\")\n",
    "        + 0.1 * (device == \"app\")\n",
    "        + 0.4 * (dest_tier == \"tier1\")\n",
    "        + 0.2 * (dest_tier == \"tier2\")\n",
    "        + 0.15 * lt_0_1\n",
    "        + 0.05 * lt_2_7\n",
    "        + 0.0 * lt_8_30\n",
    "        - 0.05 * lt_31_90\n",
    "        - 0.1 * lt_91_120\n",
    "        + 0.5 * (funnel_depth == 1)\n",
    "        + 1.2 * (funnel_depth == 2)\n",
    "        + 2.0 * (funnel_depth == 3)\n",
    "        + 0.0002 * tenure_days\n",
    "        + 0.05 * np.cos(2 * np.pi * hour_local / 24.0)\n",
    "    )\n",
    "\n",
    "    # True treatment effect on log-odds (uplift_logit): depends on realistic, not all, features\n",
    "    uplift_logit = (\n",
    "        0.45 * (price_sort_used == 1)\n",
    "        + 0.35 * (channel == \"paid_search\")\n",
    "        + 0.20 * (channel == \"email\")\n",
    "        + 0.25 * ((lead_time >= 8) & (lead_time <= 60))\n",
    "        + 0.20 * (funnel_depth == 0)\n",
    "        + 0.15 * (funnel_depth == 1)\n",
    "        - 0.05 * (funnel_depth == 3)\n",
    "        + 0.10 * (past_coupon_user == 1)\n",
    "        - 0.08 * (device == \"app\")  # app users a bit less elastic\n",
    "        + 0.05\n",
    "        * ((price_sort_used == 1) & ((lead_time >= 8) & (lead_time <= 60)))  # mild interaction\n",
    "    )\n",
    "\n",
    "    # Mild idiosyncratic noise\n",
    "    rng_noise = np.random.default_rng(seed + 13)\n",
    "    uplift_logit += rng_noise.normal(0, 0.05, size=n)\n",
    "\n",
    "    # Potential outcomes\n",
    "    logit_y0 = baseline_logit\n",
    "    logit_y1 = baseline_logit + uplift_logit\n",
    "    p_y0 = sigmoid(logit_y0)\n",
    "    p_y1 = sigmoid(logit_y1)\n",
    "\n",
    "    # Realized outcome given treatment\n",
    "    Y = rng.binomial(1, np.where(T == 1, p_y1, p_y0))\n",
    "\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            \"client_id\": np.arange(n),\n",
    "            \"Y\": Y,\n",
    "            \"T\": T,\n",
    "            \"channel\": channel,\n",
    "            \"device\": device,\n",
    "            \"lead_time\": lead_time,\n",
    "            \"funnel_depth\": funnel_depth,\n",
    "            \"price_sort_used\": price_sort_used,\n",
    "            \"past_coupon_user\": past_coupon_user,\n",
    "            \"tenure_days\": tenure_days,\n",
    "            \"dest_tier\": dest_tier,\n",
    "            \"hour_local\": hour_local,\n",
    "            \"recent_ad_exposure\": recent_ad_exposure,\n",
    "        }\n",
    "    )\n",
    "    meta_data = pd.DataFrame(\n",
    "        {\n",
    "            \"client_id\": np.arange(n),\n",
    "            \"Y\": Y,\n",
    "            \"T\": T,\n",
    "            \"p_treat\": p_treat,\n",
    "            \"true_p_y0\": p_y0,\n",
    "            \"true_p_y1\": p_y1,\n",
    "            \"true_uplift\": p_y1 - p_y0,\n",
    "        }\n",
    "    )\n",
    "    return data, meta_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7790c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observational:\n",
      "  n = 60000\n",
      "  treat_rate = 0.574\n",
      "  conv_rate_T1 = 0.1794\n",
      "  conv_rate_T0 = 0.1123\n",
      "\n",
      "RCT:\n",
      "  n = 60000\n",
      "  treat_rate = 0.5012\n",
      "  conv_rate_T1 = 0.1737\n",
      "  conv_rate_T0 = 0.1076\n"
     ]
    }
   ],
   "source": [
    "# Observational (targeted / unbalanced)\n",
    "obs_df = data_generating_process(60_000, setting=\"observational\", seed=11)\n",
    "\n",
    "# Randomized experiment (balanced 50/50)\n",
    "rct_df = data_generating_process(60_000, setting=\"rct\", seed=12)\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"Observational:\")\n",
    "print(\"  n =\", len(obs_df))\n",
    "print(\"  treat_rate =\", obs_df[\"T\"].mean().round(4))\n",
    "print(\"  conv_rate_T1 =\", obs_df.loc[obs_df[\"T\"] == 1, \"Y\"].mean().round(4))\n",
    "print(\"  conv_rate_T0 =\", obs_df.loc[obs_df[\"T\"] == 0, \"Y\"].mean().round(4))\n",
    "\n",
    "print(\"\\nRCT:\")\n",
    "print(\"  n =\", len(rct_df))\n",
    "print(\"  treat_rate =\", rct_df[\"T\"].mean().round(4))\n",
    "print(\"  conv_rate_T1 =\", rct_df.loc[rct_df[\"T\"] == 1, \"Y\"].mean().round(4))\n",
    "print(\"  conv_rate_T0 =\", rct_df.loc[rct_df[\"T\"] == 0, \"Y\"].mean().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9514e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>T</th>\n",
       "      <th>p_treat</th>\n",
       "      <th>channel</th>\n",
       "      <th>device</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>funnel_depth</th>\n",
       "      <th>price_sort_used</th>\n",
       "      <th>past_coupon_user</th>\n",
       "      <th>tenure_days</th>\n",
       "      <th>dest_tier</th>\n",
       "      <th>hour_local</th>\n",
       "      <th>recent_ad_exposure</th>\n",
       "      <th>true_p_y0</th>\n",
       "      <th>true_p_y1</th>\n",
       "      <th>true_uplift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>paid_search</td>\n",
       "      <td>mobile_web</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1337</td>\n",
       "      <td>tier1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087421</td>\n",
       "      <td>0.171102</td>\n",
       "      <td>0.083681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>direct</td>\n",
       "      <td>mobile_web</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "      <td>tier2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267089</td>\n",
       "      <td>0.257368</td>\n",
       "      <td>-0.009720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>paid_search</td>\n",
       "      <td>desktop</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1080</td>\n",
       "      <td>tier1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058908</td>\n",
       "      <td>0.095553</td>\n",
       "      <td>0.036645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>paid_search</td>\n",
       "      <td>desktop</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1660</td>\n",
       "      <td>tier1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.117326</td>\n",
       "      <td>0.200716</td>\n",
       "      <td>0.083390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>paid_search</td>\n",
       "      <td>mobile_web</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1588</td>\n",
       "      <td>tier3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057576</td>\n",
       "      <td>0.091587</td>\n",
       "      <td>0.034011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>email</td>\n",
       "      <td>app</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1031</td>\n",
       "      <td>tier1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087696</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.120637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>organic</td>\n",
       "      <td>app</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>815</td>\n",
       "      <td>tier1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058031</td>\n",
       "      <td>0.099992</td>\n",
       "      <td>0.041962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>email</td>\n",
       "      <td>mobile_web</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1581</td>\n",
       "      <td>tier3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064715</td>\n",
       "      <td>0.188899</td>\n",
       "      <td>0.124184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>app_push</td>\n",
       "      <td>app</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1392</td>\n",
       "      <td>tier3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127494</td>\n",
       "      <td>0.142514</td>\n",
       "      <td>0.015020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>app_push</td>\n",
       "      <td>mobile_web</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>tier3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046570</td>\n",
       "      <td>0.103732</td>\n",
       "      <td>0.057162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Y  T  p_treat      channel      device  lead_time  funnel_depth  \\\n",
       "0      0  1      0.5  paid_search  mobile_web         30             1   \n",
       "1      1  1      0.5       direct  mobile_web          0             3   \n",
       "2      0  1      0.5  paid_search     desktop        120             0   \n",
       "3      0  0      0.5  paid_search     desktop         21             1   \n",
       "4      0  0      0.5  paid_search  mobile_web        120             1   \n",
       "...   .. ..      ...          ...         ...        ...           ...   \n",
       "59995  0  0      0.5        email         app         21             1   \n",
       "59996  0  1      0.5      organic         app          7             0   \n",
       "59997  0  1      0.5        email  mobile_web         21             1   \n",
       "59998  0  0      0.5     app_push         app         45             2   \n",
       "59999  0  1      0.5     app_push  mobile_web         21             1   \n",
       "\n",
       "       price_sort_used  past_coupon_user  tenure_days dest_tier  hour_local  \\\n",
       "0                    0                 0         1337     tier1          17   \n",
       "1                    0                 0          526     tier2          21   \n",
       "2                    0                 0         1080     tier1           5   \n",
       "3                    0                 0         1660     tier1           0   \n",
       "4                    0                 0         1588     tier3          17   \n",
       "...                ...               ...          ...       ...         ...   \n",
       "59995                1                 0         1031     tier1          11   \n",
       "59996                1                 0          815     tier1          18   \n",
       "59997                1                 1         1581     tier3           5   \n",
       "59998                0                 0         1392     tier3           1   \n",
       "59999                1                 0          121     tier3          10   \n",
       "\n",
       "       recent_ad_exposure  true_p_y0  true_p_y1  true_uplift  \n",
       "0                       0   0.087421   0.171102     0.083681  \n",
       "1                       1   0.267089   0.257368    -0.009720  \n",
       "2                       1   0.058908   0.095553     0.036645  \n",
       "3                       0   0.117326   0.200716     0.083390  \n",
       "4                       0   0.057576   0.091587     0.034011  \n",
       "...                   ...        ...        ...          ...  \n",
       "59995                   0   0.087696   0.208333     0.120637  \n",
       "59996                   0   0.058031   0.099992     0.041962  \n",
       "59997                   0   0.064715   0.188899     0.124184  \n",
       "59998                   1   0.127494   0.142514     0.015020  \n",
       "59999                   0   0.046570   0.103732     0.057162  \n",
       "\n",
       "[60000 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f420f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# UPLIFT MODELING: T-learner, X-learner, DR-learner (from scratch)\n",
    "# ============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Common helpers\n",
    "# -----------------------------\n",
    "CAT_COLS = [\"channel\",\"device\",\"dest_tier\"]\n",
    "NUM_COLS = [\"lead_time\",\"funnel_depth\",\"price_sort_used\",\"past_coupon_user\",\n",
    "            \"tenure_days\",\"hour_local\",\"recent_ad_exposure\"]\n",
    "\n",
    "def make_preprocessor() -> ColumnTransformer:\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(drop=\"first\", handle_unknown=\"ignore\"), CAT_COLS),\n",
    "            (\"num\", \"passthrough\", NUM_COLS),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def train_test_split_df(df: pd.DataFrame, test_size=0.25, seed=7):\n",
    "    X = df[CAT_COLS + NUM_COLS]\n",
    "    y = df[\"Y\"].astype(int).values\n",
    "    t = df[\"T\"].astype(int).values\n",
    "    # keep prop for IPW evaluation if present\n",
    "    p = df[\"p_treat\"].values if \"p_treat\" in df.columns else np.full(len(df), 0.5)\n",
    "    return train_test_split(X, y, t, p, test_size=test_size, random_state=seed, stratify=t)\n",
    "\n",
    "# Simple propensity model (for observational data)\n",
    "def fit_propensity(X, t) -> Pipeline:\n",
    "    pre = make_preprocessor()\n",
    "    prop = Pipeline([\n",
    "        (\"pre\", pre),\n",
    "        (\"logit\", LogisticRegression(max_iter=300))\n",
    "    ])\n",
    "    prop.fit(X, t)\n",
    "    return prop\n",
    "\n",
    "# -----------------------------\n",
    "# 1) T-learner\n",
    "# -----------------------------\n",
    "def fit_t_learner(X_train, y_train, t_train) -> Tuple[Pipeline, Pipeline]:\n",
    "    pre = make_preprocessor()\n",
    "    clf1 = Pipeline([(\"pre\", pre), (\"gb\", GradientBoostingClassifier(random_state=7))])  # Y|T=1\n",
    "    clf0 = Pipeline([(\"pre\", pre), (\"gb\", GradientBoostingClassifier(random_state=7))])  # Y|T=0\n",
    "    clf1.fit(X_train[t_train==1], y_train[t_train==1])\n",
    "    clf0.fit(X_train[t_train==0], y_train[t_train==0])\n",
    "    return clf1, clf0\n",
    "\n",
    "def predict_uplift_t_learner(clf1, clf0, X) -> np.ndarray:\n",
    "    p1 = clf1.predict_proba(X)[:,1]\n",
    "    p0 = clf0.predict_proba(X)[:,1]\n",
    "    return p1 - p0\n",
    "\n",
    "# -----------------------------\n",
    "# 2) X-learner\n",
    "# -----------------------------\n",
    "def fit_x_learner(X_train, y_train, t_train, prop_model=None) -> Dict[str, Pipeline]:\n",
    "    # Stage 1: T-learner outcome models\n",
    "    m1, m0 = fit_t_learner(X_train, y_train, t_train)\n",
    "\n",
    "    # Impute individual effects\n",
    "    # D1 for treated: Y - m0(X)\n",
    "    # D0 for control: m1(X) - Y\n",
    "    p0_cf = m0.predict_proba(X_train)[:,1]\n",
    "    p1_cf = m1.predict_proba(X_train)[:,1]\n",
    "    D1 = y_train - p0_cf    # only meaningful where T=1\n",
    "    D0 = p1_cf - y_train    # only meaningful where T=0\n",
    "\n",
    "    # Stage 2: effect models within each group\n",
    "    pre = make_preprocessor()\n",
    "    g1 = Pipeline([(\"pre\", pre), (\"gbr\", GradientBoostingRegressor(random_state=7))])  # for treated group\n",
    "    g0 = Pipeline([(\"pre\", pre), (\"gbr\", GradientBoostingRegressor(random_state=7))])  # for control group\n",
    "    g1.fit(X_train[t_train==1], D1[t_train==1])\n",
    "    g0.fit(X_train[t_train==0], D0[t_train==0])\n",
    "\n",
    "    # Propensity model for combination weights (if not provided)\n",
    "    if prop_model is None:\n",
    "        prop_model = fit_propensity(X_train, t_train)\n",
    "\n",
    "    return {\"m1\": m1, \"m0\": m0, \"g1\": g1, \"g0\": g0, \"prop\": prop_model}\n",
    "\n",
    "def predict_uplift_x_learner(x_models: Dict[str, Pipeline], X) -> np.ndarray:\n",
    "    e = x_models[\"prop\"].predict_proba(X)[:,1]\n",
    "    # tau_hat1 = g1(X) (good for treated-like points)\n",
    "    # tau_hat0 = g0(X) (good for control-like points)\n",
    "    tau1 = x_models[\"g1\"].predict(X)\n",
    "    tau0 = x_models[\"g0\"].predict(X)\n",
    "    # Combine with Rubin-style weights w(x) = e(x)\n",
    "    return e * tau0 + (1.0 - e) * tau1\n",
    "\n",
    "# -----------------------------\n",
    "# 3) DR-learner (orthogonal / doubly-robust)\n",
    "# -----------------------------\n",
    "def fit_dr_learner(X_train, y_train, t_train, prop_model=None) -> Dict[str, Pipeline]:\n",
    "    pre = make_preprocessor()\n",
    "    # Outcome models m_t(x) for t=0,1\n",
    "    m1 = Pipeline([(\"pre\", pre), (\"gb\", GradientBoostingClassifier(random_state=7))])\n",
    "    m0 = Pipeline([(\"pre\", pre), (\"gb\", GradientBoostingClassifier(random_state=7))])\n",
    "    m1.fit(X_train[t_train==1], y_train[t_train==1])\n",
    "    m0.fit(X_train[t_train==0], y_train[t_train==0])\n",
    "\n",
    "    # Propensity\n",
    "    if prop_model is None:\n",
    "        prop_model = fit_propensity(X_train, t_train)\n",
    "\n",
    "    # Build pseudo-outcome (orthogonalized):\n",
    "    # tau_tilde = ((Y - m_T(X)) * (T - e(X))) / (e(X) * (1 - e(X)))\n",
    "    mu1 = m1.predict_proba(X_train)[:,1]\n",
    "    mu0 = m0.predict_proba(X_train)[:,1]\n",
    "    e = np.clip(prop_model.predict_proba(X_train)[:,1], 1e-3, 1-1e-3)\n",
    "    muT = np.where(t_train==1, mu1, mu0)\n",
    "    numer = (y_train - muT) * (t_train - e)\n",
    "    denom = e * (1 - e)\n",
    "    tau_tilde = numer / denom\n",
    "\n",
    "    # Final stage: regress tau_tilde on X with a flexible regressor\n",
    "    tau_model = Pipeline([(\"pre\", pre), (\"gbr\", GradientBoostingRegressor(random_state=7))])\n",
    "    tau_model.fit(X_train, tau_tilde)\n",
    "\n",
    "    return {\"m1\": m1, \"m0\": m0, \"prop\": prop_model, \"tau\": tau_model}\n",
    "\n",
    "def predict_uplift_dr_learner(dr_models: Dict[str, Pipeline], X) -> np.ndarray:\n",
    "    return dr_models[\"tau\"].predict(X)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Policy curve & AUUC (evaluation)\n",
    "# -----------------------------\n",
    "def policy_value_curve(df: pd.DataFrame, tau_hat: np.ndarray, use_ipw: bool) -> pd.DataFrame:\n",
    "    # Sort by predicted uplift\n",
    "    d = df.copy()\n",
    "    d = d.assign(tau_hat=tau_hat).sort_values(\"tau_hat\", ascending=False).reset_index(drop=True)\n",
    "    n = len(d)\n",
    "    ks = np.linspace(0.1, 1.0, 10)\n",
    "    rows = []\n",
    "    prev_k = 0.0\n",
    "    prev_auuc = 0.0\n",
    "    prev_uplift = 0.0\n",
    "\n",
    "    for k in ks:\n",
    "        m = int(np.floor(k * n))\n",
    "        seg = d.iloc[:m]\n",
    "        if use_ipw:\n",
    "            e = np.clip(seg[\"p_treat\"].values, 1e-3, 1-1e-3)\n",
    "            y = seg[\"Y\"].values\n",
    "            t = seg[\"T\"].values\n",
    "            w_t = t / e\n",
    "            w_c = (1 - t) / (1 - e)\n",
    "            mu_t = np.sum(w_t * y) / np.sum(w_t)\n",
    "            mu_c = np.sum(w_c * y) / np.sum(w_c)\n",
    "            uplift = mu_t - mu_c\n",
    "        else:\n",
    "            uplift = seg.loc[seg[\"T\"]==1, \"Y\"].mean() - seg.loc[seg[\"T\"]==0, \"Y\"].mean()\n",
    "\n",
    "        auuc = prev_auuc + 0.5*(uplift + prev_uplift)*(k - prev_k)\n",
    "        rows.append({\"k\": k, \"group_size\": m, \"uplift_per_user\": uplift, \"AUUC\": auuc})\n",
    "        prev_k, prev_auuc, prev_uplift = k, auuc, uplift\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Example usage\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Example with RCT data (balanced groups)\n",
    "    # from your generator:\n",
    "    # rct_df = generate_lodging_uplift_data(60_000, \"rct\", seed=12)\n",
    "    # obs_df = generate_lodging_uplift_data(60_000, \"observational\", seed=11)\n",
    "\n",
    "    # Replace with one of your dataframes:\n",
    "    df = rct_df  # or obs_df\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te, t_tr, t_te = train_test_split_df(df)\n",
    "\n",
    "    # T-learner\n",
    "    m1, m0 = fit_t_learner(X_tr, y_tr, t_tr)\n",
    "    tau_hat_T = predict_uplift_t_learner(m1, m0, X_te)\n",
    "\n",
    "    # X-learner\n",
    "    prop_tr = fit_propensity(X_tr, t_tr) if \"p_treat\" not in df.columns else None\n",
    "    x_models = fit_x_learner(X_tr, y_tr, t_tr, prop_model=prop_tr)\n",
    "    tau_hat_X = predict_uplift_x_learner(x_models, X_te)\n",
    "\n",
    "    # DR-learner\n",
    "    dr_models = fit_dr_learner(X_tr, y_tr, t_tr, prop_model=prop_tr)\n",
    "    tau_hat_DR = predict_uplift_dr_learner(dr_models, X_te)\n",
    "\n",
    "    # Evaluate with policy curves\n",
    "    test_df = pd.DataFrame({\n",
    "        \"Y\": y_te, \"T\": t_te,\n",
    "        \"p_treat\": df.loc[X_te.index, \"p_treat\"].values if \"p_treat\" in df.columns else 0.5\n",
    "    })\n",
    "    use_ipw = not np.allclose(test_df[\"p_treat\"].values, 0.5)  # Observational -> IPW; RCT -> diff-in-means\n",
    "\n",
    "    curve_T  = policy_value_curve(test_df, tau_hat_T,  use_ipw=use_ipw)\n",
    "    curve_X  = policy_value_curve(test_df, tau_hat_X,  use_ipw=use_ipw)\n",
    "    curve_DR = policy_value_curve(test_df, tau_hat_DR, use_ipw=use_ipw)\n",
    "\n",
    "    print(\"Top-k AUUC (T, X, DR):\",\n",
    "          curve_T[\"AUUC\"].iloc[-1].round(4),\n",
    "          curve_X[\"AUUC\"].iloc[-1].round(4),\n",
    "          curve_DR[\"AUUC\"].iloc[-1].round(4))\n",
    "\n",
    "    # Treating the top 30% example (simulate policy value)\n",
    "    top_k = 0.30\n",
    "    k_idx = int(np.floor(top_k * len(test_df)))\n",
    "    order = np.argsort(-tau_hat_DR)  # by DR uplift\n",
    "    seg = test_df.iloc[order[:k_idx]]\n",
    "    if use_ipw:\n",
    "        e = np.clip(seg[\"p_treat\"].values, 1e-3, 1-1e-3)\n",
    "        y = seg[\"Y\"].values; t = seg[\"T\"].values\n",
    "        mu_t = np.sum((t/e)*y)/np.sum(t/e)\n",
    "        mu_c = np.sum(((1-t)/(1-e))*y)/np.sum((1-t)/(1-e))\n",
    "        print(\"Top-30% uplift per user (IPW):\", (mu_t - mu_c).round(4))\n",
    "    else:\n",
    "        print(\"Top-30% uplift per user (RCT diff-in-means):\",\n",
    "              (seg.loc[seg[\"T\"]==1,\"Y\"].mean() - seg.loc[seg[\"T\"]==0,\"Y\"].mean()).round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945eab6e",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "TBW"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-inference-studies (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
