{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0421c8de",
   "metadata": {},
   "source": [
    "# Uplift modelling\n",
    "\n",
    "An complex example of how heterogeneous treatment effects are used in ecommerce platforms. ðŸš€ðŸš€ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce9902",
   "metadata": {},
   "source": [
    "**The business problem:**\n",
    "\n",
    "We are concerted with *giving or not giving users a 5% discount voucher*.\n",
    "\n",
    "If we give it to everyone, we'll likely get more bookings, but at the same time we hurt our margins. So the best way to proceed is to give the coupons only to those customers that were unsure about the decision and that will actually convert after receiving it. Also, not giving the coupons to customers that were already going to book something no matter what!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3126ea",
   "metadata": {},
   "source": [
    "**The causal problem:**\n",
    "\n",
    "Our treatment $T$ is offering customers this coupon, a binary variable.\n",
    "\n",
    "Our outcome $Y$ is the customer finalizing their booking or not, also a binary variable.\n",
    "\n",
    "Additionally, we have access to a number of other variables $X$ characterizing the user, the channel that brough them to the platform, the specific ongoing session, and so on... We believe some of them could be valuable in deciding the effectiveness of the intervention. In other words, the effect isn't uniform but varies depending on some of these factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d10e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from uplift_modelling_utils import data_generating_process\n",
    "\n",
    "np.random.seed(111)\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.plotting_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4e5342",
   "metadata": {},
   "source": [
    "### Collect data and check basic properties\n",
    "\n",
    "The `data_generating_process` function returns the `data` itself, which can be used to train models. It also returns `metadata`, which is NOT available in practice, but which we can explore here to assess model performance exactly.\n",
    "\n",
    "We draw 60000 samples and see that there seems to be a difference in the booking probability when offering customers a coupon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7790c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>Y</th>\n",
       "      <th>T</th>\n",
       "      <th>channel</th>\n",
       "      <th>device</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>funnel_depth</th>\n",
       "      <th>price_sort_used</th>\n",
       "      <th>past_coupon_user</th>\n",
       "      <th>tenure_days</th>\n",
       "      <th>dest_tier</th>\n",
       "      <th>hour_local</th>\n",
       "      <th>recent_ad_exposure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>email</td>\n",
       "      <td>desktop</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>tier2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>paid_search</td>\n",
       "      <td>mobile_web</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1238</td>\n",
       "      <td>tier2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>paid_search</td>\n",
       "      <td>desktop</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1498</td>\n",
       "      <td>tier1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>paid_search</td>\n",
       "      <td>mobile_web</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>tier1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>paid_search</td>\n",
       "      <td>desktop</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1672</td>\n",
       "      <td>tier1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   client_id  Y  T      channel      device  lead_time  funnel_depth  \\\n",
       "0          0  0  1        email     desktop         14             0   \n",
       "1          1  0  1  paid_search  mobile_web          5             1   \n",
       "2          2  0  1  paid_search     desktop         90             1   \n",
       "3          3  0  1  paid_search  mobile_web         30             2   \n",
       "4          4  0  1  paid_search     desktop          3             2   \n",
       "\n",
       "   price_sort_used  past_coupon_user  tenure_days dest_tier  hour_local  \\\n",
       "0                0                 1          231     tier2           6   \n",
       "1                0                 1         1238     tier2          15   \n",
       "2                1                 0         1498     tier1          11   \n",
       "3                1                 1          138     tier1           9   \n",
       "4                1                 0         1672     tier1           3   \n",
       "\n",
       "   recent_ad_exposure  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observational (targeted / unbalanced)\n",
    "data, metadata = data_generating_process(60000, setting=\"observational\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f9514e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      " n = 60000\n",
      " treat_rate = 0.5733\n",
      " conv_rate_T1 = 0.178\n",
      " conv_rate_T0 = 0.1132\n",
      " ATE (naive) = 0.0648\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity checks\n",
    "print(\"Dataset:\")\n",
    "print(\" n =\", len(data))\n",
    "print(\" treat_rate =\", data[\"T\"].mean().round(4))\n",
    "print(\" conv_rate_T1 =\", data.loc[data[\"T\"] == 1, \"Y\"].mean().round(4))\n",
    "print(\" conv_rate_T0 =\", data.loc[data[\"T\"] == 0, \"Y\"].mean().round(4))\n",
    "print(\" ATE (naive) =\", (data.loc[data[\"T\"] == 1, \"Y\"].mean() - data.loc[data[\"T\"] == 0, \"Y\"].mean()).round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0764378d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>Y</th>\n",
       "      <th>T</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>funnel_depth</th>\n",
       "      <th>price_sort_used</th>\n",
       "      <th>past_coupon_user</th>\n",
       "      <th>tenure_days</th>\n",
       "      <th>dest_tier</th>\n",
       "      <th>hour_local</th>\n",
       "      <th>recent_ad_exposure</th>\n",
       "      <th>channel_direct</th>\n",
       "      <th>channel_email</th>\n",
       "      <th>channel_organic</th>\n",
       "      <th>channel_paid_search</th>\n",
       "      <th>device_desktop</th>\n",
       "      <th>device_mobile_web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1238</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1498</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1672</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>59995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1578</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>59996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>577</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>59997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1076</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>59998</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>489</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>59999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1032</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       client_id  Y  T  lead_time  funnel_depth  price_sort_used  \\\n",
       "0              0  0  1         14             0                0   \n",
       "1              1  0  1          5             1                0   \n",
       "2              2  0  1         90             1                1   \n",
       "3              3  0  1         30             2                1   \n",
       "4              4  0  1          3             2                1   \n",
       "...          ... .. ..        ...           ...              ...   \n",
       "59995      59995  0  1         21             0                0   \n",
       "59996      59996  0  1         60             1                1   \n",
       "59997      59997  0  0          5             1                1   \n",
       "59998      59998  0  1          7             0                1   \n",
       "59999      59999  0  0         10             0                0   \n",
       "\n",
       "       past_coupon_user  tenure_days dest_tier  hour_local  \\\n",
       "0                     1          231         2           6   \n",
       "1                     1         1238         2          15   \n",
       "2                     0         1498         1          11   \n",
       "3                     1          138         1           9   \n",
       "4                     0         1672         1           3   \n",
       "...                 ...          ...       ...         ...   \n",
       "59995                 1         1578         3          17   \n",
       "59996                 0          577         1          20   \n",
       "59997                 0         1076         1          13   \n",
       "59998                 0          489         1          11   \n",
       "59999                 1         1032         1           2   \n",
       "\n",
       "       recent_ad_exposure  channel_direct  channel_email  channel_organic  \\\n",
       "0                       0               0              1                0   \n",
       "1                       0               0              0                0   \n",
       "2                       0               0              0                0   \n",
       "3                       0               0              0                0   \n",
       "4                       0               0              0                0   \n",
       "...                   ...             ...            ...              ...   \n",
       "59995                   0               0              0                1   \n",
       "59996                   0               0              0                1   \n",
       "59997                   0               0              0                1   \n",
       "59998                   0               1              0                0   \n",
       "59999                   0               0              0                1   \n",
       "\n",
       "       channel_paid_search  device_desktop  device_mobile_web  \n",
       "0                        0               1                  0  \n",
       "1                        1               0                  1  \n",
       "2                        1               1                  0  \n",
       "3                        1               0                  1  \n",
       "4                        1               1                  0  \n",
       "...                    ...             ...                ...  \n",
       "59995                    0               0                  0  \n",
       "59996                    0               0                  0  \n",
       "59997                    0               0                  1  \n",
       "59998                    0               0                  1  \n",
       "59999                    0               1                  0  \n",
       "\n",
       "[60000 rows x 17 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encode \"channel\" and \"device\"\n",
    "data = pd.get_dummies(data, columns=[\"channel\", \"device\"], drop_first=True, dtype=int)\n",
    "# Ordinal encode \"dest_tier\"\n",
    "data.loc[:, \"dest_tier\"] = data[\"dest_tier\"].map({\"tier1\": 1, \"tier2\": 2, \"tier3\": 3})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8482a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_df(df: pd.DataFrame, features: list, test_size=0.25, seed=123):\n",
    "    x = df[features].values\n",
    "    y = df[\"Y\"].astype(float).values\n",
    "    t = df[\"T\"].astype(float).values\n",
    "    return train_test_split(x, y, t, test_size=test_size, random_state=seed, stratify=t)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, t_train, t_test = train_test_split_df(\n",
    "    data,\n",
    "    features=[col for col in data.columns if col not in [\"client_id\", \"Y\", \"T\"]],\n",
    "    test_size=0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e92a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLearner:\n",
    "    \"\"\"A simple T-Learner implementation.\"\"\"\n",
    "\n",
    "    def __init__(self, model_factory=lambda: GradientBoostingClassifier(random_state=7)) -> None:\n",
    "        \"\"\"Specify the model class (factory) to be used for the two models.\"\"\"\n",
    "        self.m1 = model_factory()\n",
    "        self.m0 = model_factory()\n",
    "\n",
    "    def fit(self, x: np.ndarray, t: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"Fit the control and treatment models.\"\"\"\n",
    "        self.m1.fit(x[t == 1], y[t == 1])\n",
    "        self.m0.fit(x[t == 0], y[t == 0])\n",
    "\n",
    "    def predict_uplift(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predict the uplift (treatment effect) for each sample in x.\"\"\"\n",
    "        p1 = self.m1.predict_proba(x)[:, 1]\n",
    "        p0 = self.m0.predict_proba(x)[:, 1]\n",
    "        return p1 - p0\n",
    "\n",
    "# T-learner\n",
    "t_learner = TLearner()\n",
    "t_learner.fit(X_train, t_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a639fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLearner:\n",
    "    \"\"\"A simple X-Learner implementation.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        clf_factory=lambda: GradientBoostingClassifier(random_state=7),\n",
    "        reg_factory=lambda: GradientBoostingRegressor(random_state=7),\n",
    "        prop_factory=lambda: LogisticRegression(max_iter=300),\n",
    "    ) -> None:\n",
    "        \"\"\"Specify the model classes (factories) to be used.\"\"\"\n",
    "        self.m1 = clf_factory()\n",
    "        self.m0 = clf_factory()\n",
    "        self.g1 = reg_factory()\n",
    "        self.g0 = reg_factory()\n",
    "        self.prop = prop_factory()\n",
    "\n",
    "    def fit(self, x: np.ndarray, y: np.ndarray, t: np.ndarray) -> None:\n",
    "        \"\"\"Fit the two outcome models, the two treatment effect models, and the propensity model.\"\"\"\n",
    "        self.m1.fit(x[t == 1], y[t == 1])\n",
    "        self.m0.fit(x[t == 0], y[t == 0])\n",
    "\n",
    "        p0_cf = self.m0.predict_proba(x)[:, 1]\n",
    "        p1_cf = self.m1.predict_proba(x)[:, 1]\n",
    "        d1 = y - p0_cf  # valid where t==1\n",
    "        d0 = p1_cf - y  # valid where t==0\n",
    "\n",
    "        self.g1.fit(x[t == 1], d1[t == 1])\n",
    "        self.g0.fit(x[t == 0], d0[t == 0])\n",
    "\n",
    "        self.prop.fit(x, t)\n",
    "\n",
    "    def predict_uplift(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Predict the uplift for a given set of features.\"\"\"\n",
    "        e = np.clip(self.prop.predict_proba(x)[:, 1], 1e-3, 1 - 1e-3)\n",
    "        tau1 = self.g1.predict(x)\n",
    "        tau0 = self.g0.predict(x)\n",
    "        return e * tau0 + (1.0 - e) * tau1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa2076d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with RCT data (balanced groups)\n",
    "# from your generator:\n",
    "# rct_df = generate_lodging_uplift_data(60_000, \"rct\", seed=12)\n",
    "# obs_df = generate_lodging_uplift_data(60_000, \"observational\", seed=11)\n",
    "\n",
    "# Replace with one of your dataframes:\n",
    "df = rct_df  # or obs_df\n",
    "\n",
    "X_tr, X_te, y_tr, y_te, t_tr, t_te = train_test_split_df(df)\n",
    "\n",
    "# T-learner\n",
    "m1, m0 = fit_t_learner(X_tr, y_tr, t_tr)\n",
    "tau_hat_T = predict_uplift_t_learner(m1, m0, X_te)\n",
    "\n",
    "# X-learner\n",
    "prop_tr = fit_propensity(X_tr, t_tr) if \"p_treat\" not in df.columns else None\n",
    "x_models = fit_x_learner(X_tr, y_tr, t_tr, prop_model=prop_tr)\n",
    "tau_hat_X = predict_uplift_x_learner(x_models, X_te)\n",
    "\n",
    "# DR-learner\n",
    "dr_models = fit_dr_learner(X_tr, y_tr, t_tr, prop_model=prop_tr)\n",
    "tau_hat_DR = predict_uplift_dr_learner(dr_models, X_te)\n",
    "\n",
    "# Evaluate with policy curves\n",
    "test_df = pd.DataFrame({\n",
    "    \"Y\": y_te, \"T\": t_te,\n",
    "    \"p_treat\": df.loc[X_te.index, \"p_treat\"].values if \"p_treat\" in df.columns else 0.5\n",
    "})\n",
    "use_ipw = not np.allclose(test_df[\"p_treat\"].values, 0.5)  # Observational -> IPW; RCT -> diff-in-means\n",
    "\n",
    "curve_T  = policy_value_curve(test_df, tau_hat_T,  use_ipw=use_ipw)\n",
    "curve_X  = policy_value_curve(test_df, tau_hat_X,  use_ipw=use_ipw)\n",
    "curve_DR = policy_value_curve(test_df, tau_hat_DR, use_ipw=use_ipw)\n",
    "\n",
    "print(\"Top-k AUUC (T, X, DR):\",\n",
    "        curve_T[\"AUUC\"].iloc[-1].round(4),\n",
    "        curve_X[\"AUUC\"].iloc[-1].round(4),\n",
    "        curve_DR[\"AUUC\"].iloc[-1].round(4))\n",
    "\n",
    "# Treating the top 30% example (simulate policy value)\n",
    "top_k = 0.30\n",
    "k_idx = int(np.floor(top_k * len(test_df)))\n",
    "order = np.argsort(-tau_hat_DR)  # by DR uplift\n",
    "seg = test_df.iloc[order[:k_idx]]\n",
    "if use_ipw:\n",
    "    e = np.clip(seg[\"p_treat\"].values, 1e-3, 1-1e-3)\n",
    "    y = seg[\"Y\"].values; t = seg[\"T\"].values\n",
    "    mu_t = np.sum((t/e)*y)/np.sum(t/e)\n",
    "    mu_c = np.sum(((1-t)/(1-e))*y)/np.sum((1-t)/(1-e))\n",
    "    print(\"Top-30% uplift per user (IPW):\", (mu_t - mu_c).round(4))\n",
    "else:\n",
    "    print(\"Top-30% uplift per user (RCT diff-in-means):\",\n",
    "            (seg.loc[seg[\"T\"]==1,\"Y\"].mean() - seg.loc[seg[\"T\"]==0,\"Y\"].mean()).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945eab6e",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "TBW"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal-inference-studies (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
